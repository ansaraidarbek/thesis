{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy, categorical_crossentropy, mean_squared_error\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height, img_num_channels = 28, 28, 1\n",
    "\n",
    "(input_train, targets), (input_test, target_test) = mnist.load_data()\n",
    "\n",
    "# Determine shape of the data\n",
    "input_shape = (img_width, img_height, img_num_channels)\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "inputs = input_train / 255\n",
    "input_test = input_test / 255\n",
    "inputs = np.expand_dims(inputs, -1)\n",
    "input_test = np.expand_dims(input_test, -1)\n",
    "targets = tf.keras.utils.to_categorical(targets, 10)\n",
    "target_test = tf.keras.utils.to_categorical(target_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel1(no_epochs, bs):\n",
    "    batch_size = bs\n",
    "    loss_function = categorical_crossentropy\n",
    "    optimizer = Adam()\n",
    "    no_classes = 10\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation=sigmoid, input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation=sigmoid))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(no_classes, activation=sigmoid))\n",
    "    model.summary()\n",
    "    model.compile(loss=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "    history = model.fit(inputs, targets, epochs=no_epochs,validation_split=0.1, shuffle= True, batch_size=batch_size)\n",
    "    test_loss, test_acc = model.evaluate(input_test,  target_test, verbose=2)\n",
    "    print(f'testSetLoss: {test_loss} - testSetAccuracyz: {test_acc}%')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel2(no_epochs, bs):\n",
    "    batch_size = bs\n",
    "    loss_function = mean_squared_error\n",
    "    optimizer = Adam()\n",
    "    no_classes = 10\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(no_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "    history = model.fit(inputs, targets, epochs=no_epochs,validation_split=0.1, shuffle= True, batch_size=batch_size)\n",
    "    test_loss, test_acc = model.evaluate(input_test,  target_test, verbose=2)\n",
    "    print(f'testSetLoss: {test_loss} - testSetAccuracyz: {test_acc}%')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel3(no_epochs, bs):\n",
    "    batch_size = bs\n",
    "    loss_function = categorical_crossentropy\n",
    "    optimizer = SGD(learning_rate=0.1)\n",
    "    no_classes = 10\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(no_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "    history = model.fit(inputs, targets, epochs=no_epochs,validation_split=0.1, shuffle= True, batch_size=batch_size)\n",
    "    test_loss, test_acc = model.evaluate(input_test,  target_test, verbose=2)\n",
    "    print(f'testSetLoss: {test_loss} - testSetAccuracyz: {test_acc}%')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel4(no_epochs, bs):\n",
    "    batch_size = bs\n",
    "    loss_function = categorical_crossentropy\n",
    "    optimizer = SGD(learning_rate=0.01)\n",
    "    no_classes = 10\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(no_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "    history = model.fit(inputs, targets, epochs=no_epochs,validation_split=0.1, shuffle= True, batch_size=batch_size)\n",
    "    test_loss, test_acc = model.evaluate(input_test,  target_test, verbose=2)\n",
    "    print(f'testSetLoss: {test_loss} - testSetAccuracyz: {test_acc}%')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "27000/27000 [==============================] - 158s 6ms/step - loss: 0.2661 - accuracy: 0.9119 - val_loss: 0.0840 - val_accuracy: 0.9758\n",
      "Epoch 2/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0823 - accuracy: 0.9742 - val_loss: 0.0774 - val_accuracy: 0.9762\n",
      "Epoch 3/100\n",
      "27000/27000 [==============================] - 147s 5ms/step - loss: 0.0644 - accuracy: 0.9804 - val_loss: 0.0598 - val_accuracy: 0.9837\n",
      "Epoch 4/100\n",
      "27000/27000 [==============================] - 147s 5ms/step - loss: 0.0559 - accuracy: 0.9829 - val_loss: 0.0532 - val_accuracy: 0.9850\n",
      "Epoch 5/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0473 - accuracy: 0.9852 - val_loss: 0.0530 - val_accuracy: 0.9853\n",
      "Epoch 6/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0409 - accuracy: 0.9873 - val_loss: 0.0565 - val_accuracy: 0.9838\n",
      "Epoch 7/100\n",
      "27000/27000 [==============================] - 164s 6ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 0.0491 - val_accuracy: 0.9858\n",
      "Epoch 8/100\n",
      "27000/27000 [==============================] - 165s 6ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.0512 - val_accuracy: 0.9858\n",
      "Epoch 9/100\n",
      "27000/27000 [==============================] - 191s 7ms/step - loss: 0.0314 - accuracy: 0.9904 - val_loss: 0.0567 - val_accuracy: 0.9855\n",
      "Epoch 10/100\n",
      "27000/27000 [==============================] - 166s 6ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 0.0505 - val_accuracy: 0.9882\n",
      "Epoch 11/100\n",
      "27000/27000 [==============================] - 159s 6ms/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 0.0557 - val_accuracy: 0.9863\n",
      "Epoch 12/100\n",
      "27000/27000 [==============================] - 163s 6ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.0530 - val_accuracy: 0.9880\n",
      "Epoch 13/100\n",
      "27000/27000 [==============================] - 166s 6ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0554 - val_accuracy: 0.9885\n",
      "Epoch 14/100\n",
      "27000/27000 [==============================] - 161s 6ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0635 - val_accuracy: 0.9872\n",
      "Epoch 15/100\n",
      "27000/27000 [==============================] - 153s 6ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0584 - val_accuracy: 0.9877\n",
      "Epoch 16/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.0680 - val_accuracy: 0.9870\n",
      "Epoch 17/100\n",
      "27000/27000 [==============================] - 147s 5ms/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0611 - val_accuracy: 0.9860\n",
      "Epoch 18/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.0578 - val_accuracy: 0.9882\n",
      "Epoch 19/100\n",
      "27000/27000 [==============================] - 147s 5ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0572 - val_accuracy: 0.9878\n",
      "Epoch 20/100\n",
      "27000/27000 [==============================] - 146s 5ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.0626 - val_accuracy: 0.9873\n",
      "Epoch 21/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0650 - val_accuracy: 0.9888\n",
      "Epoch 22/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.0623 - val_accuracy: 0.9885\n",
      "Epoch 23/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0733 - val_accuracy: 0.9857\n",
      "Epoch 24/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.0715 - val_accuracy: 0.9883\n",
      "Epoch 25/100\n",
      "27000/27000 [==============================] - 146s 5ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.0746 - val_accuracy: 0.9863\n",
      "Epoch 26/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0750 - val_accuracy: 0.9885\n",
      "Epoch 27/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.0730 - val_accuracy: 0.9887\n",
      "Epoch 28/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0821 - val_accuracy: 0.9868\n",
      "Epoch 29/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0739 - val_accuracy: 0.9875\n",
      "Epoch 30/100\n",
      "27000/27000 [==============================] - 146s 5ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0771 - val_accuracy: 0.9868\n",
      "Epoch 31/100\n",
      "27000/27000 [==============================] - 146s 5ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0848 - val_accuracy: 0.9872\n",
      "Epoch 32/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0819 - val_accuracy: 0.9882\n",
      "Epoch 33/100\n",
      "27000/27000 [==============================] - 145s 5ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0751 - val_accuracy: 0.9878\n",
      "Epoch 34/100\n",
      "27000/27000 [==============================] - 145s 5ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 0.0850 - val_accuracy: 0.9868\n",
      "Epoch 35/100\n",
      "27000/27000 [==============================] - 145s 5ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0913 - val_accuracy: 0.9883\n",
      "Epoch 36/100\n",
      "27000/27000 [==============================] - 146s 5ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0918 - val_accuracy: 0.9890\n",
      "Epoch 37/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0829 - val_accuracy: 0.9900\n",
      "Epoch 38/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1063 - val_accuracy: 0.9880\n",
      "Epoch 39/100\n",
      "27000/27000 [==============================] - 145s 5ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0867 - val_accuracy: 0.9863\n",
      "Epoch 40/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.0823 - val_accuracy: 0.9892\n",
      "Epoch 41/100\n",
      "27000/27000 [==============================] - 208s 8ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0864 - val_accuracy: 0.9892\n",
      "Epoch 42/100\n",
      "27000/27000 [==============================] - 439s 16ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0991 - val_accuracy: 0.9868\n",
      "Epoch 43/100\n",
      "27000/27000 [==============================] - 146s 5ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0886 - val_accuracy: 0.9890\n",
      "Epoch 44/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0988 - val_accuracy: 0.9873\n",
      "Epoch 45/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.1171 - val_accuracy: 0.9872\n",
      "Epoch 46/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0984 - val_accuracy: 0.9893\n",
      "Epoch 47/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1070 - val_accuracy: 0.9868\n",
      "Epoch 48/100\n",
      "27000/27000 [==============================] - 147s 5ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1002 - val_accuracy: 0.9882\n",
      "Epoch 49/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 0.0950 - val_accuracy: 0.9878\n",
      "Epoch 50/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.1017 - val_accuracy: 0.9870\n",
      "Epoch 51/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0965 - val_accuracy: 0.9882\n",
      "Epoch 52/100\n",
      "27000/27000 [==============================] - 147s 5ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.1045 - val_accuracy: 0.9878\n",
      "Epoch 53/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.1139 - val_accuracy: 0.9885\n",
      "Epoch 54/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.1061 - val_accuracy: 0.9882\n",
      "Epoch 55/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.1029 - val_accuracy: 0.9883\n",
      "Epoch 56/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.1060 - val_accuracy: 0.9873\n",
      "Epoch 57/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.1109 - val_accuracy: 0.9878\n",
      "Epoch 58/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.1267 - val_accuracy: 0.9858\n",
      "Epoch 59/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1229 - val_accuracy: 0.9880\n",
      "Epoch 60/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.1290 - val_accuracy: 0.9882\n",
      "Epoch 61/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1014 - val_accuracy: 0.9878\n",
      "Epoch 62/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1151 - val_accuracy: 0.9870\n",
      "Epoch 63/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.1101 - val_accuracy: 0.9892\n",
      "Epoch 64/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.1126 - val_accuracy: 0.9897\n",
      "Epoch 65/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1100 - val_accuracy: 0.9873\n",
      "Epoch 66/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1157 - val_accuracy: 0.9880\n",
      "Epoch 67/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.1193 - val_accuracy: 0.9887\n",
      "Epoch 68/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1141 - val_accuracy: 0.9883\n",
      "Epoch 69/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.1217 - val_accuracy: 0.9887\n",
      "Epoch 70/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1224 - val_accuracy: 0.9892\n",
      "Epoch 71/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1198 - val_accuracy: 0.9892\n",
      "Epoch 72/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.1070 - val_accuracy: 0.9885\n",
      "Epoch 73/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.1405 - val_accuracy: 0.9872\n",
      "Epoch 74/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1290 - val_accuracy: 0.9867\n",
      "Epoch 75/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1449 - val_accuracy: 0.9883\n",
      "Epoch 76/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1305 - val_accuracy: 0.9885\n",
      "Epoch 77/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.1289 - val_accuracy: 0.9893\n",
      "Epoch 78/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1366 - val_accuracy: 0.9878\n",
      "Epoch 79/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1293 - val_accuracy: 0.9888\n",
      "Epoch 80/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.1335 - val_accuracy: 0.9882\n",
      "Epoch 81/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.1343 - val_accuracy: 0.9868\n",
      "Epoch 82/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.1253 - val_accuracy: 0.9890\n",
      "Epoch 83/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1314 - val_accuracy: 0.9888\n",
      "Epoch 84/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1255 - val_accuracy: 0.9895\n",
      "Epoch 85/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.1343 - val_accuracy: 0.9878\n",
      "Epoch 86/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1334 - val_accuracy: 0.9890\n",
      "Epoch 87/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1338 - val_accuracy: 0.9862\n",
      "Epoch 88/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.1437 - val_accuracy: 0.9873\n",
      "Epoch 89/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.1310 - val_accuracy: 0.9880\n",
      "Epoch 90/100\n",
      "27000/27000 [==============================] - 166s 6ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1458 - val_accuracy: 0.9880\n",
      "Epoch 91/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1348 - val_accuracy: 0.9882\n",
      "Epoch 92/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.1459 - val_accuracy: 0.9877\n",
      "Epoch 93/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.1308 - val_accuracy: 0.9880\n",
      "Epoch 94/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.1699 - val_accuracy: 0.9867\n",
      "Epoch 95/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.1397 - val_accuracy: 0.9885\n",
      "Epoch 96/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1345 - val_accuracy: 0.9875\n",
      "Epoch 97/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1389 - val_accuracy: 0.9885\n",
      "Epoch 98/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1644 - val_accuracy: 0.9868\n",
      "Epoch 99/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1294 - val_accuracy: 0.9873\n",
      "Epoch 100/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1478 - val_accuracy: 0.9873\n",
      "313/313 - 2s - loss: 0.1277 - accuracy: 0.9860\n",
      "testSetLoss: 0.1277390420436859 - testSetAccuracyz: 0.9860000014305115%\n"
     ]
    }
   ],
   "source": [
    "test1_2 = trainModel1(100, 2)\n",
    "hist_df = pd.DataFrame(test1_2.history)\n",
    "hist_json_file = 'test1_2.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 0.4221 - accuracy: 0.8582 - val_loss: 0.0888 - val_accuracy: 0.9728\n",
      "Epoch 2/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0915 - accuracy: 0.9718 - val_loss: 0.0785 - val_accuracy: 0.9768\n",
      "Epoch 3/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0672 - accuracy: 0.9791 - val_loss: 0.0626 - val_accuracy: 0.9827\n",
      "Epoch 4/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0553 - accuracy: 0.9831 - val_loss: 0.0520 - val_accuracy: 0.9853\n",
      "Epoch 5/100\n",
      "6750/6750 [==============================] - 41s 6ms/step - loss: 0.0466 - accuracy: 0.9853 - val_loss: 0.0435 - val_accuracy: 0.9883\n",
      "Epoch 6/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 0.0415 - accuracy: 0.9869 - val_loss: 0.0496 - val_accuracy: 0.9862\n",
      "Epoch 7/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0368 - accuracy: 0.9880 - val_loss: 0.0468 - val_accuracy: 0.9890\n",
      "Epoch 8/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.0472 - val_accuracy: 0.9870\n",
      "Epoch 9/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 0.0495 - val_accuracy: 0.9867\n",
      "Epoch 10/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 0.0502 - val_accuracy: 0.9867\n",
      "Epoch 11/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.0459 - val_accuracy: 0.9887\n",
      "Epoch 12/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0406 - val_accuracy: 0.9895\n",
      "Epoch 13/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.0471 - val_accuracy: 0.9892\n",
      "Epoch 14/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.0452 - val_accuracy: 0.9883\n",
      "Epoch 15/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.0490 - val_accuracy: 0.9877\n",
      "Epoch 16/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.0533 - val_accuracy: 0.9870\n",
      "Epoch 17/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.0500 - val_accuracy: 0.9878\n",
      "Epoch 18/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0581 - val_accuracy: 0.9860\n",
      "Epoch 19/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0544 - val_accuracy: 0.9855\n",
      "Epoch 20/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0670 - val_accuracy: 0.9847\n",
      "Epoch 21/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.0539 - val_accuracy: 0.9893\n",
      "Epoch 22/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0585 - val_accuracy: 0.9888\n",
      "Epoch 23/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0667 - val_accuracy: 0.9875\n",
      "Epoch 24/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0627 - val_accuracy: 0.9865\n",
      "Epoch 25/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0522 - val_accuracy: 0.9895\n",
      "Epoch 26/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0574 - val_accuracy: 0.9883\n",
      "Epoch 27/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0613 - val_accuracy: 0.9877\n",
      "Epoch 28/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0589 - val_accuracy: 0.9883\n",
      "Epoch 29/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0585 - val_accuracy: 0.9868\n",
      "Epoch 30/100\n",
      "6750/6750 [==============================] - 41s 6ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0626 - val_accuracy: 0.9872\n",
      "Epoch 31/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0681 - val_accuracy: 0.9877\n",
      "Epoch 32/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0589 - val_accuracy: 0.9885\n",
      "Epoch 33/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0595 - val_accuracy: 0.9885\n",
      "Epoch 34/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0651 - val_accuracy: 0.9887\n",
      "Epoch 35/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0719 - val_accuracy: 0.9870\n",
      "Epoch 36/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0715 - val_accuracy: 0.9880\n",
      "Epoch 37/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0604 - val_accuracy: 0.9888\n",
      "Epoch 38/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0653 - val_accuracy: 0.9883\n",
      "Epoch 39/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0650 - val_accuracy: 0.9897\n",
      "Epoch 40/100\n",
      "6750/6750 [==============================] - 41s 6ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0738 - val_accuracy: 0.9863\n",
      "Epoch 41/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0705 - val_accuracy: 0.9883\n",
      "Epoch 42/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0815 - val_accuracy: 0.9862\n",
      "Epoch 43/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0708 - val_accuracy: 0.9895\n",
      "Epoch 44/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0700 - val_accuracy: 0.9880\n",
      "Epoch 45/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0794 - val_accuracy: 0.9882\n",
      "Epoch 46/100\n",
      "6750/6750 [==============================] - 41s 6ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0661 - val_accuracy: 0.9882\n",
      "Epoch 47/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0727 - val_accuracy: 0.9872\n",
      "Epoch 48/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0718 - val_accuracy: 0.9895\n",
      "Epoch 49/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0741 - val_accuracy: 0.9887\n",
      "Epoch 50/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0723 - val_accuracy: 0.9892\n",
      "Epoch 51/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0746 - val_accuracy: 0.9887\n",
      "Epoch 52/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0723 - val_accuracy: 0.9895\n",
      "Epoch 53/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0776 - val_accuracy: 0.9883\n",
      "Epoch 54/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0778 - val_accuracy: 0.9883\n",
      "Epoch 55/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0742 - val_accuracy: 0.9890\n",
      "Epoch 56/100\n",
      "6750/6750 [==============================] - 41s 6ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0764 - val_accuracy: 0.9893\n",
      "Epoch 57/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0759 - val_accuracy: 0.9890\n",
      "Epoch 58/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0847 - val_accuracy: 0.9885\n",
      "Epoch 59/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0737 - val_accuracy: 0.9888\n",
      "Epoch 60/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0780 - val_accuracy: 0.9872\n",
      "Epoch 61/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0868 - val_accuracy: 0.9882\n",
      "Epoch 62/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0844 - val_accuracy: 0.9888\n",
      "Epoch 63/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0796 - val_accuracy: 0.9888\n",
      "Epoch 64/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 9.9466e-04 - accuracy: 0.9997 - val_loss: 0.0817 - val_accuracy: 0.9885\n",
      "Epoch 65/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0884 - val_accuracy: 0.9883\n",
      "Epoch 66/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 9.5917e-04 - accuracy: 0.9997 - val_loss: 0.0787 - val_accuracy: 0.9883\n",
      "Epoch 67/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 7.5542e-04 - accuracy: 0.9998 - val_loss: 0.0807 - val_accuracy: 0.9897\n",
      "Epoch 68/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1006 - val_accuracy: 0.9857\n",
      "Epoch 69/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 9.7000e-04 - accuracy: 0.9996 - val_loss: 0.0908 - val_accuracy: 0.9888\n",
      "Epoch 70/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 7.2906e-04 - accuracy: 0.9996 - val_loss: 0.0849 - val_accuracy: 0.9888\n",
      "Epoch 71/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0933 - val_accuracy: 0.9882\n",
      "Epoch 72/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 8.5150e-04 - accuracy: 0.9997 - val_loss: 0.1016 - val_accuracy: 0.9877\n",
      "Epoch 73/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 9.9663e-04 - accuracy: 0.9997 - val_loss: 0.0828 - val_accuracy: 0.9895\n",
      "Epoch 74/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 8.0078e-04 - accuracy: 0.9997 - val_loss: 0.0916 - val_accuracy: 0.9892\n",
      "Epoch 75/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 5.8434e-04 - accuracy: 0.9998 - val_loss: 0.0836 - val_accuracy: 0.9897\n",
      "Epoch 76/100\n",
      "6750/6750 [==============================] - 42s 6ms/step - loss: 7.2827e-04 - accuracy: 0.9997 - val_loss: 0.0839 - val_accuracy: 0.9893\n",
      "Epoch 77/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 8.6706e-04 - accuracy: 0.9997 - val_loss: 0.0929 - val_accuracy: 0.9895\n",
      "Epoch 78/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 8.9645e-04 - accuracy: 0.9997 - val_loss: 0.0878 - val_accuracy: 0.9887\n",
      "Epoch 79/100\n",
      "6750/6750 [==============================] - 41s 6ms/step - loss: 6.0381e-04 - accuracy: 0.9998 - val_loss: 0.0847 - val_accuracy: 0.9880\n",
      "Epoch 80/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 7.6884e-04 - accuracy: 0.9998 - val_loss: 0.0873 - val_accuracy: 0.9882\n",
      "Epoch 81/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 6.1537e-04 - accuracy: 0.9998 - val_loss: 0.0853 - val_accuracy: 0.9893\n",
      "Epoch 82/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 7.7458e-04 - accuracy: 0.9997 - val_loss: 0.0838 - val_accuracy: 0.9887\n",
      "Epoch 83/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 6.3193e-04 - accuracy: 0.9997 - val_loss: 0.0987 - val_accuracy: 0.9880\n",
      "Epoch 84/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 9.6154e-04 - accuracy: 0.9996 - val_loss: 0.0994 - val_accuracy: 0.9877\n",
      "Epoch 85/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 5.0373e-04 - accuracy: 0.9999 - val_loss: 0.1036 - val_accuracy: 0.9883\n",
      "Epoch 86/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.6930e-04 - accuracy: 0.9997 - val_loss: 0.0880 - val_accuracy: 0.9890\n",
      "Epoch 87/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 2.8103e-04 - accuracy: 0.9999 - val_loss: 0.1087 - val_accuracy: 0.9868\n",
      "Epoch 88/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 6.7914e-04 - accuracy: 0.9998 - val_loss: 0.0961 - val_accuracy: 0.9882\n",
      "Epoch 89/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 5.7030e-04 - accuracy: 0.9999 - val_loss: 0.1016 - val_accuracy: 0.9882\n",
      "Epoch 90/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 3.4378e-04 - accuracy: 0.9999 - val_loss: 0.0919 - val_accuracy: 0.9880\n",
      "Epoch 91/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 5.7202e-04 - accuracy: 0.9998 - val_loss: 0.0937 - val_accuracy: 0.9898\n",
      "Epoch 92/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 5.0259e-04 - accuracy: 0.9999 - val_loss: 0.0953 - val_accuracy: 0.9898\n",
      "Epoch 93/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 8.6349e-04 - accuracy: 0.9996 - val_loss: 0.0961 - val_accuracy: 0.9890\n",
      "Epoch 94/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 2.6265e-04 - accuracy: 0.9999 - val_loss: 0.1040 - val_accuracy: 0.9877\n",
      "Epoch 95/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 8.5761e-04 - accuracy: 0.9997 - val_loss: 0.0948 - val_accuracy: 0.9895\n",
      "Epoch 96/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 2.6025e-04 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9863\n",
      "Epoch 97/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 8.0954e-04 - accuracy: 0.9997 - val_loss: 0.0974 - val_accuracy: 0.9883\n",
      "Epoch 98/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 7.2742e-04 - accuracy: 0.9998 - val_loss: 0.0994 - val_accuracy: 0.9890\n",
      "Epoch 99/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 3.4261e-04 - accuracy: 0.9999 - val_loss: 0.0976 - val_accuracy: 0.9887\n",
      "Epoch 100/100\n",
      "6750/6750 [==============================] - 42s 6ms/step - loss: 3.6786e-04 - accuracy: 0.9999 - val_loss: 0.1046 - val_accuracy: 0.9882\n",
      "313/313 - 1s - loss: 0.0848 - accuracy: 0.9875\n",
      "testSetLoss: 0.08475511521100998 - testSetAccuracyz: 0.987500011920929%\n"
     ]
    }
   ],
   "source": [
    "test1_8 = trainModel1(100, 8)\n",
    "hist_df = pd.DataFrame(test1_8.history)\n",
    "hist_json_file = 'test1_8.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 0.5045 - accuracy: 0.8322 - val_loss: 0.1220 - val_accuracy: 0.9648\n",
      "Epoch 2/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.1090 - accuracy: 0.9665 - val_loss: 0.0829 - val_accuracy: 0.9772\n",
      "Epoch 3/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0760 - accuracy: 0.9765 - val_loss: 0.0688 - val_accuracy: 0.9802\n",
      "Epoch 4/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0615 - accuracy: 0.9807 - val_loss: 0.0557 - val_accuracy: 0.9842\n",
      "Epoch 5/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0506 - accuracy: 0.9845 - val_loss: 0.0584 - val_accuracy: 0.9840\n",
      "Epoch 6/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0441 - accuracy: 0.9860 - val_loss: 0.0553 - val_accuracy: 0.9832\n",
      "Epoch 7/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0388 - accuracy: 0.9879 - val_loss: 0.0522 - val_accuracy: 0.9852\n",
      "Epoch 8/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 0.0441 - val_accuracy: 0.9848\n",
      "Epoch 9/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0311 - accuracy: 0.9904 - val_loss: 0.0489 - val_accuracy: 0.9850\n",
      "Epoch 10/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.0537 - val_accuracy: 0.9842\n",
      "Epoch 11/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.0466 - val_accuracy: 0.9868\n",
      "Epoch 12/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.0529 - val_accuracy: 0.9853\n",
      "Epoch 13/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 0.0517 - val_accuracy: 0.9843\n",
      "Epoch 14/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0502 - val_accuracy: 0.9865\n",
      "Epoch 15/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.0459 - val_accuracy: 0.9865\n",
      "Epoch 16/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.0510 - val_accuracy: 0.9870\n",
      "Epoch 17/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0475 - val_accuracy: 0.9873\n",
      "Epoch 18/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.0506 - val_accuracy: 0.9858\n",
      "Epoch 19/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0493 - val_accuracy: 0.9872\n",
      "Epoch 20/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0500 - val_accuracy: 0.9872\n",
      "Epoch 21/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0469 - val_accuracy: 0.9877\n",
      "Epoch 22/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0517 - val_accuracy: 0.9877\n",
      "Epoch 23/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0502 - val_accuracy: 0.9885\n",
      "Epoch 24/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0558 - val_accuracy: 0.9867\n",
      "Epoch 25/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0501 - val_accuracy: 0.9883\n",
      "Epoch 26/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0685 - val_accuracy: 0.9857\n",
      "Epoch 27/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0587 - val_accuracy: 0.9865\n",
      "Epoch 28/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0540 - val_accuracy: 0.9875\n",
      "Epoch 29/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0620 - val_accuracy: 0.9878\n",
      "Epoch 30/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0550 - val_accuracy: 0.9878\n",
      "Epoch 31/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0567 - val_accuracy: 0.9877\n",
      "Epoch 32/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0582 - val_accuracy: 0.9875\n",
      "Epoch 33/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0601 - val_accuracy: 0.9868\n",
      "Epoch 34/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0578 - val_accuracy: 0.9885\n",
      "Epoch 35/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0584 - val_accuracy: 0.9870\n",
      "Epoch 36/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0601 - val_accuracy: 0.9888\n",
      "Epoch 37/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0622 - val_accuracy: 0.9875\n",
      "Epoch 38/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0619 - val_accuracy: 0.9880\n",
      "Epoch 39/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0622 - val_accuracy: 0.9877\n",
      "Epoch 40/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0703 - val_accuracy: 0.9868\n",
      "Epoch 41/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0600 - val_accuracy: 0.9888\n",
      "Epoch 42/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0644 - val_accuracy: 0.9883\n",
      "Epoch 43/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0687 - val_accuracy: 0.9875\n",
      "Epoch 44/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0639 - val_accuracy: 0.9880\n",
      "Epoch 45/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0709 - val_accuracy: 0.9873\n",
      "Epoch 46/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0703 - val_accuracy: 0.9870\n",
      "Epoch 47/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0755 - val_accuracy: 0.9863\n",
      "Epoch 48/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0666 - val_accuracy: 0.9868\n",
      "Epoch 49/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0677 - val_accuracy: 0.9880\n",
      "Epoch 50/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0720 - val_accuracy: 0.9865\n",
      "Epoch 51/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0761 - val_accuracy: 0.9870\n",
      "Epoch 52/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0703 - val_accuracy: 0.9890\n",
      "Epoch 53/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0747 - val_accuracy: 0.9878\n",
      "Epoch 54/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0808 - val_accuracy: 0.9880\n",
      "Epoch 55/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0791 - val_accuracy: 0.9865\n",
      "Epoch 56/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0777 - val_accuracy: 0.9860\n",
      "Epoch 57/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0786 - val_accuracy: 0.9870\n",
      "Epoch 58/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 5.9973e-04 - accuracy: 0.9999 - val_loss: 0.0877 - val_accuracy: 0.9862\n",
      "Epoch 59/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0735 - val_accuracy: 0.9878\n",
      "Epoch 60/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 7.2209e-04 - accuracy: 0.9999 - val_loss: 0.0722 - val_accuracy: 0.9882\n",
      "Epoch 61/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0672 - val_accuracy: 0.9890\n",
      "Epoch 62/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0650 - val_accuracy: 0.9892\n",
      "Epoch 63/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0781 - val_accuracy: 0.9878\n",
      "Epoch 64/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 1.7660e-04 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 0.9890\n",
      "Epoch 65/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0764 - val_accuracy: 0.9875\n",
      "Epoch 66/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.4445e-04 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9885\n",
      "Epoch 67/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0754 - val_accuracy: 0.9883\n",
      "Epoch 68/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0821 - val_accuracy: 0.9883\n",
      "Epoch 69/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 8.0621e-04 - accuracy: 0.9997 - val_loss: 0.0753 - val_accuracy: 0.9895\n",
      "Epoch 70/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0799 - val_accuracy: 0.9872\n",
      "Epoch 71/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0770 - val_accuracy: 0.9877\n",
      "Epoch 72/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 2.4505e-04 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9890\n",
      "Epoch 73/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0752 - val_accuracy: 0.9880\n",
      "Epoch 74/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 8.5090e-04 - accuracy: 0.9997 - val_loss: 0.0849 - val_accuracy: 0.9873\n",
      "Epoch 75/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0767 - val_accuracy: 0.9882\n",
      "Epoch 76/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 6.3115e-04 - accuracy: 0.9998 - val_loss: 0.0790 - val_accuracy: 0.9887\n",
      "Epoch 77/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 9.4634e-04 - accuracy: 0.9997 - val_loss: 0.0885 - val_accuracy: 0.9875\n",
      "Epoch 78/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 4.3057e-04 - accuracy: 0.9999 - val_loss: 0.0803 - val_accuracy: 0.9902\n",
      "Epoch 79/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0852 - val_accuracy: 0.9875\n",
      "Epoch 80/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.2939e-04 - accuracy: 0.9999 - val_loss: 0.0821 - val_accuracy: 0.9882\n",
      "Epoch 81/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0939 - val_accuracy: 0.9868\n",
      "Epoch 82/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 5.5676e-04 - accuracy: 0.9998 - val_loss: 0.0925 - val_accuracy: 0.9868\n",
      "Epoch 83/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 6.9710e-04 - accuracy: 0.9998 - val_loss: 0.0766 - val_accuracy: 0.9893\n",
      "Epoch 84/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0826 - val_accuracy: 0.9878\n",
      "Epoch 85/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 2.1308e-04 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9855\n",
      "Epoch 86/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0824 - val_accuracy: 0.9883\n",
      "Epoch 87/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 1.1342e-04 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9900\n",
      "Epoch 88/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0783 - val_accuracy: 0.9887\n",
      "Epoch 89/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 9.7263e-04 - accuracy: 0.9997 - val_loss: 0.0935 - val_accuracy: 0.9875\n",
      "Epoch 90/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 5.9267e-04 - accuracy: 0.9999 - val_loss: 0.0852 - val_accuracy: 0.9875\n",
      "Epoch 91/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0914 - val_accuracy: 0.9872\n",
      "Epoch 92/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 1.8314e-04 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9878\n",
      "Epoch 93/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0819 - val_accuracy: 0.9883\n",
      "Epoch 94/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 5.3176e-05 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9885\n",
      "Epoch 95/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0992 - val_accuracy: 0.9873\n",
      "Epoch 96/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 5.6920e-04 - accuracy: 0.9998 - val_loss: 0.0806 - val_accuracy: 0.9895\n",
      "Epoch 97/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.5964e-04 - accuracy: 0.9999 - val_loss: 0.0881 - val_accuracy: 0.9877\n",
      "Epoch 98/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0881 - val_accuracy: 0.9892\n",
      "Epoch 99/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 5.9956e-04 - accuracy: 0.9998 - val_loss: 0.0836 - val_accuracy: 0.9885\n",
      "Epoch 100/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 2.7724e-05 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9888\n",
      "313/313 - 1s - loss: 0.0793 - accuracy: 0.9887\n",
      "testSetLoss: 0.07934556901454926 - testSetAccuracyz: 0.9886999726295471%\n"
     ]
    }
   ],
   "source": [
    "test1_16 = trainModel1(100, 16)\n",
    "hist_df = pd.DataFrame(test1_16.history)\n",
    "hist_json_file = 'test1_16.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.6823 - accuracy: 0.7689 - val_loss: 0.1449 - val_accuracy: 0.9607\n",
      "Epoch 2/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.1379 - accuracy: 0.9587 - val_loss: 0.0908 - val_accuracy: 0.9735\n",
      "Epoch 3/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0914 - accuracy: 0.9726 - val_loss: 0.0720 - val_accuracy: 0.9782\n",
      "Epoch 4/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0718 - accuracy: 0.9781 - val_loss: 0.0664 - val_accuracy: 0.9825\n",
      "Epoch 5/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0603 - accuracy: 0.9814 - val_loss: 0.0585 - val_accuracy: 0.9818\n",
      "Epoch 6/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0528 - accuracy: 0.9830 - val_loss: 0.0626 - val_accuracy: 0.9823\n",
      "Epoch 7/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0464 - accuracy: 0.9854 - val_loss: 0.0527 - val_accuracy: 0.9852\n",
      "Epoch 8/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0418 - accuracy: 0.9868 - val_loss: 0.0528 - val_accuracy: 0.9850\n",
      "Epoch 9/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 0.0486 - val_accuracy: 0.9858\n",
      "Epoch 10/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0343 - accuracy: 0.9887 - val_loss: 0.0542 - val_accuracy: 0.9860\n",
      "Epoch 11/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0304 - accuracy: 0.9900 - val_loss: 0.0604 - val_accuracy: 0.9823\n",
      "Epoch 12/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0488 - val_accuracy: 0.9863\n",
      "Epoch 13/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0560 - val_accuracy: 0.9842\n",
      "Epoch 14/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0463 - val_accuracy: 0.9872\n",
      "Epoch 15/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0533 - val_accuracy: 0.9857\n",
      "Epoch 16/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0458 - val_accuracy: 0.9873\n",
      "Epoch 17/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.0485 - val_accuracy: 0.9865\n",
      "Epoch 18/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0153 - accuracy: 0.9956 - val_loss: 0.0528 - val_accuracy: 0.9860\n",
      "Epoch 19/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0523 - val_accuracy: 0.9870\n",
      "Epoch 20/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.0463 - val_accuracy: 0.9895\n",
      "Epoch 21/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.0459 - val_accuracy: 0.9890\n",
      "Epoch 22/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0548 - val_accuracy: 0.9858\n",
      "Epoch 23/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0441 - val_accuracy: 0.9895\n",
      "Epoch 24/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0471 - val_accuracy: 0.9873\n",
      "Epoch 25/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.0518 - val_accuracy: 0.9880\n",
      "Epoch 26/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 27/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0456 - val_accuracy: 0.9888\n",
      "Epoch 28/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0549 - val_accuracy: 0.9873\n",
      "Epoch 29/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0554 - val_accuracy: 0.9878\n",
      "Epoch 30/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0523 - val_accuracy: 0.9883\n",
      "Epoch 31/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0517 - val_accuracy: 0.9893\n",
      "Epoch 32/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0526 - val_accuracy: 0.9892\n",
      "Epoch 33/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0646 - val_accuracy: 0.9882\n",
      "Epoch 34/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0566 - val_accuracy: 0.9883\n",
      "Epoch 35/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0575 - val_accuracy: 0.9883\n",
      "Epoch 36/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0578 - val_accuracy: 0.9885\n",
      "Epoch 37/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0608 - val_accuracy: 0.9873\n",
      "Epoch 38/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0584 - val_accuracy: 0.9887\n",
      "Epoch 39/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0550 - val_accuracy: 0.9902\n",
      "Epoch 40/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0578 - val_accuracy: 0.9882\n",
      "Epoch 41/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0554 - val_accuracy: 0.9888\n",
      "Epoch 42/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0677 - val_accuracy: 0.9875\n",
      "Epoch 43/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0636 - val_accuracy: 0.9885\n",
      "Epoch 44/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0603 - val_accuracy: 0.9893\n",
      "Epoch 45/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0556 - val_accuracy: 0.9892\n",
      "Epoch 46/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0569 - val_accuracy: 0.9897\n",
      "Epoch 47/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0610 - val_accuracy: 0.9887\n",
      "Epoch 48/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0614 - val_accuracy: 0.9893\n",
      "Epoch 49/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0642 - val_accuracy: 0.9893\n",
      "Epoch 50/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0644 - val_accuracy: 0.9883\n",
      "Epoch 51/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0642 - val_accuracy: 0.9892\n",
      "Epoch 52/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0651 - val_accuracy: 0.9887\n",
      "Epoch 53/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0627 - val_accuracy: 0.9897\n",
      "Epoch 54/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0655 - val_accuracy: 0.9883\n",
      "Epoch 55/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0620 - val_accuracy: 0.9895\n",
      "Epoch 56/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0895 - val_accuracy: 0.9828\n",
      "Epoch 57/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0616 - val_accuracy: 0.9898\n",
      "Epoch 58/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 2.8738e-04 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9893\n",
      "Epoch 59/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0766 - val_accuracy: 0.9873\n",
      "Epoch 60/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0660 - val_accuracy: 0.9893\n",
      "Epoch 61/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0753 - val_accuracy: 0.9877\n",
      "Epoch 62/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 7.5566e-04 - accuracy: 0.9999 - val_loss: 0.0679 - val_accuracy: 0.9885\n",
      "Epoch 63/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 2.0992e-04 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 0.9897\n",
      "Epoch 64/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0833 - val_accuracy: 0.9877\n",
      "Epoch 65/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0682 - val_accuracy: 0.9882\n",
      "Epoch 66/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 1.8396e-04 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9897\n",
      "Epoch 67/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0762 - val_accuracy: 0.9877\n",
      "Epoch 68/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 6.6428e-04 - accuracy: 0.9999 - val_loss: 0.0688 - val_accuracy: 0.9903\n",
      "Epoch 69/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 7.2344e-04 - accuracy: 0.9999 - val_loss: 0.0665 - val_accuracy: 0.9893\n",
      "Epoch 70/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0672 - val_accuracy: 0.9895\n",
      "Epoch 71/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 5.4800e-04 - accuracy: 0.9999 - val_loss: 0.0757 - val_accuracy: 0.9882\n",
      "Epoch 72/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 5.1755e-04 - accuracy: 0.9999 - val_loss: 0.0672 - val_accuracy: 0.9887\n",
      "Epoch 73/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 1.3509e-04 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9887\n",
      "Epoch 74/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0701 - val_accuracy: 0.9898\n",
      "Epoch 75/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 1.2739e-04 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9898\n",
      "Epoch 76/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 9.0302e-05 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 0.9895\n",
      "Epoch 77/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0731 - val_accuracy: 0.9898\n",
      "Epoch 78/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 3.7232e-04 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9908\n",
      "Epoch 79/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 1.0810e-04 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9910\n",
      "Epoch 80/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 1.1458e-04 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9893\n",
      "Epoch 81/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0691 - val_accuracy: 0.9905\n",
      "Epoch 82/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 1.0055e-04 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9905\n",
      "Epoch 83/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 7.1113e-05 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9908\n",
      "Epoch 84/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0800 - val_accuracy: 0.9888\n",
      "Epoch 85/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 8.7363e-04 - accuracy: 0.9998 - val_loss: 0.0747 - val_accuracy: 0.9907\n",
      "Epoch 86/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 2.0554e-04 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9900\n",
      "Epoch 87/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0774 - val_accuracy: 0.9888\n",
      "Epoch 88/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 2.4522e-04 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9905\n",
      "Epoch 89/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 6.4204e-05 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9905\n",
      "Epoch 90/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 4.9546e-05 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 0.9905\n",
      "Epoch 91/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0730 - val_accuracy: 0.9888\n",
      "Epoch 92/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 4.3480e-04 - accuracy: 0.9999 - val_loss: 0.0737 - val_accuracy: 0.9897\n",
      "Epoch 93/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0715 - val_accuracy: 0.9897\n",
      "Epoch 94/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 9.8931e-05 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9902\n",
      "Epoch 95/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 5.7045e-05 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9902\n",
      "Epoch 96/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0791 - val_accuracy: 0.9883\n",
      "Epoch 97/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 5.8837e-04 - accuracy: 0.9999 - val_loss: 0.0765 - val_accuracy: 0.9897\n",
      "Epoch 98/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 7.7167e-05 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9895\n",
      "Epoch 99/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 4.9439e-05 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9895\n",
      "Epoch 100/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0773 - val_accuracy: 0.9890\n",
      "313/313 - 1s - loss: 0.0698 - accuracy: 0.9875\n",
      "testSetLoss: 0.06981083750724792 - testSetAccuracyz: 0.987500011920929%\n"
     ]
    }
   ],
   "source": [
    "test1_32 = trainModel1(100, 32)\n",
    "hist_df = pd.DataFrame(test1_32.history)\n",
    "hist_json_file = 'test1_32.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "844/844 [==============================] - 7s 7ms/step - loss: 0.9833 - accuracy: 0.6711 - val_loss: 0.2242 - val_accuracy: 0.9340\n",
      "Epoch 2/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.2025 - accuracy: 0.9409 - val_loss: 0.1199 - val_accuracy: 0.9678\n",
      "Epoch 3/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.1252 - accuracy: 0.9628 - val_loss: 0.0928 - val_accuracy: 0.9752\n",
      "Epoch 4/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0934 - accuracy: 0.9721 - val_loss: 0.0720 - val_accuracy: 0.9787\n",
      "Epoch 5/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0754 - accuracy: 0.9776 - val_loss: 0.0688 - val_accuracy: 0.9808\n",
      "Epoch 6/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0645 - accuracy: 0.9806 - val_loss: 0.0613 - val_accuracy: 0.9825\n",
      "Epoch 7/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0571 - accuracy: 0.9826 - val_loss: 0.0569 - val_accuracy: 0.9835\n",
      "Epoch 8/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0513 - accuracy: 0.9838 - val_loss: 0.0609 - val_accuracy: 0.9822\n",
      "Epoch 9/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 0.0545 - val_accuracy: 0.9845\n",
      "Epoch 10/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0427 - accuracy: 0.9871 - val_loss: 0.0512 - val_accuracy: 0.9857\n",
      "Epoch 11/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0393 - accuracy: 0.9879 - val_loss: 0.0526 - val_accuracy: 0.9860\n",
      "Epoch 12/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 0.0551 - val_accuracy: 0.9838\n",
      "Epoch 13/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0327 - accuracy: 0.9900 - val_loss: 0.0507 - val_accuracy: 0.9858\n",
      "Epoch 14/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.0496 - val_accuracy: 0.9865\n",
      "Epoch 15/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0274 - accuracy: 0.9916 - val_loss: 0.0519 - val_accuracy: 0.9862\n",
      "Epoch 16/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0259 - accuracy: 0.9921 - val_loss: 0.0493 - val_accuracy: 0.9862\n",
      "Epoch 17/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.0527 - val_accuracy: 0.9858\n",
      "Epoch 18/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0217 - accuracy: 0.9936 - val_loss: 0.0552 - val_accuracy: 0.9843\n",
      "Epoch 19/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.0538 - val_accuracy: 0.9845\n",
      "Epoch 20/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0490 - val_accuracy: 0.9855\n",
      "Epoch 21/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.0503 - val_accuracy: 0.9862\n",
      "Epoch 22/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.0498 - val_accuracy: 0.9862\n",
      "Epoch 23/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.0515 - val_accuracy: 0.9857\n",
      "Epoch 24/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.0510 - val_accuracy: 0.9870\n",
      "Epoch 25/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.0547 - val_accuracy: 0.9862\n",
      "Epoch 26/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.0458 - val_accuracy: 0.9882\n",
      "Epoch 27/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0472 - val_accuracy: 0.9880\n",
      "Epoch 28/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0095 - accuracy: 0.9978 - val_loss: 0.0488 - val_accuracy: 0.9883\n",
      "Epoch 29/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.0478 - val_accuracy: 0.9887\n",
      "Epoch 30/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0510 - val_accuracy: 0.9883\n",
      "Epoch 31/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0530 - val_accuracy: 0.9865\n",
      "Epoch 32/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0492 - val_accuracy: 0.9888\n",
      "Epoch 33/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0475 - val_accuracy: 0.9882\n",
      "Epoch 34/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0511 - val_accuracy: 0.9878\n",
      "Epoch 35/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.0593 - val_accuracy: 0.9867\n",
      "Epoch 36/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0558 - val_accuracy: 0.9863\n",
      "Epoch 37/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0508 - val_accuracy: 0.9887\n",
      "Epoch 38/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0510 - val_accuracy: 0.9883\n",
      "Epoch 39/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0611 - val_accuracy: 0.9848\n",
      "Epoch 40/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0521 - val_accuracy: 0.9883\n",
      "Epoch 41/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0518 - val_accuracy: 0.9890\n",
      "Epoch 42/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0518 - val_accuracy: 0.9887\n",
      "Epoch 43/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0567 - val_accuracy: 0.9862\n",
      "Epoch 44/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0536 - val_accuracy: 0.9897\n",
      "Epoch 45/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0531 - val_accuracy: 0.9880\n",
      "Epoch 46/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0546 - val_accuracy: 0.9890\n",
      "Epoch 47/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0546 - val_accuracy: 0.9885\n",
      "Epoch 48/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0624 - val_accuracy: 0.9882\n",
      "Epoch 49/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0563 - val_accuracy: 0.9888\n",
      "Epoch 50/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0566 - val_accuracy: 0.9888\n",
      "Epoch 51/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0614 - val_accuracy: 0.9877\n",
      "Epoch 52/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0545 - val_accuracy: 0.9897\n",
      "Epoch 53/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 9.7096e-04 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9865\n",
      "Epoch 54/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0578 - val_accuracy: 0.9892\n",
      "Epoch 55/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0624 - val_accuracy: 0.9878\n",
      "Epoch 56/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0638 - val_accuracy: 0.9878\n",
      "Epoch 57/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0647 - val_accuracy: 0.9880\n",
      "Epoch 58/100\n",
      "844/844 [==============================] - 7s 9ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0646 - val_accuracy: 0.9880\n",
      "Epoch 59/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0701 - val_accuracy: 0.9872\n",
      "Epoch 60/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 6.2673e-04 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 0.9880\n",
      "Epoch 61/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 6.0302e-04 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 0.9885\n",
      "Epoch 62/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 8.4539e-04 - accuracy: 0.9998 - val_loss: 0.0806 - val_accuracy: 0.9862\n",
      "Epoch 63/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0631 - val_accuracy: 0.9888\n",
      "Epoch 64/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 3.5966e-04 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9895\n",
      "Epoch 65/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.8110e-04 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9890\n",
      "Epoch 66/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.9128e-04 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 0.9885\n",
      "Epoch 67/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0655 - val_accuracy: 0.9890\n",
      "Epoch 68/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 3.4925e-04 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9885\n",
      "Epoch 69/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.4415e-04 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9888\n",
      "Epoch 70/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.3248e-04 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9883\n",
      "Epoch 71/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.8795e-04 - accuracy: 1.0000 - val_loss: 0.0637 - val_accuracy: 0.9885\n",
      "Epoch 72/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0693 - val_accuracy: 0.9878\n",
      "Epoch 73/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.6008e-04 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9880\n",
      "Epoch 74/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.9075e-04 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 0.9882\n",
      "Epoch 75/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.8164e-04 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9883\n",
      "Epoch 76/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.2382e-04 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 0.9867\n",
      "Epoch 77/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0666 - val_accuracy: 0.9882\n",
      "Epoch 78/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.3673e-04 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 0.9888\n",
      "Epoch 79/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.5984e-04 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9890\n",
      "Epoch 80/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.4555e-04 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9892\n",
      "Epoch 81/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.4177e-04 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9888\n",
      "Epoch 82/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0685 - val_accuracy: 0.9893\n",
      "Epoch 83/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 5.2654e-04 - accuracy: 0.9999 - val_loss: 0.0661 - val_accuracy: 0.9892\n",
      "Epoch 84/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.5089e-04 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9885\n",
      "Epoch 85/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.2639e-04 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 0.9893\n",
      "Epoch 86/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.1362e-04 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 0.9887\n",
      "Epoch 87/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.0888e-04 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 0.9888\n",
      "Epoch 88/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.1149e-04 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9888\n",
      "Epoch 89/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0687 - val_accuracy: 0.9883\n",
      "Epoch 90/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.1293e-04 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9880\n",
      "Epoch 91/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.2493e-04 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9890\n",
      "Epoch 92/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.0482e-04 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9888\n",
      "Epoch 93/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 9.3026e-05 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9898\n",
      "Epoch 94/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 8.5909e-05 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9880\n",
      "Epoch 95/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 9.1667e-05 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 0.9900\n",
      "Epoch 96/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0721 - val_accuracy: 0.9880\n",
      "Epoch 97/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.7100e-04 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9875\n",
      "Epoch 98/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.0456e-04 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9882\n",
      "Epoch 99/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 8.4884e-05 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9877\n",
      "Epoch 100/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 7.8089e-05 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9880\n",
      "313/313 - 1s - loss: 0.0545 - accuracy: 0.9897\n",
      "testSetLoss: 0.05446115881204605 - testSetAccuracyz: 0.9897000193595886%\n"
     ]
    }
   ],
   "source": [
    "test1_64 = trainModel1(100, 64)\n",
    "hist_df = pd.DataFrame(test1_64.history)\n",
    "hist_json_file = 'test1_64.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 5s 11ms/step - loss: 1.2999 - accuracy: 0.5694 - val_loss: 0.3364 - val_accuracy: 0.9065\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.3232 - accuracy: 0.9046 - val_loss: 0.1963 - val_accuracy: 0.9457\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.2080 - accuracy: 0.9394 - val_loss: 0.1412 - val_accuracy: 0.9595\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.1505 - accuracy: 0.9562 - val_loss: 0.1066 - val_accuracy: 0.9717\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.1180 - accuracy: 0.9661 - val_loss: 0.0889 - val_accuracy: 0.9768\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0990 - accuracy: 0.9713 - val_loss: 0.0826 - val_accuracy: 0.9767\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0864 - accuracy: 0.9739 - val_loss: 0.0739 - val_accuracy: 0.9793\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0750 - accuracy: 0.9779 - val_loss: 0.0661 - val_accuracy: 0.9808\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0677 - accuracy: 0.9797 - val_loss: 0.0639 - val_accuracy: 0.9817\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0607 - accuracy: 0.9819 - val_loss: 0.0566 - val_accuracy: 0.9842\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0565 - accuracy: 0.9825 - val_loss: 0.0572 - val_accuracy: 0.9823\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0518 - accuracy: 0.9844 - val_loss: 0.0565 - val_accuracy: 0.9840\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0477 - accuracy: 0.9856 - val_loss: 0.0522 - val_accuracy: 0.9855\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0451 - accuracy: 0.9866 - val_loss: 0.0539 - val_accuracy: 0.9848\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0427 - accuracy: 0.9869 - val_loss: 0.0512 - val_accuracy: 0.9838\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0396 - accuracy: 0.9880 - val_loss: 0.0478 - val_accuracy: 0.9862\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 0.0470 - val_accuracy: 0.9858\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0350 - accuracy: 0.9891 - val_loss: 0.0479 - val_accuracy: 0.9867\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.0503 - val_accuracy: 0.9857\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0310 - accuracy: 0.9910 - val_loss: 0.0473 - val_accuracy: 0.9855\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 0.0458 - val_accuracy: 0.9852\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0279 - accuracy: 0.9913 - val_loss: 0.0432 - val_accuracy: 0.9880\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 0.0457 - val_accuracy: 0.9882\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.0465 - val_accuracy: 0.9862\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.0479 - val_accuracy: 0.9868\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0224 - accuracy: 0.9934 - val_loss: 0.0429 - val_accuracy: 0.9885\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 0.0448 - val_accuracy: 0.9868\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.0439 - val_accuracy: 0.9872\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0181 - accuracy: 0.9950 - val_loss: 0.0464 - val_accuracy: 0.9875\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.0459 - val_accuracy: 0.9868\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.0476 - val_accuracy: 0.9870\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.0476 - val_accuracy: 0.9870\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0147 - accuracy: 0.9959 - val_loss: 0.0453 - val_accuracy: 0.9880\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.0476 - val_accuracy: 0.9868\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.0454 - val_accuracy: 0.9873\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0116 - accuracy: 0.9971 - val_loss: 0.0462 - val_accuracy: 0.9868\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.0478 - val_accuracy: 0.9877\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0483 - val_accuracy: 0.9873\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.0442 - val_accuracy: 0.9888\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 0.0477 - val_accuracy: 0.9877\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.0440 - val_accuracy: 0.9890\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.0483 - val_accuracy: 0.9877\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.0472 - val_accuracy: 0.9880\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0449 - val_accuracy: 0.9893\n",
      "Epoch 45/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.0476 - val_accuracy: 0.9883\n",
      "Epoch 46/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.0472 - val_accuracy: 0.9887\n",
      "Epoch 47/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0498 - val_accuracy: 0.9860\n",
      "Epoch 48/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.0533 - val_accuracy: 0.9870\n",
      "Epoch 49/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.0501 - val_accuracy: 0.9890\n",
      "Epoch 50/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0503 - val_accuracy: 0.9882\n",
      "Epoch 51/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0503 - val_accuracy: 0.9880\n",
      "Epoch 52/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0476 - val_accuracy: 0.9895\n",
      "Epoch 53/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0514 - val_accuracy: 0.9890\n",
      "Epoch 54/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0494 - val_accuracy: 0.9883\n",
      "Epoch 55/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0532 - val_accuracy: 0.9873\n",
      "Epoch 56/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0557 - val_accuracy: 0.9878\n",
      "Epoch 57/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0513 - val_accuracy: 0.9883\n",
      "Epoch 58/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0503 - val_accuracy: 0.9885\n",
      "Epoch 59/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.0497 - val_accuracy: 0.9887\n",
      "Epoch 60/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0519 - val_accuracy: 0.9892\n",
      "Epoch 61/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0532 - val_accuracy: 0.9882\n",
      "Epoch 62/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0506 - val_accuracy: 0.9897\n",
      "Epoch 63/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9902\n",
      "Epoch 64/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9888\n",
      "Epoch 65/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0525 - val_accuracy: 0.9893\n",
      "Epoch 66/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0551 - val_accuracy: 0.9885\n",
      "Epoch 67/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0563 - val_accuracy: 0.9892\n",
      "Epoch 68/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0528 - val_accuracy: 0.9897\n",
      "Epoch 69/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0554 - val_accuracy: 0.9900\n",
      "Epoch 70/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9895\n",
      "Epoch 71/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0554 - val_accuracy: 0.9890\n",
      "Epoch 72/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0604 - val_accuracy: 0.9888\n",
      "Epoch 73/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0595 - val_accuracy: 0.9885\n",
      "Epoch 74/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 0.9900\n",
      "Epoch 75/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9895\n",
      "Epoch 76/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 6.6688e-04 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 0.9898\n",
      "Epoch 77/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 7.0393e-04 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9898\n",
      "Epoch 78/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0632 - val_accuracy: 0.9870\n",
      "Epoch 79/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0567 - val_accuracy: 0.9903\n",
      "Epoch 80/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 5.6387e-04 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9897\n",
      "Epoch 81/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 4.8982e-04 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9903\n",
      "Epoch 82/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 4.5303e-04 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9892\n",
      "Epoch 83/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 5.3877e-04 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9900\n",
      "Epoch 84/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 4.3107e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9900\n",
      "Epoch 85/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 4.4180e-04 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9897\n",
      "Epoch 86/100\n",
      "422/422 [==============================] - 5s 11ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0637 - val_accuracy: 0.9875\n",
      "Epoch 87/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 6.7821e-04 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9897\n",
      "Epoch 88/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.7186e-04 - accuracy: 1.0000 - val_loss: 0.0595 - val_accuracy: 0.9898\n",
      "Epoch 89/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.3651e-04 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9895\n",
      "Epoch 90/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.3097e-04 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9898\n",
      "Epoch 91/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.2965e-04 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9902\n",
      "Epoch 92/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.3620e-04 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9898\n",
      "Epoch 93/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.8983e-04 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 0.9898\n",
      "Epoch 94/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.5060e-04 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9892\n",
      "Epoch 95/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0633 - val_accuracy: 0.9890\n",
      "Epoch 96/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 4.0736e-04 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9908\n",
      "Epoch 97/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.6309e-04 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9902\n",
      "Epoch 98/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.4033e-04 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9902\n",
      "Epoch 99/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.2142e-04 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9907\n",
      "Epoch 100/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.1540e-04 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 0.9902\n",
      "313/313 - 1s - loss: 0.0479 - accuracy: 0.9894\n",
      "testSetLoss: 0.04787454381585121 - testSetAccuracyz: 0.9894000291824341%\n"
     ]
    }
   ],
   "source": [
    "test1_128 = trainModel1(100, 128)\n",
    "hist_df = pd.DataFrame(test1_128.history)\n",
    "hist_json_file = 'test1_128.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 1.8811 - accuracy: 0.3713 - val_loss: 0.5796 - val_accuracy: 0.8558\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.4593 - accuracy: 0.8666 - val_loss: 0.2969 - val_accuracy: 0.9133\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.3128 - accuracy: 0.9086 - val_loss: 0.2103 - val_accuracy: 0.9397\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.2353 - accuracy: 0.9329 - val_loss: 0.1608 - val_accuracy: 0.9545\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.1839 - accuracy: 0.9477 - val_loss: 0.1327 - val_accuracy: 0.9662\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1521 - accuracy: 0.9566 - val_loss: 0.1104 - val_accuracy: 0.9718\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1288 - accuracy: 0.9625 - val_loss: 0.0987 - val_accuracy: 0.9730\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1130 - accuracy: 0.9670 - val_loss: 0.0911 - val_accuracy: 0.9745\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.1010 - accuracy: 0.9708 - val_loss: 0.0831 - val_accuracy: 0.9778\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0905 - accuracy: 0.9739 - val_loss: 0.0790 - val_accuracy: 0.9780\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0831 - accuracy: 0.9756 - val_loss: 0.0753 - val_accuracy: 0.9797\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0774 - accuracy: 0.9769 - val_loss: 0.0662 - val_accuracy: 0.9822\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0717 - accuracy: 0.9789 - val_loss: 0.0666 - val_accuracy: 0.98080.0720 - accuracy\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0661 - accuracy: 0.9810 - val_loss: 0.0610 - val_accuracy: 0.9823\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0623 - accuracy: 0.9816 - val_loss: 0.0614 - val_accuracy: 0.9827\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0588 - accuracy: 0.9829 - val_loss: 0.0625 - val_accuracy: 0.9822\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0570 - accuracy: 0.9829 - val_loss: 0.0570 - val_accuracy: 0.9838\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0530 - accuracy: 0.9845 - val_loss: 0.0578 - val_accuracy: 0.9845\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0497 - accuracy: 0.9853 - val_loss: 0.0536 - val_accuracy: 0.9847\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0485 - accuracy: 0.9860 - val_loss: 0.0512 - val_accuracy: 0.9858\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0459 - accuracy: 0.9867 - val_loss: 0.0551 - val_accuracy: 0.9848\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0448 - accuracy: 0.9869 - val_loss: 0.0529 - val_accuracy: 0.9847\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0427 - accuracy: 0.9874 - val_loss: 0.0484 - val_accuracy: 0.9867\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0403 - accuracy: 0.9882 - val_loss: 0.0508 - val_accuracy: 0.9855\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0390 - accuracy: 0.9888 - val_loss: 0.0502 - val_accuracy: 0.9857\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0375 - accuracy: 0.9890 - val_loss: 0.0467 - val_accuracy: 0.9865\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0358 - accuracy: 0.9894 - val_loss: 0.0478 - val_accuracy: 0.9863\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0343 - accuracy: 0.9902 - val_loss: 0.0463 - val_accuracy: 0.9867\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0334 - accuracy: 0.9900 - val_loss: 0.0474 - val_accuracy: 0.9862\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0315 - accuracy: 0.9907 - val_loss: 0.0447 - val_accuracy: 0.9878\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 0.0456 - val_accuracy: 0.9873\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0288 - accuracy: 0.9918 - val_loss: 0.0451 - val_accuracy: 0.9875\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0279 - accuracy: 0.9921 - val_loss: 0.0451 - val_accuracy: 0.9875\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0267 - accuracy: 0.9925 - val_loss: 0.0429 - val_accuracy: 0.9872\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0254 - accuracy: 0.9931 - val_loss: 0.0468 - val_accuracy: 0.9875\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0246 - accuracy: 0.9929 - val_loss: 0.0416 - val_accuracy: 0.9892\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.0468 - val_accuracy: 0.9875\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0227 - accuracy: 0.9938 - val_loss: 0.0439 - val_accuracy: 0.9877\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.0438 - val_accuracy: 0.9870\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0441 - val_accuracy: 0.9870\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0201 - accuracy: 0.9945 - val_loss: 0.0427 - val_accuracy: 0.9888\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0479 - val_accuracy: 0.9858\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0187 - accuracy: 0.9950 - val_loss: 0.0430 - val_accuracy: 0.9883\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.0428 - val_accuracy: 0.9888\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.0446 - val_accuracy: 0.9878\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0161 - accuracy: 0.9959 - val_loss: 0.0435 - val_accuracy: 0.9882\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0152 - accuracy: 0.9964 - val_loss: 0.0433 - val_accuracy: 0.9892\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.0432 - val_accuracy: 0.9885\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.0427 - val_accuracy: 0.9890\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0132 - accuracy: 0.9969 - val_loss: 0.0426 - val_accuracy: 0.9892\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.0431 - val_accuracy: 0.9890\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.0421 - val_accuracy: 0.9890\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.0440 - val_accuracy: 0.9888\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.0413 - val_accuracy: 0.9893\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0106 - accuracy: 0.9980 - val_loss: 0.0426 - val_accuracy: 0.9892\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.0460 - val_accuracy: 0.9878\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0101 - accuracy: 0.9980 - val_loss: 0.0440 - val_accuracy: 0.9883\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.0439 - val_accuracy: 0.9888\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.0434 - val_accuracy: 0.9888\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0090 - accuracy: 0.9984 - val_loss: 0.0428 - val_accuracy: 0.9893\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0084 - accuracy: 0.9984 - val_loss: 0.0425 - val_accuracy: 0.9892\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.0446 - val_accuracy: 0.9883\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.0455 - val_accuracy: 0.9887\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0421 - val_accuracy: 0.9900\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0434 - val_accuracy: 0.9888\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.0472 - val_accuracy: 0.9883\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0474 - val_accuracy: 0.9877\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.0434 - val_accuracy: 0.9885\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0440 - val_accuracy: 0.9897\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0434 - val_accuracy: 0.9887\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0048 - accuracy: 0.9995 - val_loss: 0.0436 - val_accuracy: 0.9900\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0453 - val_accuracy: 0.9888\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.0456 - val_accuracy: 0.9898\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0489 - val_accuracy: 0.9883\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 0.0506 - val_accuracy: 0.9882\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0475 - val_accuracy: 0.9882\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.0450 - val_accuracy: 0.9895\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.0500 - val_accuracy: 0.9882\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.0464 - val_accuracy: 0.9887\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0467 - val_accuracy: 0.9895\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.0476 - val_accuracy: 0.9888\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0031 - accuracy: 0.9998 - val_loss: 0.0476 - val_accuracy: 0.9887\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0516 - val_accuracy: 0.9885\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.0477 - val_accuracy: 0.9885\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.0459 - val_accuracy: 0.9903\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9890\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.0486 - val_accuracy: 0.9887\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0481 - val_accuracy: 0.9895\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0475 - val_accuracy: 0.9895\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.0497 - val_accuracy: 0.9895\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0482 - val_accuracy: 0.9898\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0512 - val_accuracy: 0.9890\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0504 - val_accuracy: 0.9892\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9898\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9895\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9888\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9880\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9885\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9885\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9888\n",
      "313/313 - 1s - loss: 0.0468 - accuracy: 0.9895\n",
      "testSetLoss: 0.04677689075469971 - testSetAccuracyz: 0.9894999861717224%\n"
     ]
    }
   ],
   "source": [
    "test1_256 = trainModel1(100, 256)\n",
    "hist_df = pd.DataFrame(test1_256.history)\n",
    "hist_json_file = 'test1_256.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 4s 29ms/step - loss: 2.2720 - accuracy: 0.1857 - val_loss: 2.0172 - val_accuracy: 0.4445\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.0881 - accuracy: 0.7321 - val_loss: 0.4854 - val_accuracy: 0.8762\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.4703 - accuracy: 0.8649 - val_loss: 0.3270 - val_accuracy: 0.9103\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.3622 - accuracy: 0.8949 - val_loss: 0.2612 - val_accuracy: 0.9273\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.2980 - accuracy: 0.9145 - val_loss: 0.2155 - val_accuracy: 0.9433\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.2495 - accuracy: 0.9284 - val_loss: 0.1839 - val_accuracy: 0.9508\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.2139 - accuracy: 0.9397 - val_loss: 0.1576 - val_accuracy: 0.9602\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.1853 - accuracy: 0.9470 - val_loss: 0.1360 - val_accuracy: 0.9632\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.1644 - accuracy: 0.9527 - val_loss: 0.1237 - val_accuracy: 0.9670\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.1478 - accuracy: 0.9585 - val_loss: 0.1126 - val_accuracy: 0.9717\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.1345 - accuracy: 0.9620 - val_loss: 0.1047 - val_accuracy: 0.9728\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.1239 - accuracy: 0.9651 - val_loss: 0.0995 - val_accuracy: 0.9740\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.1151 - accuracy: 0.9669 - val_loss: 0.0932 - val_accuracy: 0.9750\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.1072 - accuracy: 0.9696 - val_loss: 0.0863 - val_accuracy: 0.9775\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.1010 - accuracy: 0.9716 - val_loss: 0.0823 - val_accuracy: 0.9787\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0944 - accuracy: 0.9729 - val_loss: 0.0776 - val_accuracy: 0.9795\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0904 - accuracy: 0.9739 - val_loss: 0.0760 - val_accuracy: 0.9793\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0852 - accuracy: 0.9753 - val_loss: 0.0730 - val_accuracy: 0.9807\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0809 - accuracy: 0.9765 - val_loss: 0.0690 - val_accuracy: 0.9813\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0774 - accuracy: 0.9779 - val_loss: 0.0670 - val_accuracy: 0.9808\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0742 - accuracy: 0.9784 - val_loss: 0.0660 - val_accuracy: 0.9825\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0714 - accuracy: 0.9791 - val_loss: 0.0645 - val_accuracy: 0.9828\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0684 - accuracy: 0.9801 - val_loss: 0.0619 - val_accuracy: 0.9827\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0660 - accuracy: 0.9809 - val_loss: 0.0610 - val_accuracy: 0.9825\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0636 - accuracy: 0.9819 - val_loss: 0.0596 - val_accuracy: 0.9822\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0614 - accuracy: 0.9821 - val_loss: 0.0574 - val_accuracy: 0.9840\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0597 - accuracy: 0.9826 - val_loss: 0.0594 - val_accuracy: 0.9820\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0576 - accuracy: 0.9834 - val_loss: 0.0559 - val_accuracy: 0.9843\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0555 - accuracy: 0.9843 - val_loss: 0.0549 - val_accuracy: 0.9843\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0538 - accuracy: 0.9844 - val_loss: 0.0573 - val_accuracy: 0.9843\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0524 - accuracy: 0.9848 - val_loss: 0.0599 - val_accuracy: 0.9822\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0506 - accuracy: 0.9850 - val_loss: 0.0509 - val_accuracy: 0.9868\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0489 - accuracy: 0.9860 - val_loss: 0.0507 - val_accuracy: 0.9868\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0474 - accuracy: 0.9866 - val_loss: 0.0514 - val_accuracy: 0.9850\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0461 - accuracy: 0.9869 - val_loss: 0.0493 - val_accuracy: 0.9858\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0445 - accuracy: 0.9873 - val_loss: 0.0498 - val_accuracy: 0.9868\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0431 - accuracy: 0.9880 - val_loss: 0.0516 - val_accuracy: 0.9855\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0429 - accuracy: 0.9878 - val_loss: 0.0475 - val_accuracy: 0.9885\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0407 - accuracy: 0.9886 - val_loss: 0.0496 - val_accuracy: 0.9862\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0402 - accuracy: 0.9890 - val_loss: 0.0488 - val_accuracy: 0.9872\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0394 - accuracy: 0.9890 - val_loss: 0.0466 - val_accuracy: 0.9865\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0386 - accuracy: 0.9891 - val_loss: 0.0467 - val_accuracy: 0.9875\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0369 - accuracy: 0.9894 - val_loss: 0.0480 - val_accuracy: 0.9862\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0362 - accuracy: 0.9900 - val_loss: 0.0466 - val_accuracy: 0.9878\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0344 - accuracy: 0.9903 - val_loss: 0.0455 - val_accuracy: 0.9875\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0338 - accuracy: 0.9905 - val_loss: 0.0473 - val_accuracy: 0.9872\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0330 - accuracy: 0.9910 - val_loss: 0.0449 - val_accuracy: 0.9877\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0324 - accuracy: 0.9911 - val_loss: 0.0451 - val_accuracy: 0.9873\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0310 - accuracy: 0.9914 - val_loss: 0.0460 - val_accuracy: 0.9880\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0305 - accuracy: 0.9918 - val_loss: 0.0458 - val_accuracy: 0.9883\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.0441 - val_accuracy: 0.9882\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.0433 - val_accuracy: 0.9877\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0281 - accuracy: 0.9921 - val_loss: 0.0438 - val_accuracy: 0.9890\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0277 - accuracy: 0.9925 - val_loss: 0.0426 - val_accuracy: 0.9887\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0267 - accuracy: 0.9926 - val_loss: 0.0429 - val_accuracy: 0.9875\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0258 - accuracy: 0.9932 - val_loss: 0.0440 - val_accuracy: 0.9875\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0255 - accuracy: 0.9931 - val_loss: 0.0434 - val_accuracy: 0.9883\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0242 - accuracy: 0.9934 - val_loss: 0.0438 - val_accuracy: 0.9882\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0241 - accuracy: 0.9938 - val_loss: 0.0448 - val_accuracy: 0.9867\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0446 - val_accuracy: 0.9873\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 0.0442 - val_accuracy: 0.9882\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 0.0424 - val_accuracy: 0.9883\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0216 - accuracy: 0.9945 - val_loss: 0.0421 - val_accuracy: 0.9872\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0211 - accuracy: 0.9949 - val_loss: 0.0438 - val_accuracy: 0.9880\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.0440 - val_accuracy: 0.9887\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0199 - accuracy: 0.9949 - val_loss: 0.0432 - val_accuracy: 0.9870\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.0415 - val_accuracy: 0.9877\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.0419 - val_accuracy: 0.9873\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0181 - accuracy: 0.9954 - val_loss: 0.0445 - val_accuracy: 0.9877\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0175 - accuracy: 0.9958 - val_loss: 0.0439 - val_accuracy: 0.9890\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0169 - accuracy: 0.9959 - val_loss: 0.0407 - val_accuracy: 0.9885\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.0403 - val_accuracy: 0.9890\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0161 - accuracy: 0.9963 - val_loss: 0.0435 - val_accuracy: 0.9883\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0158 - accuracy: 0.9960 - val_loss: 0.0422 - val_accuracy: 0.9880\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0158 - accuracy: 0.9964 - val_loss: 0.0416 - val_accuracy: 0.9885\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0150 - accuracy: 0.9965 - val_loss: 0.0401 - val_accuracy: 0.9877\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.0422 - val_accuracy: 0.9885\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0408 - val_accuracy: 0.9887\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 0.0434 - val_accuracy: 0.9878\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0133 - accuracy: 0.9972 - val_loss: 0.0444 - val_accuracy: 0.9880\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0132 - accuracy: 0.9970 - val_loss: 0.0424 - val_accuracy: 0.9878\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.0434 - val_accuracy: 0.9878\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0124 - accuracy: 0.9975 - val_loss: 0.0447 - val_accuracy: 0.9872\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0117 - accuracy: 0.9975 - val_loss: 0.0421 - val_accuracy: 0.9888\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.0452 - val_accuracy: 0.9877\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.0427 - val_accuracy: 0.9888\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.0422 - val_accuracy: 0.9887\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0105 - accuracy: 0.9982 - val_loss: 0.0425 - val_accuracy: 0.9868\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0102 - accuracy: 0.9981 - val_loss: 0.0419 - val_accuracy: 0.9880\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.0429 - val_accuracy: 0.9887\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.0432 - val_accuracy: 0.9883\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0435 - val_accuracy: 0.9875\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.0442 - val_accuracy: 0.9873\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0088 - accuracy: 0.9986 - val_loss: 0.0446 - val_accuracy: 0.9878\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0086 - accuracy: 0.9986 - val_loss: 0.0416 - val_accuracy: 0.9882\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0083 - accuracy: 0.9989 - val_loss: 0.0442 - val_accuracy: 0.9882\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.0448 - val_accuracy: 0.9873\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0078 - accuracy: 0.9990 - val_loss: 0.0442 - val_accuracy: 0.9880\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.0433 - val_accuracy: 0.9882\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.0437 - val_accuracy: 0.9882\n",
      "313/313 - 1s - loss: 0.0398 - accuracy: 0.9889\n",
      "testSetLoss: 0.039764538407325745 - testSetAccuracyz: 0.9889000058174133%\n"
     ]
    }
   ],
   "source": [
    "test1_512 = trainModel1(100, 512)\n",
    "hist_df = pd.DataFrame(test1_512.history)\n",
    "hist_json_file = 'test1_512.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0056 - accuracy: 0.9632 - val_loss: 0.0024 - val_accuracy: 0.9852\n",
      "Epoch 2/100\n",
      "27000/27000 [==============================] - 157s 6ms/step - loss: 0.0030 - accuracy: 0.9809 - val_loss: 0.0017 - val_accuracy: 0.9898\n",
      "Epoch 3/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0027 - accuracy: 0.9841 - val_loss: 0.0022 - val_accuracy: 0.9870\n",
      "Epoch 4/100\n",
      "27000/27000 [==============================] - 158s 6ms/step - loss: 0.0024 - accuracy: 0.9860 - val_loss: 0.0029 - val_accuracy: 0.9838\n",
      "Epoch 5/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0023 - accuracy: 0.9872 - val_loss: 0.0035 - val_accuracy: 0.9805\n",
      "Epoch 6/100\n",
      "27000/27000 [==============================] - 155s 6ms/step - loss: 0.0024 - accuracy: 0.9868 - val_loss: 0.0023 - val_accuracy: 0.9872\n",
      "Epoch 7/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0021 - accuracy: 0.9884 - val_loss: 0.0027 - val_accuracy: 0.9852\n",
      "Epoch 8/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0023 - accuracy: 0.9873 - val_loss: 0.0024 - val_accuracy: 0.9872\n",
      "Epoch 9/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0023 - accuracy: 0.9880 - val_loss: 0.0029 - val_accuracy: 0.9852\n",
      "Epoch 10/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0023 - accuracy: 0.9877 - val_loss: 0.0029 - val_accuracy: 0.9847\n",
      "Epoch 11/100\n",
      "27000/27000 [==============================] - 153s 6ms/step - loss: 0.0020 - accuracy: 0.9894 - val_loss: 0.0028 - val_accuracy: 0.9855\n",
      "Epoch 12/100\n",
      "27000/27000 [==============================] - 155s 6ms/step - loss: 0.0023 - accuracy: 0.9880 - val_loss: 0.0021 - val_accuracy: 0.9887\n",
      "Epoch 13/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0024 - accuracy: 0.9875 - val_loss: 0.0022 - val_accuracy: 0.9888\n",
      "Epoch 14/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0020 - accuracy: 0.9897 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 15/100\n",
      "27000/27000 [==============================] - 157s 6ms/step - loss: 0.0021 - accuracy: 0.9889 - val_loss: 0.0023 - val_accuracy: 0.9885\n",
      "Epoch 16/100\n",
      "27000/27000 [==============================] - 156s 6ms/step - loss: 0.0020 - accuracy: 0.9895 - val_loss: 0.0024 - val_accuracy: 0.9875\n",
      "Epoch 17/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0024 - accuracy: 0.9876 - val_loss: 0.0027 - val_accuracy: 0.9863\n",
      "Epoch 18/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0023 - accuracy: 0.9884 - val_loss: 0.0032 - val_accuracy: 0.9835\n",
      "Epoch 19/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0023 - accuracy: 0.9879 - val_loss: 0.0029 - val_accuracy: 0.9857\n",
      "Epoch 20/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0024 - accuracy: 0.9878 - val_loss: 0.0034 - val_accuracy: 0.9830\n",
      "Epoch 21/100\n",
      "27000/27000 [==============================] - 156s 6ms/step - loss: 0.0022 - accuracy: 0.9885 - val_loss: 0.0025 - val_accuracy: 0.9870\n",
      "Epoch 22/100\n",
      "27000/27000 [==============================] - 155s 6ms/step - loss: 0.0022 - accuracy: 0.9886 - val_loss: 0.0029 - val_accuracy: 0.9852\n",
      "Epoch 23/100\n",
      "27000/27000 [==============================] - 158s 6ms/step - loss: 0.0021 - accuracy: 0.9894 - val_loss: 0.0024 - val_accuracy: 0.9882\n",
      "Epoch 24/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0022 - accuracy: 0.9889 - val_loss: 0.0029 - val_accuracy: 0.9853\n",
      "Epoch 25/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0021 - accuracy: 0.9890 - val_loss: 0.0023 - val_accuracy: 0.9883\n",
      "Epoch 26/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0021 - accuracy: 0.9894 - val_loss: 0.0022 - val_accuracy: 0.9890\n",
      "Epoch 27/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0020 - accuracy: 0.9901 - val_loss: 0.0028 - val_accuracy: 0.9860\n",
      "Epoch 28/100\n",
      "27000/27000 [==============================] - 153s 6ms/step - loss: 0.0021 - accuracy: 0.9896 - val_loss: 0.0036 - val_accuracy: 0.9817\n",
      "Epoch 29/100\n",
      "27000/27000 [==============================] - 155s 6ms/step - loss: 0.0022 - accuracy: 0.9886 - val_loss: 0.0028 - val_accuracy: 0.9857\n",
      "Epoch 30/100\n",
      "27000/27000 [==============================] - 158s 6ms/step - loss: 0.0025 - accuracy: 0.9875 - val_loss: 0.0029 - val_accuracy: 0.9853\n",
      "Epoch 31/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0020 - accuracy: 0.9900 - val_loss: 0.0028 - val_accuracy: 0.9858\n",
      "Epoch 32/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0024 - accuracy: 0.9881 - val_loss: 0.0026 - val_accuracy: 0.9867\n",
      "Epoch 33/100\n",
      "27000/27000 [==============================] - 155s 6ms/step - loss: 0.0024 - accuracy: 0.9877 - val_loss: 0.0025 - val_accuracy: 0.9875\n",
      "Epoch 34/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0022 - accuracy: 0.9889 - val_loss: 0.0039 - val_accuracy: 0.9802\n",
      "Epoch 35/100\n",
      "27000/27000 [==============================] - 159s 6ms/step - loss: 0.0023 - accuracy: 0.9882 - val_loss: 0.0033 - val_accuracy: 0.9833\n",
      "Epoch 36/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0023 - accuracy: 0.9882 - val_loss: 0.0025 - val_accuracy: 0.9873\n",
      "Epoch 37/100\n",
      "27000/27000 [==============================] - 153s 6ms/step - loss: 0.0023 - accuracy: 0.9883 - val_loss: 0.0022 - val_accuracy: 0.9887\n",
      "Epoch 38/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0019 - accuracy: 0.9903 - val_loss: 0.0024 - val_accuracy: 0.9878\n",
      "Epoch 39/100\n",
      "27000/27000 [==============================] - 155s 6ms/step - loss: 0.0023 - accuracy: 0.9881 - val_loss: 0.0025 - val_accuracy: 0.9872\n",
      "Epoch 40/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0022 - accuracy: 0.9887 - val_loss: 0.0035 - val_accuracy: 0.9827\n",
      "Epoch 41/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0023 - accuracy: 0.9882 - val_loss: 0.0030 - val_accuracy: 0.9848\n",
      "Epoch 42/100\n",
      "27000/27000 [==============================] - 155s 6ms/step - loss: 0.0023 - accuracy: 0.9882 - val_loss: 0.0027 - val_accuracy: 0.9863\n",
      "Epoch 43/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0023 - accuracy: 0.9886 - val_loss: 0.0024 - val_accuracy: 0.9878\n",
      "Epoch 44/100\n",
      "27000/27000 [==============================] - 153s 6ms/step - loss: 0.0021 - accuracy: 0.9895 - val_loss: 0.0025 - val_accuracy: 0.9877\n",
      "Epoch 45/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0020 - accuracy: 0.9898 - val_loss: 0.0020 - val_accuracy: 0.9898\n",
      "Epoch 46/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0020 - accuracy: 0.9898 - val_loss: 0.0027 - val_accuracy: 0.9862\n",
      "Epoch 47/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0020 - accuracy: 0.9897 - val_loss: 0.0030 - val_accuracy: 0.9848\n",
      "Epoch 48/100\n",
      "27000/27000 [==============================] - 159s 6ms/step - loss: 0.0019 - accuracy: 0.9902 - val_loss: 0.0022 - val_accuracy: 0.9890\n",
      "Epoch 49/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0020 - accuracy: 0.9901 - val_loss: 0.0019 - val_accuracy: 0.9903\n",
      "Epoch 50/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0019 - accuracy: 0.9906 - val_loss: 0.0019 - val_accuracy: 0.9903\n",
      "Epoch 51/100\n",
      "27000/27000 [==============================] - 155s 6ms/step - loss: 0.0020 - accuracy: 0.9898 - val_loss: 0.0026 - val_accuracy: 0.9868\n",
      "Epoch 52/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0020 - accuracy: 0.9901 - val_loss: 0.0023 - val_accuracy: 0.9885\n",
      "Epoch 53/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0019 - accuracy: 0.9904 - val_loss: 0.0022 - val_accuracy: 0.9890\n",
      "Epoch 54/100\n",
      "27000/27000 [==============================] - 157s 6ms/step - loss: 0.0021 - accuracy: 0.9895 - val_loss: 0.0026 - val_accuracy: 0.9868\n",
      "Epoch 55/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0020 - accuracy: 0.9902 - val_loss: 0.0030 - val_accuracy: 0.9847\n",
      "Epoch 56/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0023 - accuracy: 0.9884 - val_loss: 0.0022 - val_accuracy: 0.9892\n",
      "Epoch 57/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0022 - accuracy: 0.9891 - val_loss: 0.0032 - val_accuracy: 0.9837\n",
      "Epoch 58/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0019 - accuracy: 0.9902 - val_loss: 0.0018 - val_accuracy: 0.9907\n",
      "Epoch 59/100\n",
      "27000/27000 [==============================] - 153s 6ms/step - loss: 0.0017 - accuracy: 0.9916 - val_loss: 0.0025 - val_accuracy: 0.9872\n",
      "Epoch 60/100\n",
      "27000/27000 [==============================] - 157s 6ms/step - loss: 0.0020 - accuracy: 0.9900 - val_loss: 0.0020 - val_accuracy: 0.9902\n",
      "Epoch 61/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0026 - accuracy: 0.9869 - val_loss: 0.0025 - val_accuracy: 0.9875\n",
      "Epoch 62/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0024 - accuracy: 0.9881 - val_loss: 0.0025 - val_accuracy: 0.9873\n",
      "Epoch 63/100\n",
      "27000/27000 [==============================] - 153s 6ms/step - loss: 0.0019 - accuracy: 0.9905 - val_loss: 0.0025 - val_accuracy: 0.9877\n",
      "Epoch 64/100\n",
      "27000/27000 [==============================] - 156s 6ms/step - loss: 0.0021 - accuracy: 0.9892 - val_loss: 0.0025 - val_accuracy: 0.9877\n",
      "Epoch 65/100\n",
      "27000/27000 [==============================] - 153s 6ms/step - loss: 0.0019 - accuracy: 0.9904 - val_loss: 0.0027 - val_accuracy: 0.9863\n",
      "Epoch 66/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0022 - accuracy: 0.9887 - val_loss: 0.0028 - val_accuracy: 0.9858\n",
      "Epoch 67/100\n",
      "27000/27000 [==============================] - 158s 6ms/step - loss: 0.0021 - accuracy: 0.9893 - val_loss: 0.0025 - val_accuracy: 0.9877\n",
      "Epoch 68/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0020 - accuracy: 0.9900 - val_loss: 0.0026 - val_accuracy: 0.9868\n",
      "Epoch 69/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0028 - accuracy: 0.9859 - val_loss: 0.0029 - val_accuracy: 0.9857\n",
      "Epoch 70/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0022 - accuracy: 0.9888 - val_loss: 0.0032 - val_accuracy: 0.9842\n",
      "Epoch 71/100\n",
      "27000/27000 [==============================] - 155s 6ms/step - loss: 0.0020 - accuracy: 0.9899 - val_loss: 0.0025 - val_accuracy: 0.9875\n",
      "Epoch 72/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0023 - accuracy: 0.9886 - val_loss: 0.0026 - val_accuracy: 0.9868\n",
      "Epoch 73/100\n",
      "27000/27000 [==============================] - 153s 6ms/step - loss: 0.0018 - accuracy: 0.9907 - val_loss: 0.0022 - val_accuracy: 0.9888\n",
      "Epoch 74/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0021 - accuracy: 0.9897 - val_loss: 0.0026 - val_accuracy: 0.9870\n",
      "Epoch 75/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0019 - accuracy: 0.9904 - val_loss: 0.0031 - val_accuracy: 0.9847\n",
      "Epoch 76/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0021 - accuracy: 0.9896 - val_loss: 0.0024 - val_accuracy: 0.9878\n",
      "Epoch 77/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0018 - accuracy: 0.9907 - val_loss: 0.0027 - val_accuracy: 0.9862\n",
      "Epoch 78/100\n",
      "27000/27000 [==============================] - 159s 6ms/step - loss: 0.0023 - accuracy: 0.9885 - val_loss: 0.0024 - val_accuracy: 0.9880\n",
      "Epoch 79/100\n",
      "27000/27000 [==============================] - 159s 6ms/step - loss: 0.0020 - accuracy: 0.9902 - val_loss: 0.0029 - val_accuracy: 0.9853\n",
      "Epoch 80/100\n",
      "27000/27000 [==============================] - 158s 6ms/step - loss: 0.0019 - accuracy: 0.9904 - val_loss: 0.0050 - val_accuracy: 0.9752\n",
      "Epoch 81/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0025 - accuracy: 0.9874 - val_loss: 0.0033 - val_accuracy: 0.9835\n",
      "Epoch 82/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0024 - accuracy: 0.9879 - val_loss: 0.0031 - val_accuracy: 0.9845\n",
      "Epoch 83/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 0.0024 - accuracy: 0.9880 - val_loss: 0.0031 - val_accuracy: 0.9843\n",
      "Epoch 84/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0022 - accuracy: 0.9891 - val_loss: 0.0033 - val_accuracy: 0.9837\n",
      "Epoch 85/100\n",
      "27000/27000 [==============================] - 147s 5ms/step - loss: 0.0018 - accuracy: 0.9909 - val_loss: 0.0022 - val_accuracy: 0.9888\n",
      "Epoch 86/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0017 - accuracy: 0.9912 - val_loss: 0.0020 - val_accuracy: 0.9902\n",
      "Epoch 87/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 0.0019 - accuracy: 0.9902 - val_loss: 0.0025 - val_accuracy: 0.9873\n",
      "Epoch 88/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0019 - accuracy: 0.9904 - val_loss: 0.0023 - val_accuracy: 0.9887\n",
      "Epoch 89/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0018 - accuracy: 0.9907 - val_loss: 0.0024 - val_accuracy: 0.9878\n",
      "Epoch 90/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0016 - accuracy: 0.9919 - val_loss: 0.0022 - val_accuracy: 0.9888\n",
      "Epoch 91/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0021 - accuracy: 0.9894 - val_loss: 0.0025 - val_accuracy: 0.9875\n",
      "Epoch 92/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0019 - accuracy: 0.9902 - val_loss: 0.0021 - val_accuracy: 0.9897\n",
      "Epoch 93/100\n",
      "27000/27000 [==============================] - 155s 6ms/step - loss: 0.0020 - accuracy: 0.9901 - val_loss: 0.0022 - val_accuracy: 0.9888\n",
      "Epoch 94/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 0.0017 - accuracy: 0.9916 - val_loss: 0.0027 - val_accuracy: 0.9863\n",
      "Epoch 95/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.0019 - accuracy: 0.9906 - val_loss: 0.0029 - val_accuracy: 0.9852\n",
      "Epoch 96/100\n",
      "27000/27000 [==============================] - 156s 6ms/step - loss: 0.0021 - accuracy: 0.9893 - val_loss: 0.0027 - val_accuracy: 0.9865\n",
      "Epoch 97/100\n",
      "27000/27000 [==============================] - 154s 6ms/step - loss: 0.0020 - accuracy: 0.9898 - val_loss: 0.0024 - val_accuracy: 0.9882\n",
      "Epoch 98/100\n",
      "27000/27000 [==============================] - 155s 6ms/step - loss: 0.0020 - accuracy: 0.9901 - val_loss: 0.0035 - val_accuracy: 0.9825\n",
      "Epoch 99/100\n",
      "27000/27000 [==============================] - 155s 6ms/step - loss: 0.0023 - accuracy: 0.9886 - val_loss: 0.0030 - val_accuracy: 0.9848\n",
      "Epoch 100/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 0.0025 - accuracy: 0.9877 - val_loss: 0.0025 - val_accuracy: 0.9877\n",
      "313/313 - 1s - loss: 0.0030 - accuracy: 0.9850\n",
      "testSetLoss: 0.0029948651790618896 - testSetAccuracyz: 0.9850000143051147%\n"
     ]
    }
   ],
   "source": [
    "test2_2 = trainModel2(100, 2)\n",
    "hist_df = pd.DataFrame(test2_2.history)\n",
    "hist_json_file = 'test2_2.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0062 - accuracy: 0.9585 - val_loss: 0.0025 - val_accuracy: 0.9835\n",
      "Epoch 2/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 0.0026 - accuracy: 0.9832 - val_loss: 0.0020 - val_accuracy: 0.9873\n",
      "Epoch 3/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 0.0019 - accuracy: 0.9884 - val_loss: 0.0019 - val_accuracy: 0.9880\n",
      "Epoch 4/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 0.0016 - accuracy: 0.9896 - val_loss: 0.0019 - val_accuracy: 0.9880\n",
      "Epoch 5/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 0.0013 - accuracy: 0.9916 - val_loss: 0.0015 - val_accuracy: 0.9908\n",
      "Epoch 6/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 0.0012 - accuracy: 0.9922 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 7/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 9.7233e-04 - accuracy: 0.9939 - val_loss: 0.0017 - val_accuracy: 0.9900\n",
      "Epoch 8/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 9.9918e-04 - accuracy: 0.9940 - val_loss: 0.0018 - val_accuracy: 0.9888\n",
      "Epoch 9/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 9.5319e-04 - accuracy: 0.9943 - val_loss: 0.0020 - val_accuracy: 0.9890\n",
      "Epoch 10/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 9.4754e-04 - accuracy: 0.9941 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 11/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 8.4293e-04 - accuracy: 0.9949 - val_loss: 0.0018 - val_accuracy: 0.9890\n",
      "Epoch 12/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 7.8912e-04 - accuracy: 0.9952 - val_loss: 0.0015 - val_accuracy: 0.9915\n",
      "Epoch 13/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 7.6129e-04 - accuracy: 0.9956 - val_loss: 0.0018 - val_accuracy: 0.9893\n",
      "Epoch 14/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 7.8419e-04 - accuracy: 0.9954 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 15/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 7.9751e-04 - accuracy: 0.9952 - val_loss: 0.0020 - val_accuracy: 0.9885\n",
      "Epoch 16/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 7.1160e-04 - accuracy: 0.9959 - val_loss: 0.0019 - val_accuracy: 0.9888\n",
      "Epoch 17/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.9437e-04 - accuracy: 0.9960 - val_loss: 0.0017 - val_accuracy: 0.9907\n",
      "Epoch 18/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 7.7460e-04 - accuracy: 0.9956 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 19/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.1405e-04 - accuracy: 0.9965 - val_loss: 0.0017 - val_accuracy: 0.9908\n",
      "Epoch 20/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.6675e-04 - accuracy: 0.9962 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 21/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.6754e-04 - accuracy: 0.9962 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 22/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.7869e-04 - accuracy: 0.9962 - val_loss: 0.0018 - val_accuracy: 0.9903\n",
      "Epoch 23/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 7.5674e-04 - accuracy: 0.9958 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 24/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.7164e-04 - accuracy: 0.9962 - val_loss: 0.0017 - val_accuracy: 0.9907\n",
      "Epoch 25/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.5422e-04 - accuracy: 0.9963 - val_loss: 0.0019 - val_accuracy: 0.9895\n",
      "Epoch 26/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.3745e-04 - accuracy: 0.9966 - val_loss: 0.0022 - val_accuracy: 0.9885\n",
      "Epoch 27/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 7.0013e-04 - accuracy: 0.9962 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 28/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 5.7455e-04 - accuracy: 0.9968 - val_loss: 0.0021 - val_accuracy: 0.9892\n",
      "Epoch 29/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 6.0130e-04 - accuracy: 0.9968 - val_loss: 0.0017 - val_accuracy: 0.9908\n",
      "Epoch 30/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.1511e-04 - accuracy: 0.9965 - val_loss: 0.0022 - val_accuracy: 0.9887\n",
      "Epoch 31/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.1997e-04 - accuracy: 0.9967 - val_loss: 0.0020 - val_accuracy: 0.9895\n",
      "Epoch 32/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 8.0484e-04 - accuracy: 0.9956 - val_loss: 0.0021 - val_accuracy: 0.9892\n",
      "Epoch 33/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.3626e-04 - accuracy: 0.9966 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 34/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.6491e-04 - accuracy: 0.9965 - val_loss: 0.0021 - val_accuracy: 0.9893\n",
      "Epoch 35/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 7.5420e-04 - accuracy: 0.9959 - val_loss: 0.0017 - val_accuracy: 0.9912\n",
      "Epoch 36/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.6759e-04 - accuracy: 0.9964 - val_loss: 0.0020 - val_accuracy: 0.9897\n",
      "Epoch 37/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.7401e-04 - accuracy: 0.9964 - val_loss: 0.0018 - val_accuracy: 0.9907\n",
      "Epoch 38/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.7827e-04 - accuracy: 0.9965 - val_loss: 0.0020 - val_accuracy: 0.9902\n",
      "Epoch 39/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.2067e-04 - accuracy: 0.9967 - val_loss: 0.0017 - val_accuracy: 0.9913\n",
      "Epoch 40/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 7.2797e-04 - accuracy: 0.9961 - val_loss: 0.0022 - val_accuracy: 0.9877\n",
      "Epoch 41/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.5362e-04 - accuracy: 0.9966 - val_loss: 0.0018 - val_accuracy: 0.9907\n",
      "Epoch 42/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.4945e-04 - accuracy: 0.9966 - val_loss: 0.0020 - val_accuracy: 0.9898\n",
      "Epoch 43/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 7.6237e-04 - accuracy: 0.9960 - val_loss: 0.0022 - val_accuracy: 0.9888\n",
      "Epoch 44/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 5.7684e-04 - accuracy: 0.9970 - val_loss: 0.0020 - val_accuracy: 0.9895\n",
      "Epoch 45/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.0867e-04 - accuracy: 0.9969 - val_loss: 0.0019 - val_accuracy: 0.9905\n",
      "Epoch 46/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 6.6933e-04 - accuracy: 0.9964 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 47/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.8078e-04 - accuracy: 0.9965 - val_loss: 0.0015 - val_accuracy: 0.9927\n",
      "Epoch 48/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 6.6983e-04 - accuracy: 0.9964 - val_loss: 0.0017 - val_accuracy: 0.9915\n",
      "Epoch 49/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 7.6315e-04 - accuracy: 0.9960 - val_loss: 0.0021 - val_accuracy: 0.9895\n",
      "Epoch 50/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 7.2859e-04 - accuracy: 0.9961 - val_loss: 0.0019 - val_accuracy: 0.9902\n",
      "Epoch 51/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 7.7769e-04 - accuracy: 0.9960 - val_loss: 0.0021 - val_accuracy: 0.9890\n",
      "Epoch 52/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 7.1740e-04 - accuracy: 0.9963 - val_loss: 0.0018 - val_accuracy: 0.9908\n",
      "Epoch 53/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 7.1389e-04 - accuracy: 0.9963 - val_loss: 0.0019 - val_accuracy: 0.9902\n",
      "Epoch 54/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.7588e-04 - accuracy: 0.9964 - val_loss: 0.0014 - val_accuracy: 0.9930\n",
      "Epoch 55/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 7.1125e-04 - accuracy: 0.9964 - val_loss: 0.0017 - val_accuracy: 0.9910\n",
      "Epoch 56/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 8.0273e-04 - accuracy: 0.9958 - val_loss: 0.0017 - val_accuracy: 0.9913\n",
      "Epoch 57/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.9976e-04 - accuracy: 0.9964 - val_loss: 0.0021 - val_accuracy: 0.9892\n",
      "Epoch 58/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.2491e-04 - accuracy: 0.9967 - val_loss: 0.0017 - val_accuracy: 0.9915\n",
      "Epoch 59/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 5.6815e-04 - accuracy: 0.9970 - val_loss: 0.0019 - val_accuracy: 0.9902\n",
      "Epoch 60/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.8702e-04 - accuracy: 0.9965 - val_loss: 0.0018 - val_accuracy: 0.9910\n",
      "Epoch 61/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 5.5593e-04 - accuracy: 0.9971 - val_loss: 0.0018 - val_accuracy: 0.9908\n",
      "Epoch 62/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.2551e-04 - accuracy: 0.9968 - val_loss: 0.0021 - val_accuracy: 0.9893\n",
      "Epoch 63/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 7.1249e-04 - accuracy: 0.9964 - val_loss: 0.0018 - val_accuracy: 0.9907\n",
      "Epoch 64/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 8.2431e-04 - accuracy: 0.9958 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 65/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 7.6278e-04 - accuracy: 0.9961 - val_loss: 0.0018 - val_accuracy: 0.9907\n",
      "Epoch 66/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 7.1167e-04 - accuracy: 0.9963 - val_loss: 0.0015 - val_accuracy: 0.9927\n",
      "Epoch 67/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.2846e-04 - accuracy: 0.9967 - val_loss: 0.0015 - val_accuracy: 0.9920\n",
      "Epoch 68/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 5.7120e-04 - accuracy: 0.9970 - val_loss: 0.0018 - val_accuracy: 0.9908\n",
      "Epoch 69/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.2394e-04 - accuracy: 0.9968 - val_loss: 0.0019 - val_accuracy: 0.9905\n",
      "Epoch 70/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 8.2535e-04 - accuracy: 0.9958 - val_loss: 0.0015 - val_accuracy: 0.9922\n",
      "Epoch 71/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 7.4013e-04 - accuracy: 0.9962 - val_loss: 0.0020 - val_accuracy: 0.9898\n",
      "Epoch 72/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 7.1687e-04 - accuracy: 0.9963 - val_loss: 0.0020 - val_accuracy: 0.9900\n",
      "Epoch 73/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.9912e-04 - accuracy: 0.9964 - val_loss: 0.0018 - val_accuracy: 0.9910\n",
      "Epoch 74/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.0057e-04 - accuracy: 0.9969 - val_loss: 0.0016 - val_accuracy: 0.9917\n",
      "Epoch 75/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 5.7874e-04 - accuracy: 0.9970 - val_loss: 0.0016 - val_accuracy: 0.9918\n",
      "Epoch 76/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 7.7507e-04 - accuracy: 0.9960 - val_loss: 0.0020 - val_accuracy: 0.9898\n",
      "Epoch 77/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 7.2525e-04 - accuracy: 0.9963 - val_loss: 0.0019 - val_accuracy: 0.9902\n",
      "Epoch 78/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 8.1229e-04 - accuracy: 0.9958 - val_loss: 0.0020 - val_accuracy: 0.9897\n",
      "Epoch 79/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 7.1046e-04 - accuracy: 0.9964 - val_loss: 0.0018 - val_accuracy: 0.9908\n",
      "Epoch 80/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 6.7133e-04 - accuracy: 0.9966 - val_loss: 0.0018 - val_accuracy: 0.9907\n",
      "Epoch 81/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 5.1749e-04 - accuracy: 0.9974 - val_loss: 0.0020 - val_accuracy: 0.9900\n",
      "Epoch 82/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 9.2015e-04 - accuracy: 0.9952 - val_loss: 0.0019 - val_accuracy: 0.9905\n",
      "Epoch 83/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.8831e-04 - accuracy: 0.9965 - val_loss: 0.0022 - val_accuracy: 0.9890\n",
      "Epoch 84/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.8539e-04 - accuracy: 0.9965 - val_loss: 0.0025 - val_accuracy: 0.9873\n",
      "Epoch 85/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.3760e-04 - accuracy: 0.9967 - val_loss: 0.0021 - val_accuracy: 0.9895\n",
      "Epoch 86/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 6.2236e-04 - accuracy: 0.9968 - val_loss: 0.0023 - val_accuracy: 0.9882\n",
      "Epoch 87/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 7.0632e-04 - accuracy: 0.9964 - val_loss: 0.0018 - val_accuracy: 0.9908\n",
      "Epoch 88/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 7.4458e-04 - accuracy: 0.9962 - val_loss: 0.0023 - val_accuracy: 0.9880\n",
      "Epoch 89/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.8510e-04 - accuracy: 0.9965 - val_loss: 0.0016 - val_accuracy: 0.9918\n",
      "Epoch 90/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 8.0405e-04 - accuracy: 0.9959 - val_loss: 0.0021 - val_accuracy: 0.9895\n",
      "Epoch 91/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 5.4669e-04 - accuracy: 0.9972 - val_loss: 0.0016 - val_accuracy: 0.9917\n",
      "Epoch 92/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 5.9848e-04 - accuracy: 0.9969 - val_loss: 0.0015 - val_accuracy: 0.9923\n",
      "Epoch 93/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 7.0589e-04 - accuracy: 0.9964 - val_loss: 0.0019 - val_accuracy: 0.9903\n",
      "Epoch 94/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 7.9410e-04 - accuracy: 0.9959 - val_loss: 0.0025 - val_accuracy: 0.9873\n",
      "Epoch 95/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 6.2546e-04 - accuracy: 0.9968 - val_loss: 0.0016 - val_accuracy: 0.9920\n",
      "Epoch 96/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.4539e-04 - accuracy: 0.9967 - val_loss: 0.0017 - val_accuracy: 0.9913\n",
      "Epoch 97/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.9802e-04 - accuracy: 0.9964 - val_loss: 0.0020 - val_accuracy: 0.9898\n",
      "Epoch 98/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 5.7192e-04 - accuracy: 0.9971 - val_loss: 0.0019 - val_accuracy: 0.9905\n",
      "Epoch 99/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 6.7883e-04 - accuracy: 0.9966 - val_loss: 0.0020 - val_accuracy: 0.9897\n",
      "Epoch 100/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 6.6026e-04 - accuracy: 0.9966 - val_loss: 0.0020 - val_accuracy: 0.9897\n",
      "313/313 - 1s - loss: 0.0025 - accuracy: 0.9875\n",
      "testSetLoss: 0.002489682286977768 - testSetAccuracyz: 0.987500011920929%\n"
     ]
    }
   ],
   "source": [
    "test2_8 = trainModel2(100, 8)\n",
    "hist_df = pd.DataFrame(test2_8.history)\n",
    "hist_json_file = 'test2_8.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0068 - accuracy: 0.9538 - val_loss: 0.0026 - val_accuracy: 0.9822\n",
      "Epoch 2/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0025 - accuracy: 0.9840 - val_loss: 0.0026 - val_accuracy: 0.9823\n",
      "Epoch 3/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0019 - accuracy: 0.9880 - val_loss: 0.0017 - val_accuracy: 0.9893\n",
      "Epoch 4/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 0.0014 - accuracy: 0.9909 - val_loss: 0.0017 - val_accuracy: 0.9890\n",
      "Epoch 5/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0012 - accuracy: 0.9922 - val_loss: 0.0017 - val_accuracy: 0.9893\n",
      "Epoch 6/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 0.0010 - accuracy: 0.9935 - val_loss: 0.0015 - val_accuracy: 0.9905\n",
      "Epoch 7/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 8.8616e-04 - accuracy: 0.9945 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 8/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 8.9479e-04 - accuracy: 0.9946 - val_loss: 0.0015 - val_accuracy: 0.9902\n",
      "Epoch 9/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 7.1541e-04 - accuracy: 0.9956 - val_loss: 0.0016 - val_accuracy: 0.9902\n",
      "Epoch 10/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 7.1016e-04 - accuracy: 0.9957 - val_loss: 0.0018 - val_accuracy: 0.9888\n",
      "Epoch 11/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 6.5507e-04 - accuracy: 0.9961 - val_loss: 0.0019 - val_accuracy: 0.9892\n",
      "Epoch 12/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 6.4553e-04 - accuracy: 0.9959 - val_loss: 0.0018 - val_accuracy: 0.9890\n",
      "Epoch 13/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 5.3007e-04 - accuracy: 0.9968 - val_loss: 0.0018 - val_accuracy: 0.9897\n",
      "Epoch 14/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 5.3554e-04 - accuracy: 0.9967 - val_loss: 0.0017 - val_accuracy: 0.9900\n",
      "Epoch 15/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 5.1225e-04 - accuracy: 0.9969 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 16/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 5.2547e-04 - accuracy: 0.9968 - val_loss: 0.0016 - val_accuracy: 0.9903\n",
      "Epoch 17/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 4.6258e-04 - accuracy: 0.9973 - val_loss: 0.0017 - val_accuracy: 0.9898\n",
      "Epoch 18/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 4.8505e-04 - accuracy: 0.9972 - val_loss: 0.0019 - val_accuracy: 0.9888\n",
      "Epoch 19/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 4.3318e-04 - accuracy: 0.9974 - val_loss: 0.0018 - val_accuracy: 0.9897\n",
      "Epoch 20/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 4.4361e-04 - accuracy: 0.9974 - val_loss: 0.0015 - val_accuracy: 0.9917\n",
      "Epoch 21/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.7967e-04 - accuracy: 0.9978 - val_loss: 0.0020 - val_accuracy: 0.9883\n",
      "Epoch 22/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 4.9181e-04 - accuracy: 0.9970 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 23/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.7732e-04 - accuracy: 0.9978 - val_loss: 0.0017 - val_accuracy: 0.9903\n",
      "Epoch 24/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.7462e-04 - accuracy: 0.9978 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 25/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.7795e-04 - accuracy: 0.9978 - val_loss: 0.0016 - val_accuracy: 0.9910\n",
      "Epoch 26/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.6899e-04 - accuracy: 0.9978 - val_loss: 0.0018 - val_accuracy: 0.9898\n",
      "Epoch 27/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.9351e-04 - accuracy: 0.9976 - val_loss: 0.0016 - val_accuracy: 0.9910\n",
      "Epoch 28/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 4.3416e-04 - accuracy: 0.9975 - val_loss: 0.0017 - val_accuracy: 0.9908\n",
      "Epoch 29/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.6588e-04 - accuracy: 0.9978 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 30/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.4257e-04 - accuracy: 0.9980 - val_loss: 0.0017 - val_accuracy: 0.9908\n",
      "Epoch 31/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.4353e-04 - accuracy: 0.9980 - val_loss: 0.0020 - val_accuracy: 0.9888\n",
      "Epoch 32/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.7032e-04 - accuracy: 0.9979 - val_loss: 0.0014 - val_accuracy: 0.9918\n",
      "Epoch 33/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 3.4132e-04 - accuracy: 0.9980 - val_loss: 0.0017 - val_accuracy: 0.9907\n",
      "Epoch 34/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 3.3108e-04 - accuracy: 0.9981 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 35/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.2103e-04 - accuracy: 0.9981 - val_loss: 0.0019 - val_accuracy: 0.9898\n",
      "Epoch 36/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 2.8917e-04 - accuracy: 0.9984 - val_loss: 0.0017 - val_accuracy: 0.9908\n",
      "Epoch 37/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 2.9788e-04 - accuracy: 0.9983 - val_loss: 0.0017 - val_accuracy: 0.9903\n",
      "Epoch 38/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 3.8696e-04 - accuracy: 0.9978 - val_loss: 0.0018 - val_accuracy: 0.9903\n",
      "Epoch 39/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 2.5700e-04 - accuracy: 0.9985 - val_loss: 0.0015 - val_accuracy: 0.9918\n",
      "Epoch 40/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 4.0980e-04 - accuracy: 0.9976 - val_loss: 0.0018 - val_accuracy: 0.9908\n",
      "Epoch 41/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 2.9722e-04 - accuracy: 0.9984 - val_loss: 0.0022 - val_accuracy: 0.9882\n",
      "Epoch 42/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.7926e-04 - accuracy: 0.9978 - val_loss: 0.0021 - val_accuracy: 0.9888\n",
      "Epoch 43/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.2417e-04 - accuracy: 0.9981 - val_loss: 0.0019 - val_accuracy: 0.9898\n",
      "Epoch 44/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.6584e-04 - accuracy: 0.9980 - val_loss: 0.0018 - val_accuracy: 0.9903\n",
      "Epoch 45/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.6184e-04 - accuracy: 0.9979 - val_loss: 0.0019 - val_accuracy: 0.9895\n",
      "Epoch 46/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 2.9667e-04 - accuracy: 0.9983 - val_loss: 0.0020 - val_accuracy: 0.9898\n",
      "Epoch 47/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.7020e-04 - accuracy: 0.9980 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 48/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.0540e-04 - accuracy: 0.9983 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 49/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.1686e-04 - accuracy: 0.9982 - val_loss: 0.0019 - val_accuracy: 0.9898\n",
      "Epoch 50/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 2.8636e-04 - accuracy: 0.9983 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 51/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.5081e-04 - accuracy: 0.9980 - val_loss: 0.0020 - val_accuracy: 0.9895\n",
      "Epoch 52/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.1158e-04 - accuracy: 0.9983 - val_loss: 0.0017 - val_accuracy: 0.9907\n",
      "Epoch 53/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.2493e-04 - accuracy: 0.9983 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 54/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 2.5484e-04 - accuracy: 0.9986 - val_loss: 0.0019 - val_accuracy: 0.9903\n",
      "Epoch 55/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.1995e-04 - accuracy: 0.9983 - val_loss: 0.0020 - val_accuracy: 0.9895\n",
      "Epoch 56/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.0417e-04 - accuracy: 0.9983 - val_loss: 0.0018 - val_accuracy: 0.9898\n",
      "Epoch 57/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.9990e-04 - accuracy: 0.9978 - val_loss: 0.0021 - val_accuracy: 0.9892\n",
      "Epoch 58/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.0917e-04 - accuracy: 0.9983 - val_loss: 0.0019 - val_accuracy: 0.9900\n",
      "Epoch 59/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.3314e-04 - accuracy: 0.9982 - val_loss: 0.0015 - val_accuracy: 0.9918\n",
      "Epoch 60/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.4702e-04 - accuracy: 0.9980 - val_loss: 0.0020 - val_accuracy: 0.9898\n",
      "Epoch 61/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 2.9632e-04 - accuracy: 0.9983 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 62/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.2706e-04 - accuracy: 0.9982 - val_loss: 0.0019 - val_accuracy: 0.9898\n",
      "Epoch 63/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.1662e-04 - accuracy: 0.9983 - val_loss: 0.0017 - val_accuracy: 0.9912\n",
      "Epoch 64/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.4277e-04 - accuracy: 0.9981 - val_loss: 0.0017 - val_accuracy: 0.9915\n",
      "Epoch 65/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 4.1624e-04 - accuracy: 0.9977 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 66/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.1675e-04 - accuracy: 0.9983 - val_loss: 0.0019 - val_accuracy: 0.9903\n",
      "Epoch 67/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.3481e-04 - accuracy: 0.9982 - val_loss: 0.0018 - val_accuracy: 0.9907\n",
      "Epoch 68/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 2.9802e-04 - accuracy: 0.9984 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 69/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.1336e-04 - accuracy: 0.9984 - val_loss: 0.0021 - val_accuracy: 0.9892\n",
      "Epoch 70/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.0336e-04 - accuracy: 0.9984 - val_loss: 0.0019 - val_accuracy: 0.9897\n",
      "Epoch 71/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.6114e-04 - accuracy: 0.9981 - val_loss: 0.0017 - val_accuracy: 0.9910\n",
      "Epoch 72/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 3.0964e-04 - accuracy: 0.9984 - val_loss: 0.0020 - val_accuracy: 0.9898\n",
      "Epoch 73/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.0408e-04 - accuracy: 0.9983 - val_loss: 0.0020 - val_accuracy: 0.9898\n",
      "Epoch 74/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 2.5259e-04 - accuracy: 0.9986 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 75/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.0032e-04 - accuracy: 0.9984 - val_loss: 0.0022 - val_accuracy: 0.9887\n",
      "Epoch 76/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 2.9704e-04 - accuracy: 0.9984 - val_loss: 0.0021 - val_accuracy: 0.9893\n",
      "Epoch 77/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.5929e-04 - accuracy: 0.9980 - val_loss: 0.0019 - val_accuracy: 0.9903\n",
      "Epoch 78/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 2.9742e-04 - accuracy: 0.9984 - val_loss: 0.0022 - val_accuracy: 0.9883\n",
      "Epoch 79/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 3.0835e-04 - accuracy: 0.9983 - val_loss: 0.0018 - val_accuracy: 0.9908\n",
      "Epoch 80/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 2.3775e-04 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9912\n",
      "Epoch 81/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.4853e-04 - accuracy: 0.9981 - val_loss: 0.0019 - val_accuracy: 0.9905\n",
      "Epoch 82/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 2.6953e-04 - accuracy: 0.9986 - val_loss: 0.0019 - val_accuracy: 0.9902\n",
      "Epoch 83/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 2.9928e-04 - accuracy: 0.9984 - val_loss: 0.0017 - val_accuracy: 0.9917\n",
      "Epoch 84/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.7214e-04 - accuracy: 0.9979 - val_loss: 0.0018 - val_accuracy: 0.9908\n",
      "Epoch 85/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 2.7834e-04 - accuracy: 0.9985 - val_loss: 0.0015 - val_accuracy: 0.9922\n",
      "Epoch 86/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 2.8517e-04 - accuracy: 0.9985 - val_loss: 0.0017 - val_accuracy: 0.9912\n",
      "Epoch 87/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.9459e-04 - accuracy: 0.9979 - val_loss: 0.0019 - val_accuracy: 0.9898\n",
      "Epoch 88/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.1996e-04 - accuracy: 0.9983 - val_loss: 0.0018 - val_accuracy: 0.9907\n",
      "Epoch 89/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 2.7313e-04 - accuracy: 0.9986 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 90/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 2.6965e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9910\n",
      "Epoch 91/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.4263e-04 - accuracy: 0.9982 - val_loss: 0.0019 - val_accuracy: 0.9900\n",
      "Epoch 92/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.5077e-04 - accuracy: 0.9982 - val_loss: 0.0015 - val_accuracy: 0.9925\n",
      "Epoch 93/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.4658e-04 - accuracy: 0.9982 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 94/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.6838e-04 - accuracy: 0.9981 - val_loss: 0.0015 - val_accuracy: 0.9923\n",
      "Epoch 95/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.7077e-04 - accuracy: 0.9981 - val_loss: 0.0018 - val_accuracy: 0.9908\n",
      "Epoch 96/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.3485e-04 - accuracy: 0.9982 - val_loss: 0.0019 - val_accuracy: 0.9903\n",
      "Epoch 97/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 2.5924e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9917\n",
      "Epoch 98/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 3.2468e-04 - accuracy: 0.9983 - val_loss: 0.0016 - val_accuracy: 0.9917\n",
      "Epoch 99/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 3.3567e-04 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9918\n",
      "Epoch 100/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 2.7040e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9913\n",
      "313/313 - 1s - loss: 0.0019 - accuracy: 0.9902\n",
      "testSetLoss: 0.00187375966925174 - testSetAccuracyz: 0.9901999831199646%\n"
     ]
    }
   ],
   "source": [
    "test2_16 = trainModel2(100, 16)\n",
    "hist_df = pd.DataFrame(test2_16.history)\n",
    "hist_json_file = 'test2_16.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0081 - accuracy: 0.9456 - val_loss: 0.0027 - val_accuracy: 0.9833\n",
      "Epoch 2/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0030 - accuracy: 0.9809 - val_loss: 0.0021 - val_accuracy: 0.9863\n",
      "Epoch 3/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0022 - accuracy: 0.9862 - val_loss: 0.0017 - val_accuracy: 0.9890\n",
      "Epoch 4/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0017 - accuracy: 0.9886 - val_loss: 0.0016 - val_accuracy: 0.9895\n",
      "Epoch 5/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0015 - accuracy: 0.9906 - val_loss: 0.0016 - val_accuracy: 0.9897\n",
      "Epoch 6/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0012 - accuracy: 0.9922 - val_loss: 0.0014 - val_accuracy: 0.9908\n",
      "Epoch 7/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0011 - accuracy: 0.9934 - val_loss: 0.0013 - val_accuracy: 0.9903\n",
      "Epoch 8/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 8.4399e-04 - accuracy: 0.9948 - val_loss: 0.0015 - val_accuracy: 0.9897\n",
      "Epoch 9/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 7.8093e-04 - accuracy: 0.9951 - val_loss: 0.0017 - val_accuracy: 0.9897\n",
      "Epoch 10/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 6.9446e-04 - accuracy: 0.9958 - val_loss: 0.0015 - val_accuracy: 0.9905\n",
      "Epoch 11/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 6.1599e-04 - accuracy: 0.9964 - val_loss: 0.0014 - val_accuracy: 0.9913\n",
      "Epoch 12/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 5.7629e-04 - accuracy: 0.9964 - val_loss: 0.0015 - val_accuracy: 0.9905\n",
      "Epoch 13/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 5.1397e-04 - accuracy: 0.9969 - val_loss: 0.0015 - val_accuracy: 0.9908\n",
      "Epoch 14/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 5.2290e-04 - accuracy: 0.9968 - val_loss: 0.0014 - val_accuracy: 0.9915\n",
      "Epoch 15/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 4.8318e-04 - accuracy: 0.9969 - val_loss: 0.0016 - val_accuracy: 0.9903\n",
      "Epoch 16/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 4.1957e-04 - accuracy: 0.9975 - val_loss: 0.0016 - val_accuracy: 0.9907\n",
      "Epoch 17/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 4.6121e-04 - accuracy: 0.9971 - val_loss: 0.0016 - val_accuracy: 0.9903\n",
      "Epoch 18/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.7969e-04 - accuracy: 0.9978 - val_loss: 0.0014 - val_accuracy: 0.9915\n",
      "Epoch 19/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 4.4989e-04 - accuracy: 0.9972 - val_loss: 0.0015 - val_accuracy: 0.9913\n",
      "Epoch 20/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.6130e-04 - accuracy: 0.9978 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 21/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.4061e-04 - accuracy: 0.9979 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 22/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.8787e-04 - accuracy: 0.9977 - val_loss: 0.0013 - val_accuracy: 0.9923\n",
      "Epoch 23/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.5928e-04 - accuracy: 0.9978 - val_loss: 0.0014 - val_accuracy: 0.9920\n",
      "Epoch 24/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.3431e-04 - accuracy: 0.9980 - val_loss: 0.0014 - val_accuracy: 0.9925\n",
      "Epoch 25/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.6335e-04 - accuracy: 0.9978 - val_loss: 0.0014 - val_accuracy: 0.9917\n",
      "Epoch 26/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.1468e-04 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9902\n",
      "Epoch 27/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.3249e-04 - accuracy: 0.9979 - val_loss: 0.0015 - val_accuracy: 0.9915\n",
      "Epoch 28/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.1619e-04 - accuracy: 0.9981 - val_loss: 0.0017 - val_accuracy: 0.9903\n",
      "Epoch 29/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.4146e-04 - accuracy: 0.9979 - val_loss: 0.0013 - val_accuracy: 0.9928\n",
      "Epoch 30/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.5359e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 31/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.9558e-04 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 32/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.9288e-04 - accuracy: 0.9983 - val_loss: 0.0013 - val_accuracy: 0.9923\n",
      "Epoch 33/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.6769e-04 - accuracy: 0.9985 - val_loss: 0.0014 - val_accuracy: 0.9922\n",
      "Epoch 34/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.0605e-04 - accuracy: 0.9982 - val_loss: 0.0015 - val_accuracy: 0.9920\n",
      "Epoch 35/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.7064e-04 - accuracy: 0.9984 - val_loss: 0.0015 - val_accuracy: 0.9923\n",
      "Epoch 36/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.9177e-04 - accuracy: 0.9982 - val_loss: 0.0017 - val_accuracy: 0.9902\n",
      "Epoch 37/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.6277e-04 - accuracy: 0.9984 - val_loss: 0.0016 - val_accuracy: 0.9910\n",
      "Epoch 38/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.2113e-04 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9907\n",
      "Epoch 39/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.8288e-04 - accuracy: 0.9983 - val_loss: 0.0017 - val_accuracy: 0.9902\n",
      "Epoch 40/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.1957e-04 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9907\n",
      "Epoch 41/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.8815e-04 - accuracy: 0.9982 - val_loss: 0.0014 - val_accuracy: 0.9920\n",
      "Epoch 42/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.4882e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 43/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.3111e-04 - accuracy: 0.9987 - val_loss: 0.0018 - val_accuracy: 0.9897\n",
      "Epoch 44/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 3.2684e-04 - accuracy: 0.9981 - val_loss: 0.0013 - val_accuracy: 0.9930\n",
      "Epoch 45/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 1.9360e-04 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 0.9915\n",
      "Epoch 46/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.3110e-04 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 47/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.6125e-04 - accuracy: 0.9985 - val_loss: 0.0018 - val_accuracy: 0.9900\n",
      "Epoch 48/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.5623e-04 - accuracy: 0.9985 - val_loss: 0.0019 - val_accuracy: 0.9903\n",
      "Epoch 49/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.0665e-04 - accuracy: 0.9989 - val_loss: 0.0018 - val_accuracy: 0.9895\n",
      "Epoch 50/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.5015e-04 - accuracy: 0.9985 - val_loss: 0.0015 - val_accuracy: 0.9918\n",
      "Epoch 51/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.1407e-04 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 52/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.0228e-04 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 53/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.6139e-04 - accuracy: 0.9985 - val_loss: 0.0014 - val_accuracy: 0.9922\n",
      "Epoch 54/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.6079e-04 - accuracy: 0.9985 - val_loss: 0.0018 - val_accuracy: 0.9900\n",
      "Epoch 55/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.0259e-04 - accuracy: 0.9989 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 56/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.1724e-04 - accuracy: 0.9987 - val_loss: 0.0018 - val_accuracy: 0.9903\n",
      "Epoch 57/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.6457e-04 - accuracy: 0.9985 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 58/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.5677e-04 - accuracy: 0.9985 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 59/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.4409e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 60/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.4736e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9907\n",
      "Epoch 61/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.1654e-04 - accuracy: 0.9988 - val_loss: 0.0018 - val_accuracy: 0.9902\n",
      "Epoch 62/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 1.7416e-04 - accuracy: 0.9991 - val_loss: 0.0021 - val_accuracy: 0.9882\n",
      "Epoch 63/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.7145e-04 - accuracy: 0.9985 - val_loss: 0.0015 - val_accuracy: 0.9922\n",
      "Epoch 64/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.3812e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9917\n",
      "Epoch 65/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.4648e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9910\n",
      "Epoch 66/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 1.9587e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 67/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.0368e-04 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9910\n",
      "Epoch 68/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.3742e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 69/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.0574e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 70/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 1.8806e-04 - accuracy: 0.9990 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 71/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 1.6020e-04 - accuracy: 0.9991 - val_loss: 0.0015 - val_accuracy: 0.9913\n",
      "Epoch 72/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.2357e-04 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 73/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.5527e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 74/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 1.6191e-04 - accuracy: 0.9991 - val_loss: 0.0015 - val_accuracy: 0.9920\n",
      "Epoch 75/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 1.8855e-04 - accuracy: 0.9989 - val_loss: 0.0020 - val_accuracy: 0.9895\n",
      "Epoch 76/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.3440e-04 - accuracy: 0.9987 - val_loss: 0.0015 - val_accuracy: 0.9927\n",
      "Epoch 77/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 1.9601e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9910\n",
      "Epoch 78/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.2505e-04 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9918\n",
      "Epoch 79/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.1783e-04 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 80/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.5672e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 81/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.0295e-04 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 0.9915\n",
      "Epoch 82/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 1.7622e-04 - accuracy: 0.9991 - val_loss: 0.0015 - val_accuracy: 0.9922\n",
      "Epoch 83/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.3995e-04 - accuracy: 0.9987 - val_loss: 0.0018 - val_accuracy: 0.9903\n",
      "Epoch 84/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.0594e-04 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 0.9922\n",
      "Epoch 85/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.5265e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9912\n",
      "Epoch 86/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 1.9284e-04 - accuracy: 0.9990 - val_loss: 0.0020 - val_accuracy: 0.9898\n",
      "Epoch 87/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.7393e-04 - accuracy: 0.9985 - val_loss: 0.0013 - val_accuracy: 0.9932\n",
      "Epoch 88/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 1.8509e-04 - accuracy: 0.9991 - val_loss: 0.0015 - val_accuracy: 0.9922\n",
      "Epoch 89/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 2.1673e-04 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9917\n",
      "Epoch 90/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 1.9212e-04 - accuracy: 0.9990 - val_loss: 0.0015 - val_accuracy: 0.9917\n",
      "Epoch 91/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.4125e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 92/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 2.1274e-04 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 0.9918\n",
      "Epoch 93/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 1.4284e-04 - accuracy: 0.9993 - val_loss: 0.0019 - val_accuracy: 0.9902\n",
      "Epoch 94/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.1920e-04 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9912\n",
      "Epoch 95/100\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 2.8450e-04 - accuracy: 0.9984 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 96/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 2.1110e-04 - accuracy: 0.9988 - val_loss: 0.0015 - val_accuracy: 0.9927\n",
      "Epoch 97/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 1.9675e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9920\n",
      "Epoch 98/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 2.5130e-04 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 0.9925\n",
      "Epoch 99/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 1.7178e-04 - accuracy: 0.9991 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 100/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 2.5867e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9913\n",
      "313/313 - 1s - loss: 0.0016 - accuracy: 0.9913\n",
      "testSetLoss: 0.001642534276470542 - testSetAccuracyz: 0.9912999868392944%\n"
     ]
    }
   ],
   "source": [
    "test2_32 = trainModel2(100, 32)\n",
    "hist_df = pd.DataFrame(test2_32.history)\n",
    "hist_json_file = 'test2_32.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 0.0103 - accuracy: 0.9304 - val_loss: 0.0033 - val_accuracy: 0.9780\n",
      "Epoch 2/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 0.0034 - accuracy: 0.9784 - val_loss: 0.0027 - val_accuracy: 0.9830\n",
      "Epoch 3/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 0.0025 - accuracy: 0.9843 - val_loss: 0.0021 - val_accuracy: 0.9870\n",
      "Epoch 4/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 0.0020 - accuracy: 0.9873 - val_loss: 0.0020 - val_accuracy: 0.9863\n",
      "Epoch 5/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0017 - accuracy: 0.9893 - val_loss: 0.0019 - val_accuracy: 0.9867\n",
      "Epoch 6/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 0.0014 - accuracy: 0.9912 - val_loss: 0.0023 - val_accuracy: 0.9853\n",
      "Epoch 7/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 0.0013 - accuracy: 0.9921 - val_loss: 0.0017 - val_accuracy: 0.9895\n",
      "Epoch 8/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0011 - accuracy: 0.9936 - val_loss: 0.0016 - val_accuracy: 0.9893\n",
      "Epoch 9/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 9.9947e-04 - accuracy: 0.9937 - val_loss: 0.0016 - val_accuracy: 0.9900\n",
      "Epoch 10/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 8.6838e-04 - accuracy: 0.9948 - val_loss: 0.0018 - val_accuracy: 0.9892\n",
      "Epoch 11/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 7.4635e-04 - accuracy: 0.9955 - val_loss: 0.0016 - val_accuracy: 0.9895\n",
      "Epoch 12/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 6.5950e-04 - accuracy: 0.9960 - val_loss: 0.0015 - val_accuracy: 0.9910\n",
      "Epoch 13/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 5.9790e-04 - accuracy: 0.9964 - val_loss: 0.0014 - val_accuracy: 0.9912\n",
      "Epoch 14/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 5.6676e-04 - accuracy: 0.9965 - val_loss: 0.0016 - val_accuracy: 0.9898\n",
      "Epoch 15/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 5.0268e-04 - accuracy: 0.9969 - val_loss: 0.0018 - val_accuracy: 0.9893\n",
      "Epoch 16/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 4.9011e-04 - accuracy: 0.9970 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 17/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 4.8260e-04 - accuracy: 0.9971 - val_loss: 0.0021 - val_accuracy: 0.9873\n",
      "Epoch 18/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 4.2898e-04 - accuracy: 0.9975 - val_loss: 0.0015 - val_accuracy: 0.9907\n",
      "Epoch 19/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 3.3754e-04 - accuracy: 0.9981 - val_loss: 0.0017 - val_accuracy: 0.9895\n",
      "Epoch 20/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 3.7510e-04 - accuracy: 0.9978 - val_loss: 0.0017 - val_accuracy: 0.9898\n",
      "Epoch 21/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 3.9871e-04 - accuracy: 0.9976 - val_loss: 0.0017 - val_accuracy: 0.9895\n",
      "Epoch 22/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 3.4881e-04 - accuracy: 0.9980 - val_loss: 0.0017 - val_accuracy: 0.9900\n",
      "Epoch 23/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 3.0529e-04 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9903\n",
      "Epoch 24/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 3.5886e-04 - accuracy: 0.9978 - val_loss: 0.0014 - val_accuracy: 0.9912\n",
      "Epoch 25/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.9531e-04 - accuracy: 0.9982 - val_loss: 0.0014 - val_accuracy: 0.9913\n",
      "Epoch 26/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 3.2120e-04 - accuracy: 0.9981 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 27/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.9565e-04 - accuracy: 0.9983 - val_loss: 0.0014 - val_accuracy: 0.9918\n",
      "Epoch 28/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.5340e-04 - accuracy: 0.9985 - val_loss: 0.0016 - val_accuracy: 0.9907\n",
      "Epoch 29/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 3.3671e-04 - accuracy: 0.9980 - val_loss: 0.0019 - val_accuracy: 0.9885\n",
      "Epoch 30/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.3358e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9900\n",
      "Epoch 31/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.8675e-04 - accuracy: 0.9984 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 32/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.8455e-04 - accuracy: 0.9983 - val_loss: 0.0020 - val_accuracy: 0.9878\n",
      "Epoch 33/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.6376e-04 - accuracy: 0.9984 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 34/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 2.8274e-04 - accuracy: 0.9983 - val_loss: 0.0017 - val_accuracy: 0.9902\n",
      "Epoch 35/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.5719e-04 - accuracy: 0.9986 - val_loss: 0.0014 - val_accuracy: 0.9917\n",
      "Epoch 36/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.5347e-04 - accuracy: 0.9985 - val_loss: 0.0015 - val_accuracy: 0.9910\n",
      "Epoch 37/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.9202e-04 - accuracy: 0.9989 - val_loss: 0.0014 - val_accuracy: 0.9925\n",
      "Epoch 38/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 3.2075e-04 - accuracy: 0.9980 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 39/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 2.6768e-04 - accuracy: 0.9983 - val_loss: 0.0013 - val_accuracy: 0.9925\n",
      "Epoch 40/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 1.9517e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9910\n",
      "Epoch 41/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.1126e-04 - accuracy: 0.9988 - val_loss: 0.0015 - val_accuracy: 0.9915\n",
      "Epoch 42/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 3.1539e-04 - accuracy: 0.9981 - val_loss: 0.0016 - val_accuracy: 0.9903\n",
      "Epoch 43/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.1070e-04 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9907\n",
      "Epoch 44/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.2542e-04 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 45/100\n",
      "844/844 [==============================] - 8s 10ms/step - loss: 1.9920e-04 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9895\n",
      "Epoch 46/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.2600e-04 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 0.9913\n",
      "Epoch 47/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.9859e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9903\n",
      "Epoch 48/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.1160e-04 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 49/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 2.5741e-04 - accuracy: 0.9985 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 50/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.9864e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9910\n",
      "Epoch 51/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.9887e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 52/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.2189e-04 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 53/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.5533e-04 - accuracy: 0.9984 - val_loss: 0.0019 - val_accuracy: 0.9892\n",
      "Epoch 54/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.0061e-04 - accuracy: 0.9989 - val_loss: 0.0018 - val_accuracy: 0.9900\n",
      "Epoch 55/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.0702e-04 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 56/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.8271e-04 - accuracy: 0.9990 - val_loss: 0.0015 - val_accuracy: 0.9920\n",
      "Epoch 57/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.2819e-04 - accuracy: 0.9987 - val_loss: 0.0018 - val_accuracy: 0.9898\n",
      "Epoch 58/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.0945e-04 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9907\n",
      "Epoch 59/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.1246e-04 - accuracy: 0.9988 - val_loss: 0.0019 - val_accuracy: 0.9893\n",
      "Epoch 60/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.0785e-04 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 61/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 1.3471e-04 - accuracy: 0.9993 - val_loss: 0.0017 - val_accuracy: 0.9893\n",
      "Epoch 62/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.3744e-04 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 0.9915\n",
      "Epoch 63/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.4732e-04 - accuracy: 0.9985 - val_loss: 0.0017 - val_accuracy: 0.9907\n",
      "Epoch 64/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.7818e-04 - accuracy: 0.9990 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 65/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.1497e-04 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9908\n",
      "Epoch 66/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.3390e-04 - accuracy: 0.9986 - val_loss: 0.0018 - val_accuracy: 0.9905\n",
      "Epoch 67/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.6396e-04 - accuracy: 0.9991 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 68/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 1.4426e-04 - accuracy: 0.9992 - val_loss: 0.0017 - val_accuracy: 0.9910\n",
      "Epoch 69/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.8439e-04 - accuracy: 0.9990 - val_loss: 0.0015 - val_accuracy: 0.9920\n",
      "Epoch 70/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.5842e-04 - accuracy: 0.9985 - val_loss: 0.0015 - val_accuracy: 0.9915\n",
      "Epoch 71/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.2796e-04 - accuracy: 0.9987 - val_loss: 0.0018 - val_accuracy: 0.9902\n",
      "Epoch 72/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.3379e-04 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9910\n",
      "Epoch 73/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.7770e-04 - accuracy: 0.9990 - val_loss: 0.0016 - val_accuracy: 0.9915\n",
      "Epoch 74/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.0225e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 75/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.9969e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 76/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.1267e-04 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 77/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.0302e-04 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 78/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.6886e-04 - accuracy: 0.9991 - val_loss: 0.0017 - val_accuracy: 0.9908\n",
      "Epoch 79/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.5547e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9907\n",
      "Epoch 80/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.2454e-04 - accuracy: 0.9987 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 81/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 1.7179e-04 - accuracy: 0.9990 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 82/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.9746e-04 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9903\n",
      "Epoch 83/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.9546e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 84/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.9899e-04 - accuracy: 0.9989 - val_loss: 0.0019 - val_accuracy: 0.9887\n",
      "Epoch 85/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 1.7439e-04 - accuracy: 0.9991 - val_loss: 0.0015 - val_accuracy: 0.9913\n",
      "Epoch 86/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 1.7408e-04 - accuracy: 0.9991 - val_loss: 0.0018 - val_accuracy: 0.9898\n",
      "Epoch 87/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.3474e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 88/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 2.0934e-04 - accuracy: 0.9988 - val_loss: 0.0018 - val_accuracy: 0.9903\n",
      "Epoch 89/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 2.4125e-04 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 0.9917\n",
      "Epoch 90/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.4471e-04 - accuracy: 0.9993 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 91/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.5281e-04 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 92/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.7090e-04 - accuracy: 0.9991 - val_loss: 0.0017 - val_accuracy: 0.9908\n",
      "Epoch 93/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.4767e-04 - accuracy: 0.9985 - val_loss: 0.0017 - val_accuracy: 0.9913\n",
      "Epoch 94/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 1.7128e-04 - accuracy: 0.9991 - val_loss: 0.0016 - val_accuracy: 0.9917\n",
      "Epoch 95/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 1.9773e-04 - accuracy: 0.9989 - val_loss: 0.0014 - val_accuracy: 0.9923\n",
      "Epoch 96/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.0466e-04 - accuracy: 0.9988 - val_loss: 0.0018 - val_accuracy: 0.9900\n",
      "Epoch 97/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.5980e-04 - accuracy: 0.9991 - val_loss: 0.0016 - val_accuracy: 0.9917\n",
      "Epoch 98/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.6271e-04 - accuracy: 0.9991 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 99/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 1.4636e-04 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 100/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 2.0134e-04 - accuracy: 0.9989 - val_loss: 0.0014 - val_accuracy: 0.9925\n",
      "313/313 - 1s - loss: 0.0014 - accuracy: 0.9923\n",
      "testSetLoss: 0.0014392394805327058 - testSetAccuracyz: 0.9922999739646912%\n"
     ]
    }
   ],
   "source": [
    "test2_64 = trainModel2(100, 64)\n",
    "hist_df = pd.DataFrame(test2_64.history)\n",
    "hist_json_file = 'test2_64.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 5s 10ms/step - loss: 0.0134 - accuracy: 0.9111 - val_loss: 0.0037 - val_accuracy: 0.9780\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0040 - accuracy: 0.9746 - val_loss: 0.0025 - val_accuracy: 0.9833\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0029 - accuracy: 0.9814 - val_loss: 0.0022 - val_accuracy: 0.9863\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0024 - accuracy: 0.9850 - val_loss: 0.0019 - val_accuracy: 0.9878\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0020 - accuracy: 0.9876 - val_loss: 0.0018 - val_accuracy: 0.9880\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0017 - accuracy: 0.9891 - val_loss: 0.0018 - val_accuracy: 0.9875\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0015 - accuracy: 0.9904 - val_loss: 0.0019 - val_accuracy: 0.9877\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0013 - accuracy: 0.9918 - val_loss: 0.0017 - val_accuracy: 0.9895\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0012 - accuracy: 0.9928 - val_loss: 0.0016 - val_accuracy: 0.9900\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0010 - accuracy: 0.9938 - val_loss: 0.0016 - val_accuracy: 0.9892\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 9.7643e-04 - accuracy: 0.9941 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 8.8484e-04 - accuracy: 0.9947 - val_loss: 0.0016 - val_accuracy: 0.9898\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 8.3158e-04 - accuracy: 0.9949 - val_loss: 0.0014 - val_accuracy: 0.9917\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 7.2118e-04 - accuracy: 0.9959 - val_loss: 0.0015 - val_accuracy: 0.9913\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 6.2332e-04 - accuracy: 0.9965 - val_loss: 0.0016 - val_accuracy: 0.9902\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 6.6980e-04 - accuracy: 0.9960 - val_loss: 0.0015 - val_accuracy: 0.9903\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 5.4198e-04 - accuracy: 0.9970 - val_loss: 0.0014 - val_accuracy: 0.9917\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 5.1646e-04 - accuracy: 0.9971 - val_loss: 0.0016 - val_accuracy: 0.9903\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 5.3250e-04 - accuracy: 0.9970 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 4.6330e-04 - accuracy: 0.9972 - val_loss: 0.0019 - val_accuracy: 0.9887\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 4.5670e-04 - accuracy: 0.9974 - val_loss: 0.0018 - val_accuracy: 0.9885\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 4.1851e-04 - accuracy: 0.9978 - val_loss: 0.0015 - val_accuracy: 0.9908\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.3450e-04 - accuracy: 0.9983 - val_loss: 0.0017 - val_accuracy: 0.9897\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 4.0177e-04 - accuracy: 0.9978 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.3837e-04 - accuracy: 0.9981 - val_loss: 0.0016 - val_accuracy: 0.9907\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.8187e-04 - accuracy: 0.9979 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.6966e-04 - accuracy: 0.9980 - val_loss: 0.0016 - val_accuracy: 0.9893\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.5604e-04 - accuracy: 0.9980 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.7625e-04 - accuracy: 0.9985 - val_loss: 0.0016 - val_accuracy: 0.9902\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.6822e-04 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 0.9905\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.7615e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9907\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.0338e-04 - accuracy: 0.9984 - val_loss: 0.0015 - val_accuracy: 0.9908\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 4.0540e-04 - accuracy: 0.9977 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.1631e-04 - accuracy: 0.9981 - val_loss: 0.0017 - val_accuracy: 0.9898\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.8814e-04 - accuracy: 0.9984 - val_loss: 0.0014 - val_accuracy: 0.9913\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.2927e-04 - accuracy: 0.9981 - val_loss: 0.0017 - val_accuracy: 0.9902\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.9653e-04 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9903\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.6641e-04 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 0.9913\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.2938e-04 - accuracy: 0.9988 - val_loss: 0.0018 - val_accuracy: 0.9892\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.4200e-04 - accuracy: 0.9981 - val_loss: 0.0015 - val_accuracy: 0.9908\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.7757e-04 - accuracy: 0.9984 - val_loss: 0.0016 - val_accuracy: 0.9897\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.4536e-04 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.9107e-04 - accuracy: 0.9990 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.4016e-04 - accuracy: 0.9987 - val_loss: 0.0018 - val_accuracy: 0.9892\n",
      "Epoch 45/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 3.0778e-04 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 46/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.9343e-04 - accuracy: 0.9990 - val_loss: 0.0015 - val_accuracy: 0.9917\n",
      "Epoch 47/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.6597e-04 - accuracy: 0.9985 - val_loss: 0.0017 - val_accuracy: 0.9897\n",
      "Epoch 48/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.5114e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 49/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.5860e-04 - accuracy: 0.9985 - val_loss: 0.0015 - val_accuracy: 0.9913\n",
      "Epoch 50/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.4060e-04 - accuracy: 0.9986 - val_loss: 0.0019 - val_accuracy: 0.9892\n",
      "Epoch 51/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.8787e-04 - accuracy: 0.9984 - val_loss: 0.0017 - val_accuracy: 0.9900\n",
      "Epoch 52/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.8075e-04 - accuracy: 0.9991 - val_loss: 0.0015 - val_accuracy: 0.9910\n",
      "Epoch 53/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.8561e-04 - accuracy: 0.9991 - val_loss: 0.0017 - val_accuracy: 0.9903\n",
      "Epoch 54/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.3294e-04 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9908\n",
      "Epoch 55/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.5623e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9892\n",
      "Epoch 56/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.3760e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9902\n",
      "Epoch 57/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.5692e-04 - accuracy: 0.9985 - val_loss: 0.0015 - val_accuracy: 0.9910\n",
      "Epoch 58/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.9624e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9907\n",
      "Epoch 59/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.1867e-04 - accuracy: 0.9988 - val_loss: 0.0015 - val_accuracy: 0.9910\n",
      "Epoch 60/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.8803e-04 - accuracy: 0.9990 - val_loss: 0.0014 - val_accuracy: 0.9910\n",
      "Epoch 61/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.8204e-04 - accuracy: 0.9984 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 62/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.6122e-04 - accuracy: 0.9985 - val_loss: 0.0015 - val_accuracy: 0.9917\n",
      "Epoch 63/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.0613e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 64/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.2504e-04 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 65/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.1599e-04 - accuracy: 0.9988 - val_loss: 0.0015 - val_accuracy: 0.9913\n",
      "Epoch 66/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.9002e-04 - accuracy: 0.9990 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 67/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.0960e-04 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9900\n",
      "Epoch 68/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.4928e-04 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 0.9915\n",
      "Epoch 69/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.2301e-04 - accuracy: 0.9987 - val_loss: 0.0015 - val_accuracy: 0.9913\n",
      "Epoch 70/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.1657e-04 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9900\n",
      "Epoch 71/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.9458e-04 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9905\n",
      "Epoch 72/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.1587e-04 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 73/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.3880e-04 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 0.9907\n",
      "Epoch 74/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.7269e-04 - accuracy: 0.9991 - val_loss: 0.0014 - val_accuracy: 0.9920\n",
      "Epoch 75/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.5822e-04 - accuracy: 0.9992 - val_loss: 0.0017 - val_accuracy: 0.9900\n",
      "Epoch 76/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.3057e-04 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9907\n",
      "Epoch 77/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.2868e-04 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9908\n",
      "Epoch 78/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.0521e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 79/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.9478e-04 - accuracy: 0.9990 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 80/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.5758e-04 - accuracy: 0.9992 - val_loss: 0.0015 - val_accuracy: 0.9915\n",
      "Epoch 81/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.3659e-04 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 82/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.2676e-04 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9903\n",
      "Epoch 83/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.1740e-04 - accuracy: 0.9988 - val_loss: 0.0015 - val_accuracy: 0.9913\n",
      "Epoch 84/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.9465e-04 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 0.9915\n",
      "Epoch 85/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.9517e-04 - accuracy: 0.9989 - val_loss: 0.0014 - val_accuracy: 0.9913\n",
      "Epoch 86/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.8575e-04 - accuracy: 0.9990 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 87/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.3857e-04 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9907\n",
      "Epoch 88/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.8525e-04 - accuracy: 0.9990 - val_loss: 0.0015 - val_accuracy: 0.9918\n",
      "Epoch 89/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.5310e-04 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 90/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.0123e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 91/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.2960e-04 - accuracy: 0.9988 - val_loss: 0.0015 - val_accuracy: 0.9910\n",
      "Epoch 92/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.2799e-04 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 0.9910\n",
      "Epoch 93/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.8906e-04 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9903\n",
      "Epoch 94/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.8859e-04 - accuracy: 0.9990 - val_loss: 0.0017 - val_accuracy: 0.9900\n",
      "Epoch 95/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.9259e-04 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 0.9922\n",
      "Epoch 96/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.5710e-04 - accuracy: 0.9991 - val_loss: 0.0016 - val_accuracy: 0.9912\n",
      "Epoch 97/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 1.8331e-04 - accuracy: 0.9990 - val_loss: 0.0020 - val_accuracy: 0.9888\n",
      "Epoch 98/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 2.2742e-04 - accuracy: 0.9987 - val_loss: 0.0018 - val_accuracy: 0.9898\n",
      "Epoch 99/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.0220e-04 - accuracy: 0.9989 - val_loss: 0.0020 - val_accuracy: 0.9895\n",
      "Epoch 100/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 2.1261e-04 - accuracy: 0.9989 - val_loss: 0.0019 - val_accuracy: 0.9897\n",
      "313/313 - 1s - loss: 0.0016 - accuracy: 0.9909\n",
      "testSetLoss: 0.0015802931739017367 - testSetAccuracyz: 0.9908999800682068%\n"
     ]
    }
   ],
   "source": [
    "test2_128 = trainModel2(100, 128)\n",
    "hist_df = pd.DataFrame(test2_128.history)\n",
    "hist_json_file = 'test2_128.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 4s 16ms/step - loss: 0.0184 - accuracy: 0.8888 - val_loss: 0.0047 - val_accuracy: 0.9697\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0048 - accuracy: 0.9702 - val_loss: 0.0029 - val_accuracy: 0.9810\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0035 - accuracy: 0.9784 - val_loss: 0.0027 - val_accuracy: 0.9827\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0028 - accuracy: 0.9823 - val_loss: 0.0022 - val_accuracy: 0.9843\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0024 - accuracy: 0.9846 - val_loss: 0.0020 - val_accuracy: 0.9877\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0020 - accuracy: 0.9874 - val_loss: 0.0020 - val_accuracy: 0.9857\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0018 - accuracy: 0.9892 - val_loss: 0.0021 - val_accuracy: 0.9862\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0017 - accuracy: 0.9899 - val_loss: 0.0020 - val_accuracy: 0.9872\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0016 - accuracy: 0.9904 - val_loss: 0.0017 - val_accuracy: 0.9893\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0014 - accuracy: 0.9913 - val_loss: 0.0021 - val_accuracy: 0.9855\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0013 - accuracy: 0.9920 - val_loss: 0.0018 - val_accuracy: 0.9893\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0012 - accuracy: 0.9927 - val_loss: 0.0017 - val_accuracy: 0.9893\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0012 - accuracy: 0.9929 - val_loss: 0.0016 - val_accuracy: 0.9892\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0011 - accuracy: 0.9939 - val_loss: 0.0016 - val_accuracy: 0.9888\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 9.8155e-04 - accuracy: 0.9941 - val_loss: 0.0016 - val_accuracy: 0.9903\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 9.3558e-04 - accuracy: 0.9946 - val_loss: 0.0017 - val_accuracy: 0.9895\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 8.2479e-04 - accuracy: 0.9952 - val_loss: 0.0018 - val_accuracy: 0.9888\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 7.5221e-04 - accuracy: 0.9958 - val_loss: 0.0016 - val_accuracy: 0.9898\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 7.5294e-04 - accuracy: 0.9959 - val_loss: 0.0016 - val_accuracy: 0.9897\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 6.8729e-04 - accuracy: 0.9962 - val_loss: 0.0019 - val_accuracy: 0.9873\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 6.6578e-04 - accuracy: 0.9962 - val_loss: 0.0017 - val_accuracy: 0.9892\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 6.1878e-04 - accuracy: 0.9966 - val_loss: 0.0015 - val_accuracy: 0.9910\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 6.0240e-04 - accuracy: 0.9967 - val_loss: 0.0019 - val_accuracy: 0.9873\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 5.8884e-04 - accuracy: 0.9966 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 5.6783e-04 - accuracy: 0.9968 - val_loss: 0.0016 - val_accuracy: 0.9898\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 4.8789e-04 - accuracy: 0.9974 - val_loss: 0.0020 - val_accuracy: 0.9875\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 5.0607e-04 - accuracy: 0.9973 - val_loss: 0.0016 - val_accuracy: 0.9907\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 4.7327e-04 - accuracy: 0.9974 - val_loss: 0.0017 - val_accuracy: 0.9897\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 4.3451e-04 - accuracy: 0.9977 - val_loss: 0.0015 - val_accuracy: 0.9913\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 4.5682e-04 - accuracy: 0.9974 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 4.2473e-04 - accuracy: 0.9976 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.7052e-04 - accuracy: 0.9980 - val_loss: 0.0016 - val_accuracy: 0.9902\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 4.1155e-04 - accuracy: 0.9978 - val_loss: 0.0016 - val_accuracy: 0.9910\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.7329e-04 - accuracy: 0.9980 - val_loss: 0.0015 - val_accuracy: 0.9915\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 4.7516e-04 - accuracy: 0.9973 - val_loss: 0.0017 - val_accuracy: 0.9898\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.8783e-04 - accuracy: 0.9979 - val_loss: 0.0016 - val_accuracy: 0.9897\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.1843e-04 - accuracy: 0.9984 - val_loss: 0.0014 - val_accuracy: 0.9907\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.4790e-04 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9898\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.7378e-04 - accuracy: 0.9979 - val_loss: 0.0014 - val_accuracy: 0.9912\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.9579e-04 - accuracy: 0.9978 - val_loss: 0.0018 - val_accuracy: 0.9892\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.3454e-04 - accuracy: 0.9983 - val_loss: 0.0015 - val_accuracy: 0.9910\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.1385e-04 - accuracy: 0.9984 - val_loss: 0.0017 - val_accuracy: 0.9897\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.1450e-04 - accuracy: 0.9983 - val_loss: 0.0015 - val_accuracy: 0.9910\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.2285e-04 - accuracy: 0.9983 - val_loss: 0.0015 - val_accuracy: 0.9905\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.5720e-04 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.5384e-04 - accuracy: 0.9986 - val_loss: 0.0014 - val_accuracy: 0.9913\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.9094e-04 - accuracy: 0.9978 - val_loss: 0.0015 - val_accuracy: 0.9907\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.5157e-04 - accuracy: 0.9981 - val_loss: 0.0016 - val_accuracy: 0.9907\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.5471e-04 - accuracy: 0.9987 - val_loss: 0.0015 - val_accuracy: 0.9917\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.4131e-04 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9903\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.9328e-04 - accuracy: 0.9984 - val_loss: 0.0017 - val_accuracy: 0.9895\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.4235e-04 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9895\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.4821e-04 - accuracy: 0.9979 - val_loss: 0.0015 - val_accuracy: 0.9907\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.5095e-04 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9893\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.7404e-04 - accuracy: 0.9984 - val_loss: 0.0018 - val_accuracy: 0.9888\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.9050e-04 - accuracy: 0.9983 - val_loss: 0.0019 - val_accuracy: 0.9883\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.2551e-04 - accuracy: 0.9981 - val_loss: 0.0017 - val_accuracy: 0.9893\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.8104e-04 - accuracy: 0.9984 - val_loss: 0.0015 - val_accuracy: 0.9903\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.0162e-04 - accuracy: 0.9990 - val_loss: 0.0014 - val_accuracy: 0.9917\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.7922e-04 - accuracy: 0.9991 - val_loss: 0.0016 - val_accuracy: 0.9903\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.6744e-04 - accuracy: 0.9991 - val_loss: 0.0015 - val_accuracy: 0.9913\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 1.6901e-04 - accuracy: 0.9991 - val_loss: 0.0016 - val_accuracy: 0.9902\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.6479e-04 - accuracy: 0.9992 - val_loss: 0.0015 - val_accuracy: 0.9908\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.7415e-04 - accuracy: 0.9991 - val_loss: 0.0014 - val_accuracy: 0.9917\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.4016e-04 - accuracy: 0.9980 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.8876e-04 - accuracy: 0.9976 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.8754e-04 - accuracy: 0.9983 - val_loss: 0.0015 - val_accuracy: 0.9907\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.5795e-04 - accuracy: 0.9985 - val_loss: 0.0014 - val_accuracy: 0.9915\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.2864e-04 - accuracy: 0.9988 - val_loss: 0.0015 - val_accuracy: 0.9917\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.1539e-04 - accuracy: 0.9989 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 1.9153e-04 - accuracy: 0.9990 - val_loss: 0.0016 - val_accuracy: 0.9907\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.1593e-04 - accuracy: 0.9988 - val_loss: 0.0015 - val_accuracy: 0.9907\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.9019e-04 - accuracy: 0.9991 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.9234e-04 - accuracy: 0.9984 - val_loss: 0.0014 - val_accuracy: 0.9917\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.1875e-04 - accuracy: 0.9988 - val_loss: 0.0014 - val_accuracy: 0.9917\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.7179e-04 - accuracy: 0.9991 - val_loss: 0.0014 - val_accuracy: 0.9918\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.6387e-04 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 0.9918\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.6300e-04 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 0.9918\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.7775e-04 - accuracy: 0.9991 - val_loss: 0.0014 - val_accuracy: 0.9915\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.7793e-04 - accuracy: 0.9985 - val_loss: 0.0017 - val_accuracy: 0.9897\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.0473e-04 - accuracy: 0.9983 - val_loss: 0.0014 - val_accuracy: 0.9923\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.0052e-04 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 0.9908\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.2912e-04 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9913\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.8518e-04 - accuracy: 0.9991 - val_loss: 0.0015 - val_accuracy: 0.9910\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.6459e-04 - accuracy: 0.9992 - val_loss: 0.0013 - val_accuracy: 0.9925\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.6531e-04 - accuracy: 0.9992 - val_loss: 0.0013 - val_accuracy: 0.9920\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.6029e-04 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 0.9918\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.6159e-04 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 0.9918\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.7031e-04 - accuracy: 0.9991 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.7121e-04 - accuracy: 0.9985 - val_loss: 0.0017 - val_accuracy: 0.9900\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 3.1462e-04 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.6253e-04 - accuracy: 0.9984 - val_loss: 0.0014 - val_accuracy: 0.9918\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.4354e-04 - accuracy: 0.9986 - val_loss: 0.0013 - val_accuracy: 0.9922\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.8564e-04 - accuracy: 0.9990 - val_loss: 0.0014 - val_accuracy: 0.9923\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.7193e-04 - accuracy: 0.9991 - val_loss: 0.0014 - val_accuracy: 0.9917\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.9957e-04 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 0.9912\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.7208e-04 - accuracy: 0.9991 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.0806e-04 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 0.9910\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 1.6705e-04 - accuracy: 0.9991 - val_loss: 0.0016 - val_accuracy: 0.9907\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 2.2326e-04 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "313/313 - 1s - loss: 0.0016 - accuracy: 0.9903\n",
      "testSetLoss: 0.0015585706569254398 - testSetAccuracyz: 0.9902999997138977%\n"
     ]
    }
   ],
   "source": [
    "test2_256 = trainModel2(100, 256)\n",
    "hist_df = pd.DataFrame(test2_256.history)\n",
    "hist_json_file = 'test2_256.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 0.0274 - accuracy: 0.8225 - val_loss: 0.0069 - val_accuracy: 0.9575\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0070 - accuracy: 0.9559 - val_loss: 0.0042 - val_accuracy: 0.9743\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0049 - accuracy: 0.9694 - val_loss: 0.0036 - val_accuracy: 0.9767\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0039 - accuracy: 0.9762 - val_loss: 0.0030 - val_accuracy: 0.9810\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0033 - accuracy: 0.9796 - val_loss: 0.0026 - val_accuracy: 0.9817\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0028 - accuracy: 0.9826 - val_loss: 0.0023 - val_accuracy: 0.9847\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0025 - accuracy: 0.9844 - val_loss: 0.0023 - val_accuracy: 0.9833\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0022 - accuracy: 0.9866 - val_loss: 0.0021 - val_accuracy: 0.9857\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0021 - accuracy: 0.9871 - val_loss: 0.0021 - val_accuracy: 0.9858\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0019 - accuracy: 0.9885 - val_loss: 0.0021 - val_accuracy: 0.9848\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0018 - accuracy: 0.9890 - val_loss: 0.0019 - val_accuracy: 0.9863\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0017 - accuracy: 0.9898 - val_loss: 0.0019 - val_accuracy: 0.9870\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0016 - accuracy: 0.9906 - val_loss: 0.0020 - val_accuracy: 0.9870\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0015 - accuracy: 0.9913 - val_loss: 0.0020 - val_accuracy: 0.9865\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0014 - accuracy: 0.9917 - val_loss: 0.0018 - val_accuracy: 0.9882\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0014 - accuracy: 0.9920 - val_loss: 0.0019 - val_accuracy: 0.9877\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0013 - accuracy: 0.9926 - val_loss: 0.0021 - val_accuracy: 0.9848\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0013 - accuracy: 0.9926 - val_loss: 0.0018 - val_accuracy: 0.9890\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0011 - accuracy: 0.9934 - val_loss: 0.0018 - val_accuracy: 0.9877\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0011 - accuracy: 0.9939 - val_loss: 0.0018 - val_accuracy: 0.9885\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 0.0010 - accuracy: 0.9942 - val_loss: 0.0017 - val_accuracy: 0.9898\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 9.8865e-04 - accuracy: 0.9942 - val_loss: 0.0019 - val_accuracy: 0.9875\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 9.5458e-04 - accuracy: 0.9945 - val_loss: 0.0020 - val_accuracy: 0.9868\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 9.0089e-04 - accuracy: 0.9949 - val_loss: 0.0019 - val_accuracy: 0.9870\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 8.3028e-04 - accuracy: 0.9954 - val_loss: 0.0018 - val_accuracy: 0.9883\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 7.9178e-04 - accuracy: 0.9959 - val_loss: 0.0019 - val_accuracy: 0.9875\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 7.6921e-04 - accuracy: 0.9960 - val_loss: 0.0018 - val_accuracy: 0.9887\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 6.8700e-04 - accuracy: 0.9965 - val_loss: 0.0018 - val_accuracy: 0.9888\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 6.8079e-04 - accuracy: 0.9964 - val_loss: 0.0019 - val_accuracy: 0.9878\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 7.1716e-04 - accuracy: 0.9962 - val_loss: 0.0019 - val_accuracy: 0.9877\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 6.3799e-04 - accuracy: 0.9967 - val_loss: 0.0017 - val_accuracy: 0.9888\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 5.7929e-04 - accuracy: 0.9971 - val_loss: 0.0021 - val_accuracy: 0.9868\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 6.3412e-04 - accuracy: 0.9967 - val_loss: 0.0021 - val_accuracy: 0.9867\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 6.1693e-04 - accuracy: 0.9967 - val_loss: 0.0019 - val_accuracy: 0.9870\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 6.1407e-04 - accuracy: 0.9966 - val_loss: 0.0018 - val_accuracy: 0.9885\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 5.2756e-04 - accuracy: 0.9974 - val_loss: 0.0017 - val_accuracy: 0.9893\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 5.4526e-04 - accuracy: 0.9971 - val_loss: 0.0019 - val_accuracy: 0.9877\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.9596e-04 - accuracy: 0.9975 - val_loss: 0.0020 - val_accuracy: 0.9873\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.8791e-04 - accuracy: 0.9975 - val_loss: 0.0018 - val_accuracy: 0.9887\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.4653e-04 - accuracy: 0.9977 - val_loss: 0.0020 - val_accuracy: 0.9878\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 5.0711e-04 - accuracy: 0.9974 - val_loss: 0.0018 - val_accuracy: 0.9887\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 5.5612e-04 - accuracy: 0.9970 - val_loss: 0.0021 - val_accuracy: 0.9863\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 5.2399e-04 - accuracy: 0.9973 - val_loss: 0.0018 - val_accuracy: 0.9890\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.6829e-04 - accuracy: 0.9976 - val_loss: 0.0020 - val_accuracy: 0.9872\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.7663e-04 - accuracy: 0.9975 - val_loss: 0.0018 - val_accuracy: 0.9887\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.3690e-04 - accuracy: 0.9979 - val_loss: 0.0018 - val_accuracy: 0.9888\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 4.0836e-04 - accuracy: 0.9980 - val_loss: 0.0017 - val_accuracy: 0.9890\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.7599e-04 - accuracy: 0.9982 - val_loss: 0.0017 - val_accuracy: 0.9902\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.8148e-04 - accuracy: 0.9980 - val_loss: 0.0018 - val_accuracy: 0.9888\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.5788e-04 - accuracy: 0.9982 - val_loss: 0.0017 - val_accuracy: 0.9902\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.4078e-04 - accuracy: 0.9983 - val_loss: 0.0018 - val_accuracy: 0.9898\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.3420e-04 - accuracy: 0.9984 - val_loss: 0.0017 - val_accuracy: 0.9897\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.9641e-04 - accuracy: 0.9979 - val_loss: 0.0020 - val_accuracy: 0.9880\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 6.1295e-04 - accuracy: 0.9964 - val_loss: 0.0019 - val_accuracy: 0.9882\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.5276e-04 - accuracy: 0.9976 - val_loss: 0.0018 - val_accuracy: 0.9890\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.4791e-04 - accuracy: 0.9976 - val_loss: 0.0020 - val_accuracy: 0.9880\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.0653e-04 - accuracy: 0.9978 - val_loss: 0.0018 - val_accuracy: 0.9897\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.1785e-04 - accuracy: 0.9984 - val_loss: 0.0018 - val_accuracy: 0.9895\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.9920e-04 - accuracy: 0.9985 - val_loss: 0.0017 - val_accuracy: 0.9898\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.7951e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9897\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.7544e-04 - accuracy: 0.9986 - val_loss: 0.0019 - val_accuracy: 0.9885\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.0058e-04 - accuracy: 0.9985 - val_loss: 0.0017 - val_accuracy: 0.9902\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.7618e-04 - accuracy: 0.9986 - val_loss: 0.0018 - val_accuracy: 0.9887\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.1166e-04 - accuracy: 0.9976 - val_loss: 0.0020 - val_accuracy: 0.9883\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.4086e-04 - accuracy: 0.9976 - val_loss: 0.0019 - val_accuracy: 0.9888\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.2849e-04 - accuracy: 0.9983 - val_loss: 0.0019 - val_accuracy: 0.9882\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.6194e-04 - accuracy: 0.9980 - val_loss: 0.0019 - val_accuracy: 0.9892\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.3550e-04 - accuracy: 0.9983 - val_loss: 0.0017 - val_accuracy: 0.9892\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.5700e-04 - accuracy: 0.9981 - val_loss: 0.0017 - val_accuracy: 0.9897\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.8696e-04 - accuracy: 0.9985 - val_loss: 0.0018 - val_accuracy: 0.9897\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.6528e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9892\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.6229e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9902\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.9318e-04 - accuracy: 0.9985 - val_loss: 0.0019 - val_accuracy: 0.9888\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.8615e-04 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9897\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 3.0980e-04 - accuracy: 0.9983 - val_loss: 0.0019 - val_accuracy: 0.9885\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.9380e-04 - accuracy: 0.9978 - val_loss: 0.0019 - val_accuracy: 0.9887\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.5314e-04 - accuracy: 0.9980 - val_loss: 0.0018 - val_accuracy: 0.9888\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.2328e-04 - accuracy: 0.9983 - val_loss: 0.0017 - val_accuracy: 0.9892\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.5173e-04 - accuracy: 0.9987 - val_loss: 0.0018 - val_accuracy: 0.9897\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.5298e-04 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9893\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.4171e-04 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.6492e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9910\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.7459e-04 - accuracy: 0.9986 - val_loss: 0.0018 - val_accuracy: 0.9897\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.3980e-04 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9902\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.4907e-04 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9892\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.6844e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9897\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.3510e-04 - accuracy: 0.9981 - val_loss: 0.0023 - val_accuracy: 0.9858\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.4136e-04 - accuracy: 0.9982 - val_loss: 0.0019 - val_accuracy: 0.9878\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 4.3801e-04 - accuracy: 0.9974 - val_loss: 0.0019 - val_accuracy: 0.9887\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 3.2868e-04 - accuracy: 0.9982 - val_loss: 0.0016 - val_accuracy: 0.9908\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.8849e-04 - accuracy: 0.9985 - val_loss: 0.0016 - val_accuracy: 0.9897\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.5450e-04 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9902\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.7281e-04 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9905\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.2550e-04 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9900\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.3256e-04 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9903\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.2704e-04 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9910\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2655e-04 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9897\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.2679e-04 - accuracy: 0.9988 - val_loss: 0.0016 - val_accuracy: 0.9907\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.3610e-04 - accuracy: 0.9988 - val_loss: 0.0018 - val_accuracy: 0.9888\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.2693e-04 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9903\n",
      "313/313 - 1s - loss: 0.0016 - accuracy: 0.9909\n",
      "testSetLoss: 0.0016056959284469485 - testSetAccuracyz: 0.9908999800682068%\n"
     ]
    }
   ],
   "source": [
    "test2_512 = trainModel2(100, 512)\n",
    "hist_df = pd.DataFrame(test2_512.history)\n",
    "hist_json_file = 'test2_512.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "27000/27000 [==============================] - 145s 5ms/step - loss: 0.4169 - accuracy: 0.8983 - val_loss: 0.3558 - val_accuracy: 0.8943\n",
      "Epoch 2/100\n",
      "27000/27000 [==============================] - 135s 5ms/step - loss: 1.1850 - accuracy: 0.5694 - val_loss: 2.3048 - val_accuracy: 0.1050\n",
      "Epoch 3/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 2.3128 - accuracy: 0.1018 - val_loss: 2.3099 - val_accuracy: 0.1050\n",
      "Epoch 4/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3128 - accuracy: 0.1037 - val_loss: 2.3075 - val_accuracy: 0.1050\n",
      "Epoch 5/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3125 - accuracy: 0.1051 - val_loss: 2.3145 - val_accuracy: 0.1113\n",
      "Epoch 6/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3125 - accuracy: 0.1038 - val_loss: 2.3098 - val_accuracy: 0.1045\n",
      "Epoch 7/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3126 - accuracy: 0.1057 - val_loss: 2.3199 - val_accuracy: 0.0960\n",
      "Epoch 8/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3121 - accuracy: 0.1042 - val_loss: 2.3134 - val_accuracy: 0.0992\n",
      "Epoch 9/100\n",
      "27000/27000 [==============================] - 133s 5ms/step - loss: 2.3124 - accuracy: 0.1024 - val_loss: 2.3141 - val_accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3128 - accuracy: 0.1036 - val_loss: 2.3152 - val_accuracy: 0.1050\n",
      "Epoch 11/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3127 - accuracy: 0.1028 - val_loss: 2.3110 - val_accuracy: 0.0952\n",
      "Epoch 12/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3122 - accuracy: 0.1032 - val_loss: 2.3146 - val_accuracy: 0.1045\n",
      "Epoch 13/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3122 - accuracy: 0.1021 - val_loss: 2.3107 - val_accuracy: 0.0978\n",
      "Epoch 14/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3129 - accuracy: 0.1030 - val_loss: 2.3086 - val_accuracy: 0.1113\n",
      "Epoch 15/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3124 - accuracy: 0.1034 - val_loss: 2.3177 - val_accuracy: 0.1050\n",
      "Epoch 16/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3125 - accuracy: 0.1032 - val_loss: 2.3135 - val_accuracy: 0.1050\n",
      "Epoch 17/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3132 - accuracy: 0.1033 - val_loss: 2.3037 - val_accuracy: 0.1113\n",
      "Epoch 18/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3126 - accuracy: 0.1022 - val_loss: 2.3131 - val_accuracy: 0.1000\n",
      "Epoch 19/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3123 - accuracy: 0.1033 - val_loss: 2.3121 - val_accuracy: 0.0978\n",
      "Epoch 20/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3126 - accuracy: 0.1030 - val_loss: 2.3138 - val_accuracy: 0.0995\n",
      "Epoch 21/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3128 - accuracy: 0.1032 - val_loss: 2.3139 - val_accuracy: 0.0915\n",
      "Epoch 22/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3124 - accuracy: 0.1021 - val_loss: 2.3163 - val_accuracy: 0.1113\n",
      "Epoch 23/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3123 - accuracy: 0.1045 - val_loss: 2.3209 - val_accuracy: 0.1050\n",
      "Epoch 24/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3122 - accuracy: 0.1040 - val_loss: 2.3062 - val_accuracy: 0.1113\n",
      "Epoch 25/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3125 - accuracy: 0.1035 - val_loss: 2.3137 - val_accuracy: 0.1113\n",
      "Epoch 26/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3127 - accuracy: 0.1050 - val_loss: 2.3124 - val_accuracy: 0.0960\n",
      "Epoch 27/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3128 - accuracy: 0.1020 - val_loss: 2.3081 - val_accuracy: 0.1045\n",
      "Epoch 28/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3125 - accuracy: 0.1044 - val_loss: 2.3080 - val_accuracy: 0.0960\n",
      "Epoch 29/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3129 - accuracy: 0.1023 - val_loss: 2.3057 - val_accuracy: 0.1113\n",
      "Epoch 30/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 2.3123 - accuracy: 0.1041 - val_loss: 2.3070 - val_accuracy: 0.1050\n",
      "Epoch 31/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3125 - accuracy: 0.1031 - val_loss: 2.3116 - val_accuracy: 0.1050\n",
      "Epoch 32/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3123 - accuracy: 0.1029 - val_loss: 2.3087 - val_accuracy: 0.1045\n",
      "Epoch 33/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3123 - accuracy: 0.1035 - val_loss: 2.3205 - val_accuracy: 0.1045\n",
      "Epoch 34/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3124 - accuracy: 0.1017 - val_loss: 2.3097 - val_accuracy: 0.0995\n",
      "Epoch 35/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3124 - accuracy: 0.1034 - val_loss: 2.3163 - val_accuracy: 0.1000\n",
      "Epoch 36/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3128 - accuracy: 0.1041 - val_loss: 2.3118 - val_accuracy: 0.0915\n",
      "Epoch 37/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3123 - accuracy: 0.1038 - val_loss: 2.3079 - val_accuracy: 0.0915\n",
      "Epoch 38/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3125 - accuracy: 0.1013 - val_loss: 2.3143 - val_accuracy: 0.1050\n",
      "Epoch 39/100\n",
      "27000/27000 [==============================] - 161s 6ms/step - loss: 2.3133 - accuracy: 0.1010 - val_loss: 2.3226 - val_accuracy: 0.0992\n",
      "Epoch 40/100\n",
      "27000/27000 [==============================] - 160s 6ms/step - loss: 2.3122 - accuracy: 0.1023 - val_loss: 2.3225 - val_accuracy: 0.1050\n",
      "Epoch 41/100\n",
      "27000/27000 [==============================] - 237s 9ms/step - loss: 2.3131 - accuracy: 0.1032 - val_loss: 2.3109 - val_accuracy: 0.0952\n",
      "Epoch 42/100\n",
      "27000/27000 [==============================] - 257s 10ms/step - loss: 1.6280 - accuracy: 0.4067 - val_loss: 2.3096 - val_accuracy: 0.0992\n",
      "Epoch 43/100\n",
      "27000/27000 [==============================] - 317s 12ms/step - loss: 2.3121 - accuracy: 0.1061 - val_loss: 2.3128 - val_accuracy: 0.1050\n",
      "Epoch 44/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3124 - accuracy: 0.1035 - val_loss: 2.3179 - val_accuracy: 0.0995\n",
      "Epoch 45/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3123 - accuracy: 0.1071 - val_loss: 2.3115 - val_accuracy: 0.0995\n",
      "Epoch 46/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3122 - accuracy: 0.1040 - val_loss: 2.3212 - val_accuracy: 0.1050\n",
      "Epoch 47/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3125 - accuracy: 0.1028 - val_loss: 2.3098 - val_accuracy: 0.1113\n",
      "Epoch 48/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3124 - accuracy: 0.1015 - val_loss: 2.3140 - val_accuracy: 0.1113\n",
      "Epoch 49/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3124 - accuracy: 0.1047 - val_loss: 2.3101 - val_accuracy: 0.0995\n",
      "Epoch 50/100\n",
      "27000/27000 [==============================] - 144s 5ms/step - loss: 2.3121 - accuracy: 0.1026 - val_loss: 2.3072 - val_accuracy: 0.1113\n",
      "Epoch 51/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3128 - accuracy: 0.1024 - val_loss: 2.3098 - val_accuracy: 0.0960\n",
      "Epoch 52/100\n",
      "27000/27000 [==============================] - 133s 5ms/step - loss: 2.3129 - accuracy: 0.1014 - val_loss: 2.3099 - val_accuracy: 0.1050\n",
      "Epoch 53/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3130 - accuracy: 0.1030 - val_loss: 2.3130 - val_accuracy: 0.0992\n",
      "Epoch 54/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3121 - accuracy: 0.1037 - val_loss: 2.3152 - val_accuracy: 0.0915\n",
      "Epoch 55/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3128 - accuracy: 0.1009 - val_loss: 2.3108 - val_accuracy: 0.1045\n",
      "Epoch 56/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3129 - accuracy: 0.1042 - val_loss: 2.3107 - val_accuracy: 0.0992\n",
      "Epoch 57/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.3124 - accuracy: 0.1045 - val_loss: 2.3082 - val_accuracy: 0.0960\n",
      "Epoch 58/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 2.3122 - accuracy: 0.1040 - val_loss: 2.3198 - val_accuracy: 0.0952\n",
      "Epoch 59/100\n",
      "27000/27000 [==============================] - 153s 6ms/step - loss: 2.3129 - accuracy: 0.1029 - val_loss: 2.3147 - val_accuracy: 0.1000\n",
      "Epoch 60/100\n",
      "27000/27000 [==============================] - 147s 5ms/step - loss: 2.3125 - accuracy: 0.1024 - val_loss: 2.3073 - val_accuracy: 0.1000\n",
      "Epoch 61/100\n",
      "27000/27000 [==============================] - 146s 5ms/step - loss: 2.3123 - accuracy: 0.1042 - val_loss: 2.3235 - val_accuracy: 0.1045\n",
      "Epoch 62/100\n",
      "27000/27000 [==============================] - 175s 6ms/step - loss: 2.3128 - accuracy: 0.1043 - val_loss: 2.3135 - val_accuracy: 0.0960\n",
      "Epoch 63/100\n",
      "27000/27000 [==============================] - 165s 6ms/step - loss: 2.3125 - accuracy: 0.1029 - val_loss: 2.3063 - val_accuracy: 0.0960\n",
      "Epoch 64/100\n",
      "27000/27000 [==============================] - 201s 7ms/step - loss: 2.3121 - accuracy: 0.1029 - val_loss: 2.3144 - val_accuracy: 0.1050\n",
      "Epoch 65/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 2.3121 - accuracy: 0.1034 - val_loss: 2.3180 - val_accuracy: 0.1050\n",
      "Epoch 66/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3124 - accuracy: 0.1031 - val_loss: 2.3207 - val_accuracy: 0.1113\n",
      "Epoch 67/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3131 - accuracy: 0.1037 - val_loss: 2.3053 - val_accuracy: 0.1113\n",
      "Epoch 68/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3127 - accuracy: 0.1036 - val_loss: 2.3061 - val_accuracy: 0.1050\n",
      "Epoch 69/100\n",
      "27000/27000 [==============================] - 151s 6ms/step - loss: 2.3129 - accuracy: 0.1034 - val_loss: 2.3052 - val_accuracy: 0.1045\n",
      "Epoch 70/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 2.3124 - accuracy: 0.1037 - val_loss: 2.3114 - val_accuracy: 0.1050\n",
      "Epoch 71/100\n",
      "27000/27000 [==============================] - 144s 5ms/step - loss: 2.3129 - accuracy: 0.1021 - val_loss: 2.3031 - val_accuracy: 0.1045\n",
      "Epoch 72/100\n",
      "27000/27000 [==============================] - 158s 6ms/step - loss: 2.3124 - accuracy: 0.1037 - val_loss: 2.3150 - val_accuracy: 0.0952\n",
      "Epoch 73/100\n",
      "27000/27000 [==============================] - 167s 6ms/step - loss: 2.3124 - accuracy: 0.1010 - val_loss: 2.3149 - val_accuracy: 0.1050\n",
      "Epoch 74/100\n",
      "27000/27000 [==============================] - 156s 6ms/step - loss: 2.3119 - accuracy: 0.1062 - val_loss: 2.3218 - val_accuracy: 0.1050\n",
      "Epoch 75/100\n",
      "27000/27000 [==============================] - 144s 5ms/step - loss: 2.3123 - accuracy: 0.1044 - val_loss: 2.3154 - val_accuracy: 0.1050\n",
      "Epoch 76/100\n",
      "27000/27000 [==============================] - 144s 5ms/step - loss: 2.3120 - accuracy: 0.1029 - val_loss: 2.3144 - val_accuracy: 0.0995\n",
      "Epoch 77/100\n",
      "27000/27000 [==============================] - 152s 6ms/step - loss: 2.3124 - accuracy: 0.1054 - val_loss: 2.3144 - val_accuracy: 0.0960\n",
      "Epoch 78/100\n",
      "27000/27000 [==============================] - 193s 7ms/step - loss: 2.3119 - accuracy: 0.1051 - val_loss: 2.3139 - val_accuracy: 0.1050\n",
      "Epoch 79/100\n",
      "27000/27000 [==============================] - 168s 6ms/step - loss: 2.3123 - accuracy: 0.1019 - val_loss: 2.3138 - val_accuracy: 0.1050\n",
      "Epoch 80/100\n",
      "21946/27000 [=======================>......] - ETA: 28s - loss: 2.3124 - accuracy: 0.1032"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Acer\\source\\repos\\CudaBatchSize\\CudaBatchSize\\degredeModel9.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Acer/source/repos/CudaBatchSize/CudaBatchSize/degredeModel9.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test3_2 \u001b[39m=\u001b[39m trainModel3(\u001b[39m100\u001b[39;49m, \u001b[39m2\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Acer/source/repos/CudaBatchSize/CudaBatchSize/degredeModel9.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m hist_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(test3_2\u001b[39m.\u001b[39mhistory)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Acer/source/repos/CudaBatchSize/CudaBatchSize/degredeModel9.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m hist_json_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest3_2.csv\u001b[39m\u001b[39m'\u001b[39m \n",
      "\u001b[1;32mc:\\Users\\Acer\\source\\repos\\CudaBatchSize\\CudaBatchSize\\degredeModel9.ipynb Cell 23\u001b[0m in \u001b[0;36mtrainModel3\u001b[1;34m(no_epochs, bs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Acer/source/repos/CudaBatchSize/CudaBatchSize/degredeModel9.ipynb#X31sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Acer/source/repos/CudaBatchSize/CudaBatchSize/degredeModel9.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mloss_function,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Acer/source/repos/CudaBatchSize/CudaBatchSize/degredeModel9.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m             optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Acer/source/repos/CudaBatchSize/CudaBatchSize/degredeModel9.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m             metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Acer/source/repos/CudaBatchSize/CudaBatchSize/degredeModel9.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(inputs, targets, epochs\u001b[39m=\u001b[39;49mno_epochs,validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Acer/source/repos/CudaBatchSize/CudaBatchSize/degredeModel9.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m test_loss, test_acc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(input_test,  target_test, verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Acer/source/repos/CudaBatchSize/CudaBatchSize/degredeModel9.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtestSetLoss: \u001b[39m\u001b[39m{\u001b[39;00mtest_loss\u001b[39m}\u001b[39;00m\u001b[39m - testSetAccuracyz: \u001b[39m\u001b[39m{\u001b[39;00mtest_acc\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test3_2 = trainModel3(100, 2)\n",
    "hist_df = pd.DataFrame(test3_2.history)\n",
    "hist_json_file = 'test3_2.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_17 (Averag (None, 6, 6, 6)           0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                2170      \n",
      "=================================================================\n",
      "Total params: 2,326\n",
      "Trainable params: 2,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "6750/6750 [==============================] - 32s 5ms/step - loss: 0.0285 - accuracy: 0.8109 - val_loss: 0.0139 - val_accuracy: 0.9127\n",
      "Epoch 2/100\n",
      "6750/6750 [==============================] - 32s 5ms/step - loss: 0.0145 - accuracy: 0.9065 - val_loss: 0.0096 - val_accuracy: 0.9417\n",
      "Epoch 3/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0110 - accuracy: 0.9315 - val_loss: 0.0075 - val_accuracy: 0.9547\n",
      "Epoch 4/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0087 - accuracy: 0.9470 - val_loss: 0.0063 - val_accuracy: 0.9642\n",
      "Epoch 5/100\n",
      "6750/6750 [==============================] - 25s 4ms/step - loss: 0.0072 - accuracy: 0.9562 - val_loss: 0.0049 - val_accuracy: 0.9728\n",
      "Epoch 6/100\n",
      "6750/6750 [==============================] - 26s 4ms/step - loss: 0.0062 - accuracy: 0.9623 - val_loss: 0.0045 - val_accuracy: 0.9735\n",
      "Epoch 7/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0055 - accuracy: 0.9670 - val_loss: 0.0042 - val_accuracy: 0.9758\n",
      "Epoch 8/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0051 - accuracy: 0.9693 - val_loss: 0.0040 - val_accuracy: 0.9757\n",
      "Epoch 9/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0047 - accuracy: 0.9712 - val_loss: 0.0035 - val_accuracy: 0.9785\n",
      "Epoch 10/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0045 - accuracy: 0.9731 - val_loss: 0.0034 - val_accuracy: 0.9790\n",
      "Epoch 11/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0042 - accuracy: 0.9752 - val_loss: 0.0032 - val_accuracy: 0.9802\n",
      "Epoch 12/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0040 - accuracy: 0.9757 - val_loss: 0.0034 - val_accuracy: 0.9795\n",
      "Epoch 13/100\n",
      "6750/6750 [==============================] - 30s 5ms/step - loss: 0.0039 - accuracy: 0.9763 - val_loss: 0.0032 - val_accuracy: 0.9807\n",
      "Epoch 14/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0038 - accuracy: 0.9767 - val_loss: 0.0029 - val_accuracy: 0.9818\n",
      "Epoch 15/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0036 - accuracy: 0.9779 - val_loss: 0.0029 - val_accuracy: 0.9817\n",
      "Epoch 16/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0035 - accuracy: 0.9786 - val_loss: 0.0027 - val_accuracy: 0.9850\n",
      "Epoch 17/100\n",
      "6750/6750 [==============================] - 30s 5ms/step - loss: 0.0034 - accuracy: 0.9791 - val_loss: 0.0028 - val_accuracy: 0.9827\n",
      "Epoch 18/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0033 - accuracy: 0.9804 - val_loss: 0.0029 - val_accuracy: 0.9817\n",
      "Epoch 19/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0032 - accuracy: 0.9809 - val_loss: 0.0029 - val_accuracy: 0.9823\n",
      "Epoch 20/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0031 - accuracy: 0.9812 - val_loss: 0.0029 - val_accuracy: 0.9808\n",
      "Epoch 21/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0031 - accuracy: 0.9813 - val_loss: 0.0025 - val_accuracy: 0.9837\n",
      "Epoch 22/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0030 - accuracy: 0.9819 - val_loss: 0.0026 - val_accuracy: 0.9847\n",
      "Epoch 23/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0029 - accuracy: 0.9825 - val_loss: 0.0027 - val_accuracy: 0.9820\n",
      "Epoch 24/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0029 - accuracy: 0.9825 - val_loss: 0.0025 - val_accuracy: 0.9858\n",
      "Epoch 25/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0029 - accuracy: 0.9824 - val_loss: 0.0024 - val_accuracy: 0.9862\n",
      "Epoch 26/100\n",
      "6750/6750 [==============================] - 30s 4ms/step - loss: 0.0028 - accuracy: 0.9835 - val_loss: 0.0025 - val_accuracy: 0.9853\n",
      "Epoch 27/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0028 - accuracy: 0.9835 - val_loss: 0.0024 - val_accuracy: 0.9845\n",
      "Epoch 28/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0027 - accuracy: 0.9837 - val_loss: 0.0023 - val_accuracy: 0.9862\n",
      "Epoch 29/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0027 - accuracy: 0.9843 - val_loss: 0.0024 - val_accuracy: 0.9858\n",
      "Epoch 30/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0026 - accuracy: 0.9844 - val_loss: 0.0025 - val_accuracy: 0.9857\n",
      "Epoch 31/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0026 - accuracy: 0.9844 - val_loss: 0.0024 - val_accuracy: 0.9853\n",
      "Epoch 32/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0025 - accuracy: 0.9849 - val_loss: 0.0023 - val_accuracy: 0.9857\n",
      "Epoch 33/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0025 - accuracy: 0.9850 - val_loss: 0.0023 - val_accuracy: 0.9855\n",
      "Epoch 34/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0025 - accuracy: 0.9849 - val_loss: 0.0023 - val_accuracy: 0.9847\n",
      "Epoch 35/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0025 - accuracy: 0.9853 - val_loss: 0.0024 - val_accuracy: 0.9855\n",
      "Epoch 36/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0024 - accuracy: 0.9851 - val_loss: 0.0024 - val_accuracy: 0.9848\n",
      "Epoch 37/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0024 - accuracy: 0.9858 - val_loss: 0.0024 - val_accuracy: 0.9835\n",
      "Epoch 38/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0024 - accuracy: 0.9859 - val_loss: 0.0022 - val_accuracy: 0.9867\n",
      "Epoch 39/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0024 - accuracy: 0.9857 - val_loss: 0.0022 - val_accuracy: 0.9850\n",
      "Epoch 40/100\n",
      "6750/6750 [==============================] - 26s 4ms/step - loss: 0.0023 - accuracy: 0.9861 - val_loss: 0.0022 - val_accuracy: 0.9858\n",
      "Epoch 41/100\n",
      "6750/6750 [==============================] - 26s 4ms/step - loss: 0.0023 - accuracy: 0.9863 - val_loss: 0.0022 - val_accuracy: 0.9865\n",
      "Epoch 42/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0023 - accuracy: 0.9865 - val_loss: 0.0025 - val_accuracy: 0.9842\n",
      "Epoch 43/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0023 - accuracy: 0.9867 - val_loss: 0.0022 - val_accuracy: 0.9852\n",
      "Epoch 44/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0022 - accuracy: 0.9867 - val_loss: 0.0022 - val_accuracy: 0.9853\n",
      "Epoch 45/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0022 - accuracy: 0.9864 - val_loss: 0.0022 - val_accuracy: 0.9857\n",
      "Epoch 46/100\n",
      "6750/6750 [==============================] - 30s 5ms/step - loss: 0.0022 - accuracy: 0.9871 - val_loss: 0.0022 - val_accuracy: 0.9857\n",
      "Epoch 47/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0022 - accuracy: 0.9869 - val_loss: 0.0021 - val_accuracy: 0.9867\n",
      "Epoch 48/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0022 - accuracy: 0.9869 - val_loss: 0.0024 - val_accuracy: 0.9847\n",
      "Epoch 49/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0021 - accuracy: 0.9873 - val_loss: 0.0023 - val_accuracy: 0.9855\n",
      "Epoch 50/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0021 - accuracy: 0.9873 - val_loss: 0.0023 - val_accuracy: 0.9870\n",
      "Epoch 51/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0021 - accuracy: 0.9876 - val_loss: 0.0023 - val_accuracy: 0.9845\n",
      "Epoch 52/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0021 - accuracy: 0.9877 - val_loss: 0.0022 - val_accuracy: 0.9857\n",
      "Epoch 53/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0021 - accuracy: 0.9874 - val_loss: 0.0021 - val_accuracy: 0.9858\n",
      "Epoch 54/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0021 - accuracy: 0.9879 - val_loss: 0.0024 - val_accuracy: 0.9852\n",
      "Epoch 55/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0020 - accuracy: 0.9881 - val_loss: 0.0022 - val_accuracy: 0.9860\n",
      "Epoch 56/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0020 - accuracy: 0.9879 - val_loss: 0.0021 - val_accuracy: 0.9867\n",
      "Epoch 57/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0020 - accuracy: 0.9881 - val_loss: 0.0022 - val_accuracy: 0.9870\n",
      "Epoch 58/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0020 - accuracy: 0.9882 - val_loss: 0.0022 - val_accuracy: 0.9857\n",
      "Epoch 59/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0020 - accuracy: 0.9880 - val_loss: 0.0022 - val_accuracy: 0.9852\n",
      "Epoch 60/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0020 - accuracy: 0.9884 - val_loss: 0.0021 - val_accuracy: 0.9858\n",
      "Epoch 61/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0020 - accuracy: 0.9886 - val_loss: 0.0022 - val_accuracy: 0.9865\n",
      "Epoch 62/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0020 - accuracy: 0.9883 - val_loss: 0.0022 - val_accuracy: 0.9853\n",
      "Epoch 63/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0019 - accuracy: 0.9884 - val_loss: 0.0022 - val_accuracy: 0.9862\n",
      "Epoch 64/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0019 - accuracy: 0.9888 - val_loss: 0.0023 - val_accuracy: 0.9860\n",
      "Epoch 65/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0019 - accuracy: 0.9887 - val_loss: 0.0021 - val_accuracy: 0.9860\n",
      "Epoch 66/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0019 - accuracy: 0.9888 - val_loss: 0.0022 - val_accuracy: 0.9853\n",
      "Epoch 67/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0019 - accuracy: 0.9890 - val_loss: 0.0021 - val_accuracy: 0.9863\n",
      "Epoch 68/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0019 - accuracy: 0.9888 - val_loss: 0.0022 - val_accuracy: 0.9858\n",
      "Epoch 69/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0019 - accuracy: 0.9888 - val_loss: 0.0023 - val_accuracy: 0.9855\n",
      "Epoch 70/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0019 - accuracy: 0.9891 - val_loss: 0.0022 - val_accuracy: 0.9855\n",
      "Epoch 71/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0019 - accuracy: 0.9893 - val_loss: 0.0023 - val_accuracy: 0.9853\n",
      "Epoch 72/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0019 - accuracy: 0.9892 - val_loss: 0.0021 - val_accuracy: 0.9863\n",
      "Epoch 73/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0019 - accuracy: 0.9888 - val_loss: 0.0022 - val_accuracy: 0.9865\n",
      "Epoch 74/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0018 - accuracy: 0.9892 - val_loss: 0.0022 - val_accuracy: 0.9852\n",
      "Epoch 75/100\n",
      "6750/6750 [==============================] - 30s 5ms/step - loss: 0.0018 - accuracy: 0.9893 - val_loss: 0.0021 - val_accuracy: 0.9857\n",
      "Epoch 76/100\n",
      "6750/6750 [==============================] - 30s 5ms/step - loss: 0.0018 - accuracy: 0.9893 - val_loss: 0.0023 - val_accuracy: 0.9852\n",
      "Epoch 77/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0018 - accuracy: 0.9895 - val_loss: 0.0022 - val_accuracy: 0.9870\n",
      "Epoch 78/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0018 - accuracy: 0.9895 - val_loss: 0.0022 - val_accuracy: 0.9850\n",
      "Epoch 79/100\n",
      "6750/6750 [==============================] - 30s 4ms/step - loss: 0.0018 - accuracy: 0.9896 - val_loss: 0.0021 - val_accuracy: 0.9857\n",
      "Epoch 80/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0018 - accuracy: 0.9896 - val_loss: 0.0022 - val_accuracy: 0.9860\n",
      "Epoch 81/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0018 - accuracy: 0.9894 - val_loss: 0.0021 - val_accuracy: 0.9868\n",
      "Epoch 82/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0018 - accuracy: 0.9902 - val_loss: 0.0022 - val_accuracy: 0.9858\n",
      "Epoch 83/100\n",
      "6750/6750 [==============================] - 30s 4ms/step - loss: 0.0018 - accuracy: 0.9898 - val_loss: 0.0021 - val_accuracy: 0.9877\n",
      "Epoch 84/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0017 - accuracy: 0.9898 - val_loss: 0.0022 - val_accuracy: 0.9872\n",
      "Epoch 85/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0018 - accuracy: 0.9896 - val_loss: 0.0021 - val_accuracy: 0.9857\n",
      "Epoch 86/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0017 - accuracy: 0.9899 - val_loss: 0.0021 - val_accuracy: 0.9863\n",
      "Epoch 87/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0017 - accuracy: 0.9900 - val_loss: 0.0021 - val_accuracy: 0.9867\n",
      "Epoch 88/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0017 - accuracy: 0.9899 - val_loss: 0.0021 - val_accuracy: 0.9868\n",
      "Epoch 89/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0017 - accuracy: 0.9900 - val_loss: 0.0021 - val_accuracy: 0.9867\n",
      "Epoch 90/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0017 - accuracy: 0.9901 - val_loss: 0.0021 - val_accuracy: 0.9863\n",
      "Epoch 91/100\n",
      "6750/6750 [==============================] - 30s 4ms/step - loss: 0.0017 - accuracy: 0.9901 - val_loss: 0.0021 - val_accuracy: 0.9855\n",
      "Epoch 92/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0017 - accuracy: 0.9901 - val_loss: 0.0021 - val_accuracy: 0.9862\n",
      "Epoch 93/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0017 - accuracy: 0.9901 - val_loss: 0.0021 - val_accuracy: 0.9863\n",
      "Epoch 94/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0017 - accuracy: 0.9901 - val_loss: 0.0021 - val_accuracy: 0.9872\n",
      "Epoch 95/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0017 - accuracy: 0.9900 - val_loss: 0.0021 - val_accuracy: 0.9872\n",
      "Epoch 96/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0017 - accuracy: 0.9901 - val_loss: 0.0021 - val_accuracy: 0.9863\n",
      "Epoch 97/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0017 - accuracy: 0.9902 - val_loss: 0.0022 - val_accuracy: 0.9860\n",
      "Epoch 98/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0016 - accuracy: 0.9905 - val_loss: 0.0022 - val_accuracy: 0.9857\n",
      "Epoch 99/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0016 - accuracy: 0.9907 - val_loss: 0.0021 - val_accuracy: 0.9870\n",
      "Epoch 100/100\n",
      "6750/6750 [==============================] - 30s 5ms/step - loss: 0.0016 - accuracy: 0.9907 - val_loss: 0.0021 - val_accuracy: 0.9865\n",
      "313/313 - 1s - loss: 0.0020 - accuracy: 0.9876\n",
      "testSetLoss: 0.002010312397032976 - testSetAccuracy: 0.9876000285148621%\n"
     ]
    }
   ],
   "source": [
    "test3_8 = trainModel3(100, 8)\n",
    "hist_df = pd.DataFrame(test3_8.history)\n",
    "hist_json_file = 'test3_8.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_18 (Averag (None, 6, 6, 6)           0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                2170      \n",
      "=================================================================\n",
      "Total params: 2,326\n",
      "Trainable params: 2,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "3375/3375 [==============================] - 13s 4ms/step - loss: 0.0348 - accuracy: 0.7681 - val_loss: 0.0135 - val_accuracy: 0.9240\n",
      "Epoch 2/100\n",
      "3375/3375 [==============================] - 13s 4ms/step - loss: 0.0148 - accuracy: 0.9080 - val_loss: 0.0099 - val_accuracy: 0.9393\n",
      "Epoch 3/100\n",
      "3375/3375 [==============================] - 13s 4ms/step - loss: 0.0119 - accuracy: 0.9257 - val_loss: 0.0084 - val_accuracy: 0.9500\n",
      "Epoch 4/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0102 - accuracy: 0.9369 - val_loss: 0.0071 - val_accuracy: 0.9588\n",
      "Epoch 5/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0089 - accuracy: 0.9447 - val_loss: 0.0065 - val_accuracy: 0.9608\n",
      "Epoch 6/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0080 - accuracy: 0.9506 - val_loss: 0.0055 - val_accuracy: 0.9692\n",
      "Epoch 7/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0072 - accuracy: 0.9561 - val_loss: 0.0054 - val_accuracy: 0.9702\n",
      "Epoch 8/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0067 - accuracy: 0.9600 - val_loss: 0.0048 - val_accuracy: 0.9733\n",
      "Epoch 9/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0062 - accuracy: 0.9629 - val_loss: 0.0046 - val_accuracy: 0.9737\n",
      "Epoch 10/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0058 - accuracy: 0.9654 - val_loss: 0.0045 - val_accuracy: 0.9745\n",
      "Epoch 11/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0055 - accuracy: 0.9676 - val_loss: 0.0041 - val_accuracy: 0.9753\n",
      "Epoch 12/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0052 - accuracy: 0.9691 - val_loss: 0.0039 - val_accuracy: 0.9768\n",
      "Epoch 13/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0050 - accuracy: 0.9706 - val_loss: 0.0037 - val_accuracy: 0.9780\n",
      "Epoch 14/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0048 - accuracy: 0.9716 - val_loss: 0.0035 - val_accuracy: 0.9798\n",
      "Epoch 15/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0046 - accuracy: 0.9725 - val_loss: 0.0034 - val_accuracy: 0.9798\n",
      "Epoch 16/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0044 - accuracy: 0.9733 - val_loss: 0.0035 - val_accuracy: 0.9788\n",
      "Epoch 17/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0043 - accuracy: 0.9747 - val_loss: 0.0032 - val_accuracy: 0.9817\n",
      "Epoch 18/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0042 - accuracy: 0.9752 - val_loss: 0.0032 - val_accuracy: 0.9817\n",
      "Epoch 19/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0040 - accuracy: 0.9761 - val_loss: 0.0030 - val_accuracy: 0.9813\n",
      "Epoch 20/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0039 - accuracy: 0.9768 - val_loss: 0.0030 - val_accuracy: 0.9817\n",
      "Epoch 21/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0038 - accuracy: 0.9771 - val_loss: 0.0031 - val_accuracy: 0.9802\n",
      "Epoch 22/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0037 - accuracy: 0.9781 - val_loss: 0.0029 - val_accuracy: 0.9827\n",
      "Epoch 23/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0036 - accuracy: 0.9784 - val_loss: 0.0027 - val_accuracy: 0.9837\n",
      "Epoch 24/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0035 - accuracy: 0.9794 - val_loss: 0.0028 - val_accuracy: 0.9828\n",
      "Epoch 25/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0035 - accuracy: 0.9792 - val_loss: 0.0029 - val_accuracy: 0.9820\n",
      "Epoch 26/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0034 - accuracy: 0.9800 - val_loss: 0.0027 - val_accuracy: 0.9845\n",
      "Epoch 27/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0033 - accuracy: 0.9803 - val_loss: 0.0027 - val_accuracy: 0.9823\n",
      "Epoch 28/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0033 - accuracy: 0.9804 - val_loss: 0.0026 - val_accuracy: 0.9843\n",
      "Epoch 29/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0032 - accuracy: 0.9809 - val_loss: 0.0028 - val_accuracy: 0.9820\n",
      "Epoch 30/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0031 - accuracy: 0.9812 - val_loss: 0.0025 - val_accuracy: 0.9848\n",
      "Epoch 31/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0031 - accuracy: 0.9817 - val_loss: 0.0026 - val_accuracy: 0.9837\n",
      "Epoch 32/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0030 - accuracy: 0.9818 - val_loss: 0.0026 - val_accuracy: 0.9830\n",
      "Epoch 33/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0030 - accuracy: 0.9821 - val_loss: 0.0026 - val_accuracy: 0.9833\n",
      "Epoch 34/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0030 - accuracy: 0.9824 - val_loss: 0.0027 - val_accuracy: 0.9828\n",
      "Epoch 35/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0029 - accuracy: 0.9824 - val_loss: 0.0025 - val_accuracy: 0.9852\n",
      "Epoch 36/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0029 - accuracy: 0.9829 - val_loss: 0.0026 - val_accuracy: 0.9845\n",
      "Epoch 37/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0028 - accuracy: 0.9830 - val_loss: 0.0024 - val_accuracy: 0.9850\n",
      "Epoch 38/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0028 - accuracy: 0.9833 - val_loss: 0.0026 - val_accuracy: 0.9848\n",
      "Epoch 39/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0028 - accuracy: 0.9833 - val_loss: 0.0025 - val_accuracy: 0.9845\n",
      "Epoch 40/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0028 - accuracy: 0.9834 - val_loss: 0.0024 - val_accuracy: 0.9850\n",
      "Epoch 41/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0027 - accuracy: 0.9837 - val_loss: 0.0025 - val_accuracy: 0.9843\n",
      "Epoch 42/100\n",
      "3375/3375 [==============================] - 15s 4ms/step - loss: 0.0027 - accuracy: 0.9840 - val_loss: 0.0025 - val_accuracy: 0.9852\n",
      "Epoch 43/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0027 - accuracy: 0.9838 - val_loss: 0.0025 - val_accuracy: 0.9838\n",
      "Epoch 44/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0027 - accuracy: 0.9837 - val_loss: 0.0024 - val_accuracy: 0.9848\n",
      "Epoch 45/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0026 - accuracy: 0.9842 - val_loss: 0.0024 - val_accuracy: 0.9850\n",
      "Epoch 46/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0026 - accuracy: 0.9846 - val_loss: 0.0024 - val_accuracy: 0.9845\n",
      "Epoch 47/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0026 - accuracy: 0.9847 - val_loss: 0.0024 - val_accuracy: 0.9848\n",
      "Epoch 48/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0026 - accuracy: 0.9845 - val_loss: 0.0027 - val_accuracy: 0.9825\n",
      "Epoch 49/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0025 - accuracy: 0.9850 - val_loss: 0.0024 - val_accuracy: 0.9845\n",
      "Epoch 50/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0025 - accuracy: 0.9849 - val_loss: 0.0023 - val_accuracy: 0.9848\n",
      "Epoch 51/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0025 - accuracy: 0.9849 - val_loss: 0.0023 - val_accuracy: 0.9863\n",
      "Epoch 52/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0025 - accuracy: 0.9850 - val_loss: 0.0024 - val_accuracy: 0.9850\n",
      "Epoch 53/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0024 - accuracy: 0.9857 - val_loss: 0.0024 - val_accuracy: 0.9858\n",
      "Epoch 54/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0024 - accuracy: 0.9852 - val_loss: 0.0023 - val_accuracy: 0.9853\n",
      "Epoch 55/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0024 - accuracy: 0.9857 - val_loss: 0.0023 - val_accuracy: 0.9853\n",
      "Epoch 56/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0024 - accuracy: 0.9856 - val_loss: 0.0023 - val_accuracy: 0.9858\n",
      "Epoch 57/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0024 - accuracy: 0.9855 - val_loss: 0.0025 - val_accuracy: 0.9840\n",
      "Epoch 58/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0024 - accuracy: 0.9861 - val_loss: 0.0025 - val_accuracy: 0.9847\n",
      "Epoch 59/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0023 - accuracy: 0.9857 - val_loss: 0.0023 - val_accuracy: 0.9843\n",
      "Epoch 60/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0023 - accuracy: 0.9860 - val_loss: 0.0023 - val_accuracy: 0.9842\n",
      "Epoch 61/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0023 - accuracy: 0.9861 - val_loss: 0.0023 - val_accuracy: 0.9852\n",
      "Epoch 62/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0023 - accuracy: 0.9865 - val_loss: 0.0024 - val_accuracy: 0.9848\n",
      "Epoch 63/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0023 - accuracy: 0.9864 - val_loss: 0.0023 - val_accuracy: 0.9852\n",
      "Epoch 64/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0023 - accuracy: 0.9862 - val_loss: 0.0024 - val_accuracy: 0.9845\n",
      "Epoch 65/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0023 - accuracy: 0.9864 - val_loss: 0.0025 - val_accuracy: 0.9840\n",
      "Epoch 66/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0022 - accuracy: 0.9867 - val_loss: 0.0022 - val_accuracy: 0.9858\n",
      "Epoch 67/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0022 - accuracy: 0.9866 - val_loss: 0.0023 - val_accuracy: 0.9852\n",
      "Epoch 68/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0022 - accuracy: 0.9866 - val_loss: 0.0022 - val_accuracy: 0.9862\n",
      "Epoch 69/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0022 - accuracy: 0.9868 - val_loss: 0.0022 - val_accuracy: 0.9855\n",
      "Epoch 70/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0022 - accuracy: 0.9868 - val_loss: 0.0022 - val_accuracy: 0.9855\n",
      "Epoch 71/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0022 - accuracy: 0.9868 - val_loss: 0.0022 - val_accuracy: 0.9857\n",
      "Epoch 72/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0022 - accuracy: 0.9872 - val_loss: 0.0022 - val_accuracy: 0.9858\n",
      "Epoch 73/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0022 - accuracy: 0.9870 - val_loss: 0.0022 - val_accuracy: 0.9865\n",
      "Epoch 74/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0022 - accuracy: 0.9869 - val_loss: 0.0022 - val_accuracy: 0.9852\n",
      "Epoch 75/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0021 - accuracy: 0.9871 - val_loss: 0.0023 - val_accuracy: 0.9847\n",
      "Epoch 76/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0021 - accuracy: 0.9881 - val_loss: 0.0021 - val_accuracy: 0.9860\n",
      "Epoch 77/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0021 - accuracy: 0.9874 - val_loss: 0.0022 - val_accuracy: 0.9860\n",
      "Epoch 78/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0021 - accuracy: 0.9873 - val_loss: 0.0022 - val_accuracy: 0.9857\n",
      "Epoch 79/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0021 - accuracy: 0.9874 - val_loss: 0.0022 - val_accuracy: 0.9853\n",
      "Epoch 80/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0021 - accuracy: 0.9876 - val_loss: 0.0021 - val_accuracy: 0.9858\n",
      "Epoch 81/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0021 - accuracy: 0.9876 - val_loss: 0.0023 - val_accuracy: 0.9847\n",
      "Epoch 82/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0021 - accuracy: 0.9876 - val_loss: 0.0021 - val_accuracy: 0.9863\n",
      "Epoch 83/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0021 - accuracy: 0.9878 - val_loss: 0.0022 - val_accuracy: 0.9847\n",
      "Epoch 84/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0020 - accuracy: 0.9878 - val_loss: 0.0023 - val_accuracy: 0.9852\n",
      "Epoch 85/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0020 - accuracy: 0.9881 - val_loss: 0.0022 - val_accuracy: 0.9860\n",
      "Epoch 86/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0020 - accuracy: 0.9882 - val_loss: 0.0023 - val_accuracy: 0.9853\n",
      "Epoch 87/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0020 - accuracy: 0.9880 - val_loss: 0.0022 - val_accuracy: 0.9863\n",
      "Epoch 88/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0020 - accuracy: 0.9882 - val_loss: 0.0022 - val_accuracy: 0.9858\n",
      "Epoch 89/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0020 - accuracy: 0.9881 - val_loss: 0.0021 - val_accuracy: 0.9865\n",
      "Epoch 90/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0020 - accuracy: 0.9882 - val_loss: 0.0022 - val_accuracy: 0.9855\n",
      "Epoch 91/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0020 - accuracy: 0.9881 - val_loss: 0.0022 - val_accuracy: 0.9855\n",
      "Epoch 92/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0020 - accuracy: 0.9883 - val_loss: 0.0022 - val_accuracy: 0.9857\n",
      "Epoch 93/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0020 - accuracy: 0.9880 - val_loss: 0.0021 - val_accuracy: 0.9858\n",
      "Epoch 94/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0020 - accuracy: 0.9883 - val_loss: 0.0021 - val_accuracy: 0.9862\n",
      "Epoch 95/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0020 - accuracy: 0.9884 - val_loss: 0.0022 - val_accuracy: 0.9857\n",
      "Epoch 96/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0019 - accuracy: 0.9888 - val_loss: 0.0022 - val_accuracy: 0.9862\n",
      "Epoch 97/100\n",
      "3375/3375 [==============================] - 15s 5ms/step - loss: 0.0019 - accuracy: 0.9886 - val_loss: 0.0021 - val_accuracy: 0.9853\n",
      "Epoch 98/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0019 - accuracy: 0.9888 - val_loss: 0.0022 - val_accuracy: 0.9853\n",
      "Epoch 99/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0019 - accuracy: 0.9887 - val_loss: 0.0021 - val_accuracy: 0.9863\n",
      "Epoch 100/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0019 - accuracy: 0.9885 - val_loss: 0.0021 - val_accuracy: 0.9862\n",
      "313/313 - 1s - loss: 0.0022 - accuracy: 0.9851\n",
      "testSetLoss: 0.002181422431021929 - testSetAccuracy: 0.9850999712944031%\n"
     ]
    }
   ],
   "source": [
    "test3_16 = trainModel3(100, 16)\n",
    "hist_df = pd.DataFrame(test3_16.history)\n",
    "hist_json_file = 'test3_16.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_19 (Averag (None, 6, 6, 6)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                2170      \n",
      "=================================================================\n",
      "Total params: 2,326\n",
      "Trainable params: 2,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0453 - accuracy: 0.7003 - val_loss: 0.0174 - val_accuracy: 0.9073\n",
      "Epoch 2/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0180 - accuracy: 0.8925 - val_loss: 0.0124 - val_accuracy: 0.9283\n",
      "Epoch 3/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0145 - accuracy: 0.9107 - val_loss: 0.0105 - val_accuracy: 0.9358\n",
      "Epoch 4/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0126 - accuracy: 0.9226 - val_loss: 0.0092 - val_accuracy: 0.9437\n",
      "Epoch 5/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0112 - accuracy: 0.9319 - val_loss: 0.0082 - val_accuracy: 0.9488\n",
      "Epoch 6/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0101 - accuracy: 0.9384 - val_loss: 0.0074 - val_accuracy: 0.9548\n",
      "Epoch 7/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0092 - accuracy: 0.9438 - val_loss: 0.0068 - val_accuracy: 0.9587\n",
      "Epoch 8/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0084 - accuracy: 0.9487 - val_loss: 0.0062 - val_accuracy: 0.9635\n",
      "Epoch 9/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0078 - accuracy: 0.9524 - val_loss: 0.0059 - val_accuracy: 0.9647\n",
      "Epoch 10/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0073 - accuracy: 0.9559 - val_loss: 0.0054 - val_accuracy: 0.9673\n",
      "Epoch 11/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0069 - accuracy: 0.9584 - val_loss: 0.0052 - val_accuracy: 0.9677\n",
      "Epoch 12/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0065 - accuracy: 0.9610 - val_loss: 0.0051 - val_accuracy: 0.9683\n",
      "Epoch 13/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0062 - accuracy: 0.9626 - val_loss: 0.0048 - val_accuracy: 0.9713\n",
      "Epoch 14/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0060 - accuracy: 0.9641 - val_loss: 0.0046 - val_accuracy: 0.9732\n",
      "Epoch 15/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0057 - accuracy: 0.9657 - val_loss: 0.0045 - val_accuracy: 0.9713\n",
      "Epoch 16/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0055 - accuracy: 0.9671 - val_loss: 0.0042 - val_accuracy: 0.9733\n",
      "Epoch 17/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0053 - accuracy: 0.9681 - val_loss: 0.0042 - val_accuracy: 0.9758\n",
      "Epoch 18/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0052 - accuracy: 0.9690 - val_loss: 0.0041 - val_accuracy: 0.9747\n",
      "Epoch 19/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0050 - accuracy: 0.9702 - val_loss: 0.0040 - val_accuracy: 0.9758\n",
      "Epoch 20/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0049 - accuracy: 0.9709 - val_loss: 0.0038 - val_accuracy: 0.9767\n",
      "Epoch 21/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0048 - accuracy: 0.9717 - val_loss: 0.0038 - val_accuracy: 0.9772\n",
      "Epoch 22/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0046 - accuracy: 0.9728 - val_loss: 0.0037 - val_accuracy: 0.9762\n",
      "Epoch 23/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0045 - accuracy: 0.9728 - val_loss: 0.0036 - val_accuracy: 0.9772\n",
      "Epoch 24/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0045 - accuracy: 0.9734 - val_loss: 0.0035 - val_accuracy: 0.9785\n",
      "Epoch 25/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0043 - accuracy: 0.9741 - val_loss: 0.0036 - val_accuracy: 0.9778\n",
      "Epoch 26/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0043 - accuracy: 0.9749 - val_loss: 0.0035 - val_accuracy: 0.9785\n",
      "Epoch 27/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0042 - accuracy: 0.9752 - val_loss: 0.0034 - val_accuracy: 0.9798\n",
      "Epoch 28/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0041 - accuracy: 0.9758 - val_loss: 0.0034 - val_accuracy: 0.9787\n",
      "Epoch 29/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0040 - accuracy: 0.9761 - val_loss: 0.0033 - val_accuracy: 0.9800\n",
      "Epoch 30/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0040 - accuracy: 0.9766 - val_loss: 0.0033 - val_accuracy: 0.9793\n",
      "Epoch 31/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0039 - accuracy: 0.9769 - val_loss: 0.0033 - val_accuracy: 0.9802\n",
      "Epoch 32/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0038 - accuracy: 0.9774 - val_loss: 0.0032 - val_accuracy: 0.9795\n",
      "Epoch 33/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0038 - accuracy: 0.9780 - val_loss: 0.0031 - val_accuracy: 0.9813\n",
      "Epoch 34/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0037 - accuracy: 0.9783 - val_loss: 0.0032 - val_accuracy: 0.9802\n",
      "Epoch 35/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0037 - accuracy: 0.9786 - val_loss: 0.0031 - val_accuracy: 0.9807\n",
      "Epoch 36/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0036 - accuracy: 0.9786 - val_loss: 0.0031 - val_accuracy: 0.9797\n",
      "Epoch 37/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0036 - accuracy: 0.9792 - val_loss: 0.0029 - val_accuracy: 0.9822\n",
      "Epoch 38/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0035 - accuracy: 0.9797 - val_loss: 0.0030 - val_accuracy: 0.9812\n",
      "Epoch 39/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0034 - accuracy: 0.9801 - val_loss: 0.0029 - val_accuracy: 0.9822\n",
      "Epoch 40/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0034 - accuracy: 0.9801 - val_loss: 0.0030 - val_accuracy: 0.9813\n",
      "Epoch 41/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0034 - accuracy: 0.9805 - val_loss: 0.0029 - val_accuracy: 0.9822\n",
      "Epoch 42/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0033 - accuracy: 0.9808 - val_loss: 0.0028 - val_accuracy: 0.9832\n",
      "Epoch 43/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0033 - accuracy: 0.9813 - val_loss: 0.0030 - val_accuracy: 0.9828\n",
      "Epoch 44/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0032 - accuracy: 0.9809 - val_loss: 0.0028 - val_accuracy: 0.9835\n",
      "Epoch 45/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0032 - accuracy: 0.9816 - val_loss: 0.0028 - val_accuracy: 0.9835\n",
      "Epoch 46/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0032 - accuracy: 0.9819 - val_loss: 0.0028 - val_accuracy: 0.9825\n",
      "Epoch 47/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0031 - accuracy: 0.9819 - val_loss: 0.0028 - val_accuracy: 0.9835\n",
      "Epoch 48/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0031 - accuracy: 0.9821 - val_loss: 0.0027 - val_accuracy: 0.9825\n",
      "Epoch 49/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0031 - accuracy: 0.9824 - val_loss: 0.0029 - val_accuracy: 0.9815\n",
      "Epoch 50/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0030 - accuracy: 0.9826 - val_loss: 0.0027 - val_accuracy: 0.9837\n",
      "Epoch 51/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0030 - accuracy: 0.9829 - val_loss: 0.0028 - val_accuracy: 0.9828\n",
      "Epoch 52/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0030 - accuracy: 0.9834 - val_loss: 0.0026 - val_accuracy: 0.9833\n",
      "Epoch 53/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0029 - accuracy: 0.9828 - val_loss: 0.0027 - val_accuracy: 0.9828\n",
      "Epoch 54/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0029 - accuracy: 0.9833 - val_loss: 0.0026 - val_accuracy: 0.9835\n",
      "Epoch 55/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0029 - accuracy: 0.9834 - val_loss: 0.0027 - val_accuracy: 0.9825\n",
      "Epoch 56/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0028 - accuracy: 0.9838 - val_loss: 0.0028 - val_accuracy: 0.9830\n",
      "Epoch 57/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0028 - accuracy: 0.9838 - val_loss: 0.0026 - val_accuracy: 0.9837\n",
      "Epoch 58/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0028 - accuracy: 0.9841 - val_loss: 0.0026 - val_accuracy: 0.9830\n",
      "Epoch 59/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0028 - accuracy: 0.9843 - val_loss: 0.0026 - val_accuracy: 0.9840\n",
      "Epoch 60/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0028 - accuracy: 0.9842 - val_loss: 0.0026 - val_accuracy: 0.9837\n",
      "Epoch 61/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0027 - accuracy: 0.9845 - val_loss: 0.0027 - val_accuracy: 0.9835\n",
      "Epoch 62/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0027 - accuracy: 0.9844 - val_loss: 0.0025 - val_accuracy: 0.9843\n",
      "Epoch 63/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0027 - accuracy: 0.9846 - val_loss: 0.0026 - val_accuracy: 0.9838\n",
      "Epoch 64/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0027 - accuracy: 0.9844 - val_loss: 0.0025 - val_accuracy: 0.9845\n",
      "Epoch 65/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0026 - accuracy: 0.9847 - val_loss: 0.0026 - val_accuracy: 0.9828\n",
      "Epoch 66/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0026 - accuracy: 0.9852 - val_loss: 0.0025 - val_accuracy: 0.9838\n",
      "Epoch 67/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0026 - accuracy: 0.9851 - val_loss: 0.0024 - val_accuracy: 0.9850\n",
      "Epoch 68/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0026 - accuracy: 0.9850 - val_loss: 0.0025 - val_accuracy: 0.9843\n",
      "Epoch 69/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0026 - accuracy: 0.9852 - val_loss: 0.0025 - val_accuracy: 0.9833\n",
      "Epoch 70/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0026 - accuracy: 0.9852 - val_loss: 0.0025 - val_accuracy: 0.9838\n",
      "Epoch 71/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0025 - accuracy: 0.9853 - val_loss: 0.0025 - val_accuracy: 0.9845\n",
      "Epoch 72/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0025 - accuracy: 0.9856 - val_loss: 0.0025 - val_accuracy: 0.9852\n",
      "Epoch 73/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0025 - accuracy: 0.9854 - val_loss: 0.0025 - val_accuracy: 0.9838\n",
      "Epoch 74/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0025 - accuracy: 0.9857 - val_loss: 0.0024 - val_accuracy: 0.9845\n",
      "Epoch 75/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0025 - accuracy: 0.9856 - val_loss: 0.0024 - val_accuracy: 0.9838\n",
      "Epoch 76/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0024 - accuracy: 0.9860 - val_loss: 0.0025 - val_accuracy: 0.9838\n",
      "Epoch 77/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0024 - accuracy: 0.9856 - val_loss: 0.0024 - val_accuracy: 0.9848\n",
      "Epoch 78/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0024 - accuracy: 0.9858 - val_loss: 0.0024 - val_accuracy: 0.9845\n",
      "Epoch 79/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0024 - accuracy: 0.9862 - val_loss: 0.0025 - val_accuracy: 0.9837\n",
      "Epoch 80/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0024 - accuracy: 0.9860 - val_loss: 0.0024 - val_accuracy: 0.9845\n",
      "Epoch 81/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0024 - accuracy: 0.9864 - val_loss: 0.0023 - val_accuracy: 0.9847\n",
      "Epoch 82/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0024 - accuracy: 0.9864 - val_loss: 0.0024 - val_accuracy: 0.9847\n",
      "Epoch 83/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0024 - accuracy: 0.9864 - val_loss: 0.0023 - val_accuracy: 0.9850\n",
      "Epoch 84/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0023 - accuracy: 0.9864 - val_loss: 0.0023 - val_accuracy: 0.9853\n",
      "Epoch 85/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0023 - accuracy: 0.9866 - val_loss: 0.0025 - val_accuracy: 0.9842\n",
      "Epoch 86/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0023 - accuracy: 0.9865 - val_loss: 0.0024 - val_accuracy: 0.9847\n",
      "Epoch 87/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0023 - accuracy: 0.9866 - val_loss: 0.0024 - val_accuracy: 0.9845\n",
      "Epoch 88/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0023 - accuracy: 0.9869 - val_loss: 0.0023 - val_accuracy: 0.9850\n",
      "Epoch 89/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0023 - accuracy: 0.9865 - val_loss: 0.0024 - val_accuracy: 0.9847\n",
      "Epoch 90/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0023 - accuracy: 0.9870 - val_loss: 0.0024 - val_accuracy: 0.9843\n",
      "Epoch 91/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0023 - accuracy: 0.9870 - val_loss: 0.0023 - val_accuracy: 0.9852\n",
      "Epoch 92/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0023 - accuracy: 0.9869 - val_loss: 0.0023 - val_accuracy: 0.9857\n",
      "Epoch 93/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0022 - accuracy: 0.9870 - val_loss: 0.0024 - val_accuracy: 0.9852\n",
      "Epoch 94/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0022 - accuracy: 0.9872 - val_loss: 0.0024 - val_accuracy: 0.9848\n",
      "Epoch 95/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0022 - accuracy: 0.9874 - val_loss: 0.0023 - val_accuracy: 0.9847\n",
      "Epoch 96/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.0022 - accuracy: 0.9873 - val_loss: 0.0023 - val_accuracy: 0.9855\n",
      "Epoch 97/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0022 - accuracy: 0.9876 - val_loss: 0.0024 - val_accuracy: 0.9850\n",
      "Epoch 98/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0022 - accuracy: 0.9873 - val_loss: 0.0023 - val_accuracy: 0.9857\n",
      "Epoch 99/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0022 - accuracy: 0.9880 - val_loss: 0.0023 - val_accuracy: 0.9852\n",
      "Epoch 100/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0022 - accuracy: 0.9875 - val_loss: 0.0023 - val_accuracy: 0.9848\n",
      "313/313 - 1s - loss: 0.0025 - accuracy: 0.9838\n",
      "testSetLoss: 0.0024604354985058308 - testSetAccuracy: 0.9837999939918518%\n"
     ]
    }
   ],
   "source": [
    "test3_32 = trainModel3(100, 32)\n",
    "hist_df = pd.DataFrame(test3_32.history)\n",
    "hist_json_file = 'test3_32.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_20 (Averag (None, 6, 6, 6)           0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                2170      \n",
      "=================================================================\n",
      "Total params: 2,326\n",
      "Trainable params: 2,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0536 - accuracy: 0.6379 - val_loss: 0.0222 - val_accuracy: 0.8910\n",
      "Epoch 2/100\n",
      "844/844 [==============================] - 4s 5ms/step - loss: 0.0216 - accuracy: 0.8722 - val_loss: 0.0150 - val_accuracy: 0.9127\n",
      "Epoch 3/100\n",
      "844/844 [==============================] - 4s 5ms/step - loss: 0.0174 - accuracy: 0.8916 - val_loss: 0.0127 - val_accuracy: 0.9252\n",
      "Epoch 4/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0154 - accuracy: 0.9029 - val_loss: 0.0115 - val_accuracy: 0.9305\n",
      "Epoch 5/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0141 - accuracy: 0.9106 - val_loss: 0.0105 - val_accuracy: 0.9348\n",
      "Epoch 6/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0131 - accuracy: 0.9177 - val_loss: 0.0099 - val_accuracy: 0.9387\n",
      "Epoch 7/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0122 - accuracy: 0.9239 - val_loss: 0.0091 - val_accuracy: 0.9447\n",
      "Epoch 8/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0113 - accuracy: 0.9296 - val_loss: 0.0085 - val_accuracy: 0.9480\n",
      "Epoch 9/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0107 - accuracy: 0.9339 - val_loss: 0.0081 - val_accuracy: 0.9510\n",
      "Epoch 10/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0100 - accuracy: 0.9382 - val_loss: 0.0074 - val_accuracy: 0.9553\n",
      "Epoch 11/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0094 - accuracy: 0.9423 - val_loss: 0.0071 - val_accuracy: 0.9582\n",
      "Epoch 12/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0089 - accuracy: 0.9456 - val_loss: 0.0067 - val_accuracy: 0.9607\n",
      "Epoch 13/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0084 - accuracy: 0.9486 - val_loss: 0.0064 - val_accuracy: 0.9623\n",
      "Epoch 14/100\n",
      "844/844 [==============================] - 4s 5ms/step - loss: 0.0080 - accuracy: 0.9517 - val_loss: 0.0062 - val_accuracy: 0.9638\n",
      "Epoch 15/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0077 - accuracy: 0.9537 - val_loss: 0.0058 - val_accuracy: 0.9663\n",
      "Epoch 16/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0073 - accuracy: 0.9563 - val_loss: 0.0056 - val_accuracy: 0.9662\n",
      "Epoch 17/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0070 - accuracy: 0.9576 - val_loss: 0.0054 - val_accuracy: 0.9685\n",
      "Epoch 18/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0068 - accuracy: 0.9599 - val_loss: 0.0052 - val_accuracy: 0.9707\n",
      "Epoch 19/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0065 - accuracy: 0.9611 - val_loss: 0.0050 - val_accuracy: 0.9723\n",
      "Epoch 20/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0063 - accuracy: 0.9620 - val_loss: 0.0048 - val_accuracy: 0.9725\n",
      "Epoch 21/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0061 - accuracy: 0.9636 - val_loss: 0.0047 - val_accuracy: 0.9737\n",
      "Epoch 22/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0059 - accuracy: 0.9649 - val_loss: 0.0047 - val_accuracy: 0.9747\n",
      "Epoch 23/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0057 - accuracy: 0.9660 - val_loss: 0.0046 - val_accuracy: 0.9728\n",
      "Epoch 24/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0056 - accuracy: 0.9673 - val_loss: 0.0045 - val_accuracy: 0.9750\n",
      "Epoch 25/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0054 - accuracy: 0.9682 - val_loss: 0.0043 - val_accuracy: 0.9760\n",
      "Epoch 26/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0053 - accuracy: 0.9691 - val_loss: 0.0041 - val_accuracy: 0.9763\n",
      "Epoch 27/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0052 - accuracy: 0.9697 - val_loss: 0.0042 - val_accuracy: 0.9753\n",
      "Epoch 28/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0050 - accuracy: 0.9707 - val_loss: 0.0040 - val_accuracy: 0.9768\n",
      "Epoch 29/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0049 - accuracy: 0.9719 - val_loss: 0.0040 - val_accuracy: 0.9762\n",
      "Epoch 30/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0048 - accuracy: 0.9720 - val_loss: 0.0038 - val_accuracy: 0.9773\n",
      "Epoch 31/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0047 - accuracy: 0.9723 - val_loss: 0.0037 - val_accuracy: 0.9780\n",
      "Epoch 32/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0046 - accuracy: 0.9735 - val_loss: 0.0038 - val_accuracy: 0.9772\n",
      "Epoch 33/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0045 - accuracy: 0.9736 - val_loss: 0.0036 - val_accuracy: 0.9785\n",
      "Epoch 34/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0045 - accuracy: 0.9741 - val_loss: 0.0035 - val_accuracy: 0.9803\n",
      "Epoch 35/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0044 - accuracy: 0.9746 - val_loss: 0.0037 - val_accuracy: 0.9782\n",
      "Epoch 36/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0043 - accuracy: 0.9753 - val_loss: 0.0035 - val_accuracy: 0.9793\n",
      "Epoch 37/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0042 - accuracy: 0.9754 - val_loss: 0.0034 - val_accuracy: 0.9805\n",
      "Epoch 38/100\n",
      "844/844 [==============================] - 4s 5ms/step - loss: 0.0042 - accuracy: 0.9760 - val_loss: 0.0034 - val_accuracy: 0.9805\n",
      "Epoch 39/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0041 - accuracy: 0.9760 - val_loss: 0.0033 - val_accuracy: 0.9807\n",
      "Epoch 40/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0041 - accuracy: 0.9763 - val_loss: 0.0033 - val_accuracy: 0.9802\n",
      "Epoch 41/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0040 - accuracy: 0.9770 - val_loss: 0.0033 - val_accuracy: 0.9802\n",
      "Epoch 42/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0039 - accuracy: 0.9773 - val_loss: 0.0032 - val_accuracy: 0.9808\n",
      "Epoch 43/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0039 - accuracy: 0.9774 - val_loss: 0.0033 - val_accuracy: 0.9792\n",
      "Epoch 44/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0038 - accuracy: 0.9776 - val_loss: 0.0032 - val_accuracy: 0.9803\n",
      "Epoch 45/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0038 - accuracy: 0.9783 - val_loss: 0.0031 - val_accuracy: 0.9813\n",
      "Epoch 46/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0037 - accuracy: 0.9783 - val_loss: 0.0033 - val_accuracy: 0.9795\n",
      "Epoch 47/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0037 - accuracy: 0.9786 - val_loss: 0.0031 - val_accuracy: 0.9813\n",
      "Epoch 48/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0037 - accuracy: 0.9787 - val_loss: 0.0030 - val_accuracy: 0.9822\n",
      "Epoch 49/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0036 - accuracy: 0.9794 - val_loss: 0.0031 - val_accuracy: 0.9803\n",
      "Epoch 50/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0036 - accuracy: 0.9791 - val_loss: 0.0030 - val_accuracy: 0.9817\n",
      "Epoch 51/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0035 - accuracy: 0.9796 - val_loss: 0.0029 - val_accuracy: 0.9822\n",
      "Epoch 52/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0035 - accuracy: 0.9798 - val_loss: 0.0030 - val_accuracy: 0.9825\n",
      "Epoch 53/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0035 - accuracy: 0.9802 - val_loss: 0.0031 - val_accuracy: 0.9795\n",
      "Epoch 54/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0034 - accuracy: 0.9804 - val_loss: 0.0029 - val_accuracy: 0.9832\n",
      "Epoch 55/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0034 - accuracy: 0.9805 - val_loss: 0.0029 - val_accuracy: 0.9825\n",
      "Epoch 56/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0034 - accuracy: 0.9806 - val_loss: 0.0028 - val_accuracy: 0.9818\n",
      "Epoch 57/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0033 - accuracy: 0.9806 - val_loss: 0.0029 - val_accuracy: 0.9822\n",
      "Epoch 58/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0033 - accuracy: 0.9807 - val_loss: 0.0028 - val_accuracy: 0.9833\n",
      "Epoch 59/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0033 - accuracy: 0.9810 - val_loss: 0.0027 - val_accuracy: 0.9835\n",
      "Epoch 60/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0033 - accuracy: 0.9813 - val_loss: 0.0029 - val_accuracy: 0.9827\n",
      "Epoch 61/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0032 - accuracy: 0.9814 - val_loss: 0.0028 - val_accuracy: 0.9830\n",
      "Epoch 62/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0032 - accuracy: 0.9814 - val_loss: 0.0027 - val_accuracy: 0.9838\n",
      "Epoch 63/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0032 - accuracy: 0.9818 - val_loss: 0.0027 - val_accuracy: 0.9828\n",
      "Epoch 64/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0031 - accuracy: 0.9816 - val_loss: 0.0029 - val_accuracy: 0.9827\n",
      "Epoch 65/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0031 - accuracy: 0.9819 - val_loss: 0.0027 - val_accuracy: 0.9840\n",
      "Epoch 66/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0031 - accuracy: 0.9822 - val_loss: 0.0027 - val_accuracy: 0.9838\n",
      "Epoch 67/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0031 - accuracy: 0.9821 - val_loss: 0.0027 - val_accuracy: 0.9852\n",
      "Epoch 68/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0031 - accuracy: 0.9823 - val_loss: 0.0027 - val_accuracy: 0.9832\n",
      "Epoch 69/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0030 - accuracy: 0.9826 - val_loss: 0.0026 - val_accuracy: 0.9850\n",
      "Epoch 70/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0030 - accuracy: 0.9828 - val_loss: 0.0026 - val_accuracy: 0.9835\n",
      "Epoch 71/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0030 - accuracy: 0.9826 - val_loss: 0.0027 - val_accuracy: 0.9845\n",
      "Epoch 72/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0030 - accuracy: 0.9829 - val_loss: 0.0027 - val_accuracy: 0.9837\n",
      "Epoch 73/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0030 - accuracy: 0.9831 - val_loss: 0.0026 - val_accuracy: 0.9842\n",
      "Epoch 74/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0029 - accuracy: 0.9830 - val_loss: 0.0026 - val_accuracy: 0.9848\n",
      "Epoch 75/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0029 - accuracy: 0.9829 - val_loss: 0.0025 - val_accuracy: 0.9832\n",
      "Epoch 76/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0029 - accuracy: 0.9831 - val_loss: 0.0026 - val_accuracy: 0.9850\n",
      "Epoch 77/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0029 - accuracy: 0.9830 - val_loss: 0.0026 - val_accuracy: 0.9837\n",
      "Epoch 78/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0029 - accuracy: 0.9830 - val_loss: 0.0025 - val_accuracy: 0.9853\n",
      "Epoch 79/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0028 - accuracy: 0.9833 - val_loss: 0.0026 - val_accuracy: 0.9843\n",
      "Epoch 80/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0028 - accuracy: 0.9836 - val_loss: 0.0025 - val_accuracy: 0.9843\n",
      "Epoch 81/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0028 - accuracy: 0.9834 - val_loss: 0.0027 - val_accuracy: 0.9835\n",
      "Epoch 82/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0028 - accuracy: 0.9837 - val_loss: 0.0025 - val_accuracy: 0.9853\n",
      "Epoch 83/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0028 - accuracy: 0.9839 - val_loss: 0.0026 - val_accuracy: 0.9838\n",
      "Epoch 84/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0028 - accuracy: 0.9838 - val_loss: 0.0025 - val_accuracy: 0.9850\n",
      "Epoch 85/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0028 - accuracy: 0.9840 - val_loss: 0.0025 - val_accuracy: 0.9855\n",
      "Epoch 86/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0027 - accuracy: 0.9842 - val_loss: 0.0025 - val_accuracy: 0.9857\n",
      "Epoch 87/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0027 - accuracy: 0.9842 - val_loss: 0.0026 - val_accuracy: 0.9847\n",
      "Epoch 88/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0027 - accuracy: 0.9842 - val_loss: 0.0025 - val_accuracy: 0.9845\n",
      "Epoch 89/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0027 - accuracy: 0.9846 - val_loss: 0.0025 - val_accuracy: 0.9850\n",
      "Epoch 90/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0027 - accuracy: 0.9842 - val_loss: 0.0025 - val_accuracy: 0.9848\n",
      "Epoch 91/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0027 - accuracy: 0.9845 - val_loss: 0.0024 - val_accuracy: 0.9850\n",
      "Epoch 92/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0027 - accuracy: 0.9843 - val_loss: 0.0025 - val_accuracy: 0.9848\n",
      "Epoch 93/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0027 - accuracy: 0.9844 - val_loss: 0.0026 - val_accuracy: 0.9833\n",
      "Epoch 94/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0026 - accuracy: 0.9848 - val_loss: 0.0024 - val_accuracy: 0.9848\n",
      "Epoch 95/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0027 - accuracy: 0.9845 - val_loss: 0.0024 - val_accuracy: 0.9853\n",
      "Epoch 96/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0026 - accuracy: 0.9848 - val_loss: 0.0024 - val_accuracy: 0.9855\n",
      "Epoch 97/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0026 - accuracy: 0.9846 - val_loss: 0.0024 - val_accuracy: 0.9853\n",
      "Epoch 98/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0026 - accuracy: 0.9853 - val_loss: 0.0024 - val_accuracy: 0.9858\n",
      "Epoch 99/100\n",
      "844/844 [==============================] - 5s 5ms/step - loss: 0.0026 - accuracy: 0.9848 - val_loss: 0.0024 - val_accuracy: 0.9850\n",
      "Epoch 100/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0026 - accuracy: 0.9850 - val_loss: 0.0024 - val_accuracy: 0.9847\n",
      "313/313 - 1s - loss: 0.0026 - accuracy: 0.9839\n",
      "testSetLoss: 0.0026183840818703175 - testSetAccuracy: 0.9839000105857849%\n"
     ]
    }
   ],
   "source": [
    "test3_64 = trainModel3(100, 64)\n",
    "hist_df = pd.DataFrame(test3_64.history)\n",
    "hist_json_file = 'test3_64.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_21 (Averag (None, 6, 6, 6)           0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                2170      \n",
      "=================================================================\n",
      "Total params: 2,326\n",
      "Trainable params: 2,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 3s 5ms/step - loss: 0.0729 - accuracy: 0.4516 - val_loss: 0.0382 - val_accuracy: 0.8175\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0296 - accuracy: 0.8417 - val_loss: 0.0195 - val_accuracy: 0.8990\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0210 - accuracy: 0.8780 - val_loss: 0.0152 - val_accuracy: 0.9133\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0179 - accuracy: 0.8914 - val_loss: 0.0134 - val_accuracy: 0.9238\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0163 - accuracy: 0.8995 - val_loss: 0.0123 - val_accuracy: 0.9260\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0151 - accuracy: 0.9055 - val_loss: 0.0115 - val_accuracy: 0.9308\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0143 - accuracy: 0.9106 - val_loss: 0.0108 - val_accuracy: 0.9357\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.0135 - accuracy: 0.9154 - val_loss: 0.0103 - val_accuracy: 0.9367\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0129 - accuracy: 0.9195 - val_loss: 0.0098 - val_accuracy: 0.9395\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0122 - accuracy: 0.9232 - val_loss: 0.0092 - val_accuracy: 0.9427\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0117 - accuracy: 0.9273 - val_loss: 0.0088 - val_accuracy: 0.9452\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0111 - accuracy: 0.9304 - val_loss: 0.0084 - val_accuracy: 0.9467\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0106 - accuracy: 0.9340 - val_loss: 0.0079 - val_accuracy: 0.9498\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0101 - accuracy: 0.9368 - val_loss: 0.0076 - val_accuracy: 0.9537\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0097 - accuracy: 0.9393 - val_loss: 0.0072 - val_accuracy: 0.9557\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0093 - accuracy: 0.9423 - val_loss: 0.0070 - val_accuracy: 0.9588\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0090 - accuracy: 0.9453 - val_loss: 0.0066 - val_accuracy: 0.9612\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0086 - accuracy: 0.9472 - val_loss: 0.0064 - val_accuracy: 0.9613\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0083 - accuracy: 0.9492 - val_loss: 0.0061 - val_accuracy: 0.9640\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0080 - accuracy: 0.9514 - val_loss: 0.0060 - val_accuracy: 0.9637\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 2s 5ms/step - loss: 0.0077 - accuracy: 0.9530 - val_loss: 0.0058 - val_accuracy: 0.9677\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0074 - accuracy: 0.9549 - val_loss: 0.0055 - val_accuracy: 0.9688\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0072 - accuracy: 0.9562 - val_loss: 0.0053 - val_accuracy: 0.9688\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0070 - accuracy: 0.9581 - val_loss: 0.0052 - val_accuracy: 0.9697\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0068 - accuracy: 0.9586 - val_loss: 0.0051 - val_accuracy: 0.9705\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0066 - accuracy: 0.9600 - val_loss: 0.0050 - val_accuracy: 0.9705\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0064 - accuracy: 0.9614 - val_loss: 0.0048 - val_accuracy: 0.9720\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0062 - accuracy: 0.9624 - val_loss: 0.0047 - val_accuracy: 0.9730\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0061 - accuracy: 0.9637 - val_loss: 0.0046 - val_accuracy: 0.9735\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0059 - accuracy: 0.9645 - val_loss: 0.0046 - val_accuracy: 0.9725\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0058 - accuracy: 0.9659 - val_loss: 0.0045 - val_accuracy: 0.9750\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0057 - accuracy: 0.9665 - val_loss: 0.0043 - val_accuracy: 0.9757\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0056 - accuracy: 0.9671 - val_loss: 0.0043 - val_accuracy: 0.9750\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0055 - accuracy: 0.9679 - val_loss: 0.0042 - val_accuracy: 0.9755\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0054 - accuracy: 0.9684 - val_loss: 0.0042 - val_accuracy: 0.9763\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0053 - accuracy: 0.9694 - val_loss: 0.0042 - val_accuracy: 0.9752\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0052 - accuracy: 0.9697 - val_loss: 0.0040 - val_accuracy: 0.9753\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0051 - accuracy: 0.9704 - val_loss: 0.0040 - val_accuracy: 0.9768\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0050 - accuracy: 0.9710 - val_loss: 0.0040 - val_accuracy: 0.9755\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0050 - accuracy: 0.9711 - val_loss: 0.0038 - val_accuracy: 0.9768\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0049 - accuracy: 0.9713 - val_loss: 0.0039 - val_accuracy: 0.9775\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0048 - accuracy: 0.9716 - val_loss: 0.0037 - val_accuracy: 0.9780\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0047 - accuracy: 0.9724 - val_loss: 0.0037 - val_accuracy: 0.9788\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0047 - accuracy: 0.9727 - val_loss: 0.0037 - val_accuracy: 0.9778\n",
      "Epoch 45/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0046 - accuracy: 0.9729 - val_loss: 0.0037 - val_accuracy: 0.9775\n",
      "Epoch 46/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0046 - accuracy: 0.9734 - val_loss: 0.0037 - val_accuracy: 0.9785\n",
      "Epoch 47/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0045 - accuracy: 0.9732 - val_loss: 0.0036 - val_accuracy: 0.9783\n",
      "Epoch 48/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0045 - accuracy: 0.9742 - val_loss: 0.0036 - val_accuracy: 0.9775\n",
      "Epoch 49/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0044 - accuracy: 0.9742 - val_loss: 0.0034 - val_accuracy: 0.9788\n",
      "Epoch 50/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0044 - accuracy: 0.9742 - val_loss: 0.0035 - val_accuracy: 0.9783\n",
      "Epoch 51/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0043 - accuracy: 0.9748 - val_loss: 0.0035 - val_accuracy: 0.9783\n",
      "Epoch 52/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0043 - accuracy: 0.9746 - val_loss: 0.0034 - val_accuracy: 0.9793\n",
      "Epoch 53/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0042 - accuracy: 0.9750 - val_loss: 0.0034 - val_accuracy: 0.9803\n",
      "Epoch 54/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0042 - accuracy: 0.9750 - val_loss: 0.0034 - val_accuracy: 0.9785\n",
      "Epoch 55/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0041 - accuracy: 0.9760 - val_loss: 0.0034 - val_accuracy: 0.9800\n",
      "Epoch 56/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0041 - accuracy: 0.9760 - val_loss: 0.0033 - val_accuracy: 0.9800\n",
      "Epoch 57/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0041 - accuracy: 0.9760 - val_loss: 0.0033 - val_accuracy: 0.9797\n",
      "Epoch 58/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0040 - accuracy: 0.9767 - val_loss: 0.0033 - val_accuracy: 0.9798\n",
      "Epoch 59/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0040 - accuracy: 0.9768 - val_loss: 0.0032 - val_accuracy: 0.9802\n",
      "Epoch 60/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0040 - accuracy: 0.9767 - val_loss: 0.0032 - val_accuracy: 0.9800\n",
      "Epoch 61/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0039 - accuracy: 0.9771 - val_loss: 0.0033 - val_accuracy: 0.9797\n",
      "Epoch 62/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0039 - accuracy: 0.9768 - val_loss: 0.0032 - val_accuracy: 0.9808\n",
      "Epoch 63/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0039 - accuracy: 0.9773 - val_loss: 0.0032 - val_accuracy: 0.9807\n",
      "Epoch 64/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0038 - accuracy: 0.9779 - val_loss: 0.0031 - val_accuracy: 0.9812\n",
      "Epoch 65/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0038 - accuracy: 0.9776 - val_loss: 0.0031 - val_accuracy: 0.9817\n",
      "Epoch 66/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0038 - accuracy: 0.9776 - val_loss: 0.0031 - val_accuracy: 0.9805\n",
      "Epoch 67/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0037 - accuracy: 0.9783 - val_loss: 0.0031 - val_accuracy: 0.9802\n",
      "Epoch 68/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0037 - accuracy: 0.9778 - val_loss: 0.0031 - val_accuracy: 0.9808\n",
      "Epoch 69/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0037 - accuracy: 0.9786 - val_loss: 0.0030 - val_accuracy: 0.9810\n",
      "Epoch 70/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0037 - accuracy: 0.9785 - val_loss: 0.0031 - val_accuracy: 0.9800\n",
      "Epoch 71/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0036 - accuracy: 0.9787 - val_loss: 0.0031 - val_accuracy: 0.9812\n",
      "Epoch 72/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0036 - accuracy: 0.9786 - val_loss: 0.0030 - val_accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0036 - accuracy: 0.9789 - val_loss: 0.0030 - val_accuracy: 0.9820\n",
      "Epoch 74/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0036 - accuracy: 0.9789 - val_loss: 0.0029 - val_accuracy: 0.9818\n",
      "Epoch 75/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0035 - accuracy: 0.9794 - val_loss: 0.0029 - val_accuracy: 0.9820\n",
      "Epoch 76/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0035 - accuracy: 0.9796 - val_loss: 0.0029 - val_accuracy: 0.9827\n",
      "Epoch 77/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0035 - accuracy: 0.9797 - val_loss: 0.0029 - val_accuracy: 0.9818\n",
      "Epoch 78/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0035 - accuracy: 0.9799 - val_loss: 0.0029 - val_accuracy: 0.9812\n",
      "Epoch 79/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0034 - accuracy: 0.9800 - val_loss: 0.0029 - val_accuracy: 0.9820\n",
      "Epoch 80/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0034 - accuracy: 0.9800 - val_loss: 0.0029 - val_accuracy: 0.9820\n",
      "Epoch 81/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0034 - accuracy: 0.9800 - val_loss: 0.0029 - val_accuracy: 0.9820\n",
      "Epoch 82/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0034 - accuracy: 0.9803 - val_loss: 0.0028 - val_accuracy: 0.9823\n",
      "Epoch 83/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0034 - accuracy: 0.9806 - val_loss: 0.0029 - val_accuracy: 0.9818\n",
      "Epoch 84/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0033 - accuracy: 0.9809 - val_loss: 0.0029 - val_accuracy: 0.9827\n",
      "Epoch 85/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0033 - accuracy: 0.9806 - val_loss: 0.0028 - val_accuracy: 0.9823\n",
      "Epoch 86/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0033 - accuracy: 0.9809 - val_loss: 0.0029 - val_accuracy: 0.9822\n",
      "Epoch 87/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0033 - accuracy: 0.9810 - val_loss: 0.0028 - val_accuracy: 0.9837\n",
      "Epoch 88/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0033 - accuracy: 0.9813 - val_loss: 0.0027 - val_accuracy: 0.9835\n",
      "Epoch 89/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0032 - accuracy: 0.9813 - val_loss: 0.0027 - val_accuracy: 0.9825\n",
      "Epoch 90/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0032 - accuracy: 0.9814 - val_loss: 0.0028 - val_accuracy: 0.9825\n",
      "Epoch 91/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0032 - accuracy: 0.9815 - val_loss: 0.0028 - val_accuracy: 0.9825\n",
      "Epoch 92/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0032 - accuracy: 0.9814 - val_loss: 0.0027 - val_accuracy: 0.9835\n",
      "Epoch 93/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0032 - accuracy: 0.9817 - val_loss: 0.0027 - val_accuracy: 0.9830\n",
      "Epoch 94/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0031 - accuracy: 0.9817 - val_loss: 0.0027 - val_accuracy: 0.9838\n",
      "Epoch 95/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0031 - accuracy: 0.9819 - val_loss: 0.0027 - val_accuracy: 0.9838\n",
      "Epoch 96/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0031 - accuracy: 0.9820 - val_loss: 0.0027 - val_accuracy: 0.9837\n",
      "Epoch 97/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0031 - accuracy: 0.9823 - val_loss: 0.0027 - val_accuracy: 0.9845\n",
      "Epoch 98/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0031 - accuracy: 0.9821 - val_loss: 0.0026 - val_accuracy: 0.9840\n",
      "Epoch 99/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0030 - accuracy: 0.9825 - val_loss: 0.0026 - val_accuracy: 0.9838\n",
      "Epoch 100/100\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0030 - accuracy: 0.9827 - val_loss: 0.0027 - val_accuracy: 0.9837\n",
      "313/313 - 1s - loss: 0.0029 - accuracy: 0.9832\n",
      "testSetLoss: 0.0029396263416856527 - testSetAccuracy: 0.9832000136375427%\n"
     ]
    }
   ],
   "source": [
    "test3_128 = trainModel3(100, 128)\n",
    "hist_df = pd.DataFrame(test3_128.history)\n",
    "hist_json_file = 'test3_128.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_22 (Averag (None, 6, 6, 6)           0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                2170      \n",
      "=================================================================\n",
      "Total params: 2,326\n",
      "Trainable params: 2,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 0.0835 - accuracy: 0.3278 - val_loss: 0.0655 - val_accuracy: 0.6035\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0478 - accuracy: 0.7408 - val_loss: 0.0316 - val_accuracy: 0.8525\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.83 - 1s 6ms/step - loss: 0.0297 - accuracy: 0.8359 - val_loss: 0.0217 - val_accuracy: 0.8888\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0235 - accuracy: 0.8648 - val_loss: 0.0177 - val_accuracy: 0.9003\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0204 - accuracy: 0.8797 - val_loss: 0.0155 - val_accuracy: 0.9118\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0184 - accuracy: 0.8899 - val_loss: 0.0140 - val_accuracy: 0.9198\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0170 - accuracy: 0.8973 - val_loss: 0.0129 - val_accuracy: 0.9235\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0159 - accuracy: 0.9029 - val_loss: 0.0122 - val_accuracy: 0.9265\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0151 - accuracy: 0.9069 - val_loss: 0.0115 - val_accuracy: 0.9317\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.9111 - val_loss: 0.0110 - val_accuracy: 0.9342\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0137 - accuracy: 0.9153 - val_loss: 0.0105 - val_accuracy: 0.9378\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0131 - accuracy: 0.9189 - val_loss: 0.0101 - val_accuracy: 0.9393\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0126 - accuracy: 0.9225 - val_loss: 0.0096 - val_accuracy: 0.9432\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0121 - accuracy: 0.9258 - val_loss: 0.0092 - val_accuracy: 0.9452\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0116 - accuracy: 0.9289 - val_loss: 0.0089 - val_accuracy: 0.9445\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0112 - accuracy: 0.9315 - val_loss: 0.0085 - val_accuracy: 0.9493\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0108 - accuracy: 0.9337 - val_loss: 0.0081 - val_accuracy: 0.9505\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0104 - accuracy: 0.9363 - val_loss: 0.0079 - val_accuracy: 0.9520\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0100 - accuracy: 0.9393 - val_loss: 0.0077 - val_accuracy: 0.9542\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0097 - accuracy: 0.9406 - val_loss: 0.0073 - val_accuracy: 0.9565\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0093 - accuracy: 0.9428 - val_loss: 0.0070 - val_accuracy: 0.9575\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0090 - accuracy: 0.9451 - val_loss: 0.0068 - val_accuracy: 0.9592\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.9469 - val_loss: 0.0066 - val_accuracy: 0.9605\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0085 - accuracy: 0.9488 - val_loss: 0.0064 - val_accuracy: 0.9635\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.9508 - val_loss: 0.0062 - val_accuracy: 0.9630\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0080 - accuracy: 0.9521 - val_loss: 0.0060 - val_accuracy: 0.9657\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0078 - accuracy: 0.9538 - val_loss: 0.0059 - val_accuracy: 0.9653\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0075 - accuracy: 0.9547 - val_loss: 0.0056 - val_accuracy: 0.9673\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0074 - accuracy: 0.9562 - val_loss: 0.0055 - val_accuracy: 0.9687\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0072 - accuracy: 0.9575 - val_loss: 0.0055 - val_accuracy: 0.9700\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0070 - accuracy: 0.9586 - val_loss: 0.0052 - val_accuracy: 0.9725\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0068 - accuracy: 0.9594 - val_loss: 0.0051 - val_accuracy: 0.9722\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0066 - accuracy: 0.9609 - val_loss: 0.0050 - val_accuracy: 0.9737\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9614 - val_loss: 0.0048 - val_accuracy: 0.9743\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9622 - val_loss: 0.0048 - val_accuracy: 0.9737\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0062 - accuracy: 0.9633 - val_loss: 0.0046 - val_accuracy: 0.9748\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9642 - val_loss: 0.0046 - val_accuracy: 0.9755\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 0.9651 - val_loss: 0.0045 - val_accuracy: 0.9762\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0059 - accuracy: 0.9655 - val_loss: 0.0044 - val_accuracy: 0.9763\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0058 - accuracy: 0.9664 - val_loss: 0.0043 - val_accuracy: 0.9782\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9670 - val_loss: 0.0044 - val_accuracy: 0.9765\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9679 - val_loss: 0.0042 - val_accuracy: 0.9788\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 0.9689 - val_loss: 0.0041 - val_accuracy: 0.9785\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9692 - val_loss: 0.0041 - val_accuracy: 0.9797\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9695 - val_loss: 0.0040 - val_accuracy: 0.9798\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9704 - val_loss: 0.0039 - val_accuracy: 0.9800\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9703 - val_loss: 0.0038 - val_accuracy: 0.9798\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9710 - val_loss: 0.0038 - val_accuracy: 0.9808\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9714 - val_loss: 0.0037 - val_accuracy: 0.9810\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9717 - val_loss: 0.0037 - val_accuracy: 0.9805\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9721 - val_loss: 0.0038 - val_accuracy: 0.9802\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9725 - val_loss: 0.0036 - val_accuracy: 0.9818\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9732 - val_loss: 0.0036 - val_accuracy: 0.9808\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0047 - accuracy: 0.9733 - val_loss: 0.0037 - val_accuracy: 0.9807\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9734 - val_loss: 0.0035 - val_accuracy: 0.9818\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9736 - val_loss: 0.0035 - val_accuracy: 0.9812\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9742 - val_loss: 0.0035 - val_accuracy: 0.9808\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9741 - val_loss: 0.0034 - val_accuracy: 0.9817\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9746 - val_loss: 0.0033 - val_accuracy: 0.9817\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9750 - val_loss: 0.0033 - val_accuracy: 0.9813\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9754 - val_loss: 0.0033 - val_accuracy: 0.9817\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9756 - val_loss: 0.0033 - val_accuracy: 0.9823\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9758 - val_loss: 0.0033 - val_accuracy: 0.9817\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9760 - val_loss: 0.0032 - val_accuracy: 0.9820\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9759 - val_loss: 0.0032 - val_accuracy: 0.9818\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9763 - val_loss: 0.0031 - val_accuracy: 0.9833\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9759 - val_loss: 0.0032 - val_accuracy: 0.9833\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9765 - val_loss: 0.0031 - val_accuracy: 0.9840\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9773 - val_loss: 0.0031 - val_accuracy: 0.9823\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0040 - accuracy: 0.9771 - val_loss: 0.0030 - val_accuracy: 0.9835\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 0.9775 - val_loss: 0.0031 - val_accuracy: 0.9842\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 0.9773 - val_loss: 0.0030 - val_accuracy: 0.9840\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 0.9771 - val_loss: 0.0030 - val_accuracy: 0.9837\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9777 - val_loss: 0.0030 - val_accuracy: 0.9840\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9780 - val_loss: 0.0030 - val_accuracy: 0.9830\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9780 - val_loss: 0.0030 - val_accuracy: 0.9838\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9783 - val_loss: 0.0029 - val_accuracy: 0.9840\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9787 - val_loss: 0.0029 - val_accuracy: 0.9840\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9787 - val_loss: 0.0030 - val_accuracy: 0.9822\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9786 - val_loss: 0.0029 - val_accuracy: 0.9843\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9791 - val_loss: 0.0029 - val_accuracy: 0.9845\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9790 - val_loss: 0.0029 - val_accuracy: 0.9843\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9794 - val_loss: 0.0028 - val_accuracy: 0.9847\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9795 - val_loss: 0.0029 - val_accuracy: 0.9837\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9794 - val_loss: 0.0028 - val_accuracy: 0.9845\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9800 - val_loss: 0.0027 - val_accuracy: 0.9843\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 0.9799 - val_loss: 0.0028 - val_accuracy: 0.9835\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9802 - val_loss: 0.0027 - val_accuracy: 0.9853\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9803 - val_loss: 0.0028 - val_accuracy: 0.9843\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9807 - val_loss: 0.0027 - val_accuracy: 0.9848\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9805 - val_loss: 0.0027 - val_accuracy: 0.9847\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9809 - val_loss: 0.0027 - val_accuracy: 0.9850\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9807 - val_loss: 0.0027 - val_accuracy: 0.9843\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9808 - val_loss: 0.0028 - val_accuracy: 0.9842\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9812 - val_loss: 0.0027 - val_accuracy: 0.9843\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9809 - val_loss: 0.0027 - val_accuracy: 0.9848\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9814 - val_loss: 0.0027 - val_accuracy: 0.9848\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9813 - val_loss: 0.0027 - val_accuracy: 0.9843\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9815 - val_loss: 0.0026 - val_accuracy: 0.9850\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9818 - val_loss: 0.0026 - val_accuracy: 0.9852\n",
      "313/313 - 1s - loss: 0.0030 - accuracy: 0.9830\n",
      "testSetLoss: 0.0029578893445432186 - testSetAccuracy: 0.9829999804496765%\n"
     ]
    }
   ],
   "source": [
    "test3_256 = trainModel3(100, 256)\n",
    "hist_df = pd.DataFrame(test3_256.history)\n",
    "hist_json_file = 'test3_256.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_23 (Averag (None, 6, 6, 6)           0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 216)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                2170      \n",
      "=================================================================\n",
      "Total params: 2,326\n",
      "Trainable params: 2,326\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 1s 11ms/step - loss: 0.0890 - accuracy: 0.1933 - val_loss: 0.0859 - val_accuracy: 0.3123\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0765 - accuracy: 0.4851 - val_loss: 0.0624 - val_accuracy: 0.6332\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0522 - accuracy: 0.7008 - val_loss: 0.0393 - val_accuracy: 0.8295\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 0.0365 - accuracy: 0.8127 - val_loss: 0.0280 - val_accuracy: 0.8737\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0290 - accuracy: 0.8465 - val_loss: 0.0227 - val_accuracy: 0.8895\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0249 - accuracy: 0.8621 - val_loss: 0.0196 - val_accuracy: 0.8990\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0224 - accuracy: 0.8738 - val_loss: 0.0176 - val_accuracy: 0.9042\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0206 - accuracy: 0.8805 - val_loss: 0.0162 - val_accuracy: 0.9110\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0193 - accuracy: 0.8861 - val_loss: 0.0152 - val_accuracy: 0.9150\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0182 - accuracy: 0.8916 - val_loss: 0.0144 - val_accuracy: 0.9190\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0174 - accuracy: 0.8955 - val_loss: 0.0136 - val_accuracy: 0.9225\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0167 - accuracy: 0.8989 - val_loss: 0.0132 - val_accuracy: 0.9223\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0161 - accuracy: 0.9011 - val_loss: 0.0127 - val_accuracy: 0.9263\n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0156 - accuracy: 0.9049 - val_loss: 0.0122 - val_accuracy: 0.9268\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0151 - accuracy: 0.9071 - val_loss: 0.0119 - val_accuracy: 0.9283\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0147 - accuracy: 0.9088 - val_loss: 0.0115 - val_accuracy: 0.9300\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0143 - accuracy: 0.9112 - val_loss: 0.0112 - val_accuracy: 0.9302\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.9128 - val_loss: 0.0110 - val_accuracy: 0.9332\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0136 - accuracy: 0.9156 - val_loss: 0.0107 - val_accuracy: 0.9332\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0133 - accuracy: 0.9175 - val_loss: 0.0104 - val_accuracy: 0.9350\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0130 - accuracy: 0.9191 - val_loss: 0.0102 - val_accuracy: 0.9362\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0127 - accuracy: 0.9209 - val_loss: 0.0100 - val_accuracy: 0.9368\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0125 - accuracy: 0.9224 - val_loss: 0.0097 - val_accuracy: 0.9390\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0122 - accuracy: 0.9246 - val_loss: 0.0095 - val_accuracy: 0.9417\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0119 - accuracy: 0.9267 - val_loss: 0.0092 - val_accuracy: 0.9423\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0116 - accuracy: 0.9276 - val_loss: 0.0091 - val_accuracy: 0.9428\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0114 - accuracy: 0.9287 - val_loss: 0.0089 - val_accuracy: 0.9438\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0112 - accuracy: 0.9307 - val_loss: 0.0087 - val_accuracy: 0.9462\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0109 - accuracy: 0.9323 - val_loss: 0.0085 - val_accuracy: 0.9468\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.9340 - val_loss: 0.0083 - val_accuracy: 0.9492\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0105 - accuracy: 0.9351 - val_loss: 0.0081 - val_accuracy: 0.9487\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 1s 7ms/step - loss: 0.0103 - accuracy: 0.9365 - val_loss: 0.0079 - val_accuracy: 0.9513\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0101 - accuracy: 0.9377 - val_loss: 0.0078 - val_accuracy: 0.9535\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0099 - accuracy: 0.9394 - val_loss: 0.0076 - val_accuracy: 0.9533\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0097 - accuracy: 0.9403 - val_loss: 0.0075 - val_accuracy: 0.9547\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0095 - accuracy: 0.9415 - val_loss: 0.0074 - val_accuracy: 0.9552\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9423 - val_loss: 0.0072 - val_accuracy: 0.9565\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0092 - accuracy: 0.9439 - val_loss: 0.0071 - val_accuracy: 0.9563\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0090 - accuracy: 0.9449 - val_loss: 0.0069 - val_accuracy: 0.9582\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0088 - accuracy: 0.9459 - val_loss: 0.0068 - val_accuracy: 0.9595\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0087 - accuracy: 0.9471 - val_loss: 0.0067 - val_accuracy: 0.9598\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0085 - accuracy: 0.9478 - val_loss: 0.0065 - val_accuracy: 0.9587\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0084 - accuracy: 0.9491 - val_loss: 0.0064 - val_accuracy: 0.9617\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0082 - accuracy: 0.9497 - val_loss: 0.0063 - val_accuracy: 0.9632\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0081 - accuracy: 0.9509 - val_loss: 0.0062 - val_accuracy: 0.9635\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0079 - accuracy: 0.9520 - val_loss: 0.0061 - val_accuracy: 0.9645\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0078 - accuracy: 0.9525 - val_loss: 0.0060 - val_accuracy: 0.9643\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0077 - accuracy: 0.9538 - val_loss: 0.0059 - val_accuracy: 0.9650\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 0.9546 - val_loss: 0.0058 - val_accuracy: 0.9668\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0074 - accuracy: 0.9554 - val_loss: 0.0057 - val_accuracy: 0.9667\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0073 - accuracy: 0.9561 - val_loss: 0.0056 - val_accuracy: 0.9665\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0072 - accuracy: 0.9569 - val_loss: 0.0055 - val_accuracy: 0.9658\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0071 - accuracy: 0.9575 - val_loss: 0.0055 - val_accuracy: 0.9672\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0070 - accuracy: 0.9581 - val_loss: 0.0054 - val_accuracy: 0.9683\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0069 - accuracy: 0.9589 - val_loss: 0.0053 - val_accuracy: 0.9692\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0068 - accuracy: 0.9595 - val_loss: 0.0052 - val_accuracy: 0.9690\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0067 - accuracy: 0.9603 - val_loss: 0.0051 - val_accuracy: 0.9697\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0066 - accuracy: 0.9608 - val_loss: 0.0050 - val_accuracy: 0.9698\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0065 - accuracy: 0.9613 - val_loss: 0.0050 - val_accuracy: 0.9712\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0064 - accuracy: 0.9617 - val_loss: 0.0049 - val_accuracy: 0.9705\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0063 - accuracy: 0.9624 - val_loss: 0.0048 - val_accuracy: 0.9705\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0063 - accuracy: 0.9630 - val_loss: 0.0048 - val_accuracy: 0.9710\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0062 - accuracy: 0.9636 - val_loss: 0.0048 - val_accuracy: 0.9712\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0061 - accuracy: 0.9638 - val_loss: 0.0046 - val_accuracy: 0.9722\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0060 - accuracy: 0.9641 - val_loss: 0.0046 - val_accuracy: 0.9725\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0059 - accuracy: 0.9651 - val_loss: 0.0046 - val_accuracy: 0.9717\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0059 - accuracy: 0.9654 - val_loss: 0.0045 - val_accuracy: 0.9742\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0058 - accuracy: 0.9660 - val_loss: 0.0045 - val_accuracy: 0.9728\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 0.9665 - val_loss: 0.0044 - val_accuracy: 0.9732\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0057 - accuracy: 0.9669 - val_loss: 0.0043 - val_accuracy: 0.9745\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0056 - accuracy: 0.9672 - val_loss: 0.0043 - val_accuracy: 0.9743\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0056 - accuracy: 0.9676 - val_loss: 0.0043 - val_accuracy: 0.9752\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0055 - accuracy: 0.9681 - val_loss: 0.0042 - val_accuracy: 0.9758\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0054 - accuracy: 0.9680 - val_loss: 0.0042 - val_accuracy: 0.9765\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0054 - accuracy: 0.9691 - val_loss: 0.0042 - val_accuracy: 0.9752\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 0.9692 - val_loss: 0.0041 - val_accuracy: 0.9763\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 0.9694 - val_loss: 0.0040 - val_accuracy: 0.9765\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0052 - accuracy: 0.9699 - val_loss: 0.0041 - val_accuracy: 0.9767\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0052 - accuracy: 0.9702 - val_loss: 0.0040 - val_accuracy: 0.9773\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0051 - accuracy: 0.9702 - val_loss: 0.0040 - val_accuracy: 0.9772\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0051 - accuracy: 0.9706 - val_loss: 0.0040 - val_accuracy: 0.9767\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0050 - accuracy: 0.9711 - val_loss: 0.0039 - val_accuracy: 0.9777\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0050 - accuracy: 0.9711 - val_loss: 0.0039 - val_accuracy: 0.9773\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 0.9715 - val_loss: 0.0038 - val_accuracy: 0.9780\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 0.9717 - val_loss: 0.0038 - val_accuracy: 0.9782\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0049 - accuracy: 0.9720 - val_loss: 0.0038 - val_accuracy: 0.9787\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0048 - accuracy: 0.9721 - val_loss: 0.0037 - val_accuracy: 0.9783\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0048 - accuracy: 0.9723 - val_loss: 0.0037 - val_accuracy: 0.9780\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0048 - accuracy: 0.9726 - val_loss: 0.0038 - val_accuracy: 0.9778\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0047 - accuracy: 0.9729 - val_loss: 0.0037 - val_accuracy: 0.9792\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0047 - accuracy: 0.9728 - val_loss: 0.0036 - val_accuracy: 0.9797\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0046 - accuracy: 0.9731 - val_loss: 0.0036 - val_accuracy: 0.9790\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0046 - accuracy: 0.9733 - val_loss: 0.0036 - val_accuracy: 0.9793\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0046 - accuracy: 0.9734 - val_loss: 0.0036 - val_accuracy: 0.9783\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0046 - accuracy: 0.9736 - val_loss: 0.0036 - val_accuracy: 0.9795\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0045 - accuracy: 0.9739 - val_loss: 0.0035 - val_accuracy: 0.9795\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0045 - accuracy: 0.9743 - val_loss: 0.0035 - val_accuracy: 0.9792\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0045 - accuracy: 0.9741 - val_loss: 0.0035 - val_accuracy: 0.9785\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0044 - accuracy: 0.9743 - val_loss: 0.0035 - val_accuracy: 0.9805\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 1s 8ms/step - loss: 0.0044 - accuracy: 0.9747 - val_loss: 0.0034 - val_accuracy: 0.9798\n",
      "313/313 - 1s - loss: 0.0040 - accuracy: 0.9753\n",
      "testSetLoss: 0.004030018113553524 - testSetAccuracy: 0.9753000140190125%\n"
     ]
    }
   ],
   "source": [
    "test3_512 = trainModel3(100, 512)\n",
    "hist_df = pd.DataFrame(test3_512.history)\n",
    "hist_json_file = 'test3_512.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 0.1586 - accuracy: 0.9502 - val_loss: 0.0580 - val_accuracy: 0.9830\n",
      "Epoch 2/100\n",
      "27000/27000 [==============================] - 134s 5ms/step - loss: 0.0596 - accuracy: 0.9815 - val_loss: 0.0474 - val_accuracy: 0.9850\n",
      "Epoch 3/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 0.0434 - accuracy: 0.9861 - val_loss: 0.0437 - val_accuracy: 0.9878\n",
      "Epoch 4/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.0352 - accuracy: 0.9891 - val_loss: 0.0374 - val_accuracy: 0.9895\n",
      "Epoch 5/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 0.0288 - accuracy: 0.9904 - val_loss: 0.0395 - val_accuracy: 0.9888\n",
      "Epoch 6/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0415 - val_accuracy: 0.9892\n",
      "Epoch 7/100\n",
      "27000/27000 [==============================] - 145s 5ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.0418 - val_accuracy: 0.9892\n",
      "Epoch 8/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0382 - val_accuracy: 0.9902\n",
      "Epoch 9/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0376 - val_accuracy: 0.9898\n",
      "Epoch 10/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0397 - val_accuracy: 0.9900\n",
      "Epoch 11/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.0428 - val_accuracy: 0.9905\n",
      "Epoch 12/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0408 - val_accuracy: 0.9912\n",
      "Epoch 13/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0472 - val_accuracy: 0.9898\n",
      "Epoch 14/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0526 - val_accuracy: 0.9880\n",
      "Epoch 15/100\n",
      "27000/27000 [==============================] - 136s 5ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0469 - val_accuracy: 0.9890\n",
      "Epoch 16/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0493 - val_accuracy: 0.9897\n",
      "Epoch 17/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0461 - val_accuracy: 0.9903\n",
      "Epoch 18/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0475 - val_accuracy: 0.9895\n",
      "Epoch 19/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0498 - val_accuracy: 0.9897\n",
      "Epoch 20/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0519 - val_accuracy: 0.9900\n",
      "Epoch 21/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 6.8588e-04 - accuracy: 0.9999 - val_loss: 0.0490 - val_accuracy: 0.9915\n",
      "Epoch 22/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 7.2592e-04 - accuracy: 0.9999 - val_loss: 0.0556 - val_accuracy: 0.9903\n",
      "Epoch 23/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 7.2737e-04 - accuracy: 0.9999 - val_loss: 0.0515 - val_accuracy: 0.9912\n",
      "Epoch 24/100\n",
      "27000/27000 [==============================] - 134s 5ms/step - loss: 2.6332e-04 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9913\n",
      "Epoch 25/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 1.8162e-04 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9912\n",
      "Epoch 26/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 1.5317e-04 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9913\n",
      "Epoch 27/100\n",
      "27000/27000 [==============================] - 137s 5ms/step - loss: 1.4204e-04 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9912\n",
      "Epoch 28/100\n",
      "27000/27000 [==============================] - 133s 5ms/step - loss: 1.2417e-04 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 0.9912\n",
      "Epoch 29/100\n",
      "27000/27000 [==============================] - 137s 5ms/step - loss: 1.1616e-04 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9913\n",
      "Epoch 30/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 1.0899e-04 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9913\n",
      "Epoch 31/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 1.0191e-04 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 0.9913\n",
      "Epoch 32/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 9.4628e-05 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 0.9912\n",
      "Epoch 33/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 8.9885e-05 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9913\n",
      "Epoch 34/100\n",
      "27000/27000 [==============================] - 136s 5ms/step - loss: 8.6540e-05 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9912\n",
      "Epoch 35/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 8.2383e-05 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9913\n",
      "Epoch 36/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 7.7080e-05 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9913\n",
      "Epoch 37/100\n",
      "27000/27000 [==============================] - 137s 5ms/step - loss: 7.4510e-05 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9913\n",
      "Epoch 38/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 7.1408e-05 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9913\n",
      "Epoch 39/100\n",
      "27000/27000 [==============================] - 136s 5ms/step - loss: 6.8180e-05 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9913\n",
      "Epoch 40/100\n",
      "27000/27000 [==============================] - 137s 5ms/step - loss: 6.5837e-05 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9913\n",
      "Epoch 41/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 6.3418e-05 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 0.9912\n",
      "Epoch 42/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 6.1242e-05 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9913\n",
      "Epoch 43/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 5.9611e-05 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 0.9913\n",
      "Epoch 44/100\n",
      "27000/27000 [==============================] - 137s 5ms/step - loss: 5.7117e-05 - accuracy: 1.0000 - val_loss: 0.0613 - val_accuracy: 0.9913\n",
      "Epoch 45/100\n",
      "27000/27000 [==============================] - 135s 5ms/step - loss: 5.5540e-05 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 0.9913\n",
      "Epoch 46/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 5.3530e-05 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9915\n",
      "Epoch 47/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 5.2206e-05 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 0.9915\n",
      "Epoch 48/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 5.0726e-05 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 0.9913\n",
      "Epoch 49/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 4.8786e-05 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 0.9917\n",
      "Epoch 50/100\n",
      "27000/27000 [==============================] - 131s 5ms/step - loss: 4.7617e-05 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 0.9912\n",
      "Epoch 51/100\n",
      "27000/27000 [==============================] - 137s 5ms/step - loss: 4.6584e-05 - accuracy: 1.0000 - val_loss: 0.0627 - val_accuracy: 0.9913\n",
      "Epoch 52/100\n",
      "27000/27000 [==============================] - 136s 5ms/step - loss: 4.5232e-05 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9915\n",
      "Epoch 53/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 4.4187e-05 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9912\n",
      "Epoch 54/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 4.3146e-05 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 0.9915\n",
      "Epoch 55/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 4.1941e-05 - accuracy: 1.0000 - val_loss: 0.0637 - val_accuracy: 0.9910\n",
      "Epoch 56/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 4.0891e-05 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9913\n",
      "Epoch 57/100\n",
      "27000/27000 [==============================] - 147s 5ms/step - loss: 4.0012e-05 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9912\n",
      "Epoch 58/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 3.9183e-05 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9912\n",
      "Epoch 59/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 3.8274e-05 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 0.9913\n",
      "Epoch 60/100\n",
      "27000/27000 [==============================] - 148s 5ms/step - loss: 3.7349e-05 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9913\n",
      "Epoch 61/100\n",
      "27000/27000 [==============================] - 149s 6ms/step - loss: 3.6591e-05 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9913\n",
      "Epoch 62/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 3.5998e-05 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9913\n",
      "Epoch 63/100\n",
      "27000/27000 [==============================] - 147s 5ms/step - loss: 3.5293e-05 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9912\n",
      "Epoch 64/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 3.4436e-05 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9910\n",
      "Epoch 65/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 3.3833e-05 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9912\n",
      "Epoch 66/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 3.3157e-05 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9912\n",
      "Epoch 67/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 3.2531e-05 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9912\n",
      "Epoch 68/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 3.2092e-05 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9913\n",
      "Epoch 69/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 3.1417e-05 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9913\n",
      "Epoch 70/100\n",
      "27000/27000 [==============================] - 133s 5ms/step - loss: 3.0730e-05 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 0.9913\n",
      "Epoch 71/100\n",
      "27000/27000 [==============================] - 134s 5ms/step - loss: 3.0307e-05 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 0.9910\n",
      "Epoch 72/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 2.9852e-05 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9912\n",
      "Epoch 73/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 2.9283e-05 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 0.9912\n",
      "Epoch 74/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.8703e-05 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9912\n",
      "Epoch 75/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 2.8286e-05 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9910\n",
      "Epoch 76/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 2.7834e-05 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9912\n",
      "Epoch 77/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 2.7292e-05 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9913\n",
      "Epoch 78/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 2.6942e-05 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9913\n",
      "Epoch 79/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.6566e-05 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9912\n",
      "Epoch 80/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.6078e-05 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9912\n",
      "Epoch 81/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 2.5679e-05 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9912\n",
      "Epoch 82/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 2.5255e-05 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9912\n",
      "Epoch 83/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 2.4929e-05 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9912\n",
      "Epoch 84/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.4540e-05 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9912\n",
      "Epoch 85/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 2.4215e-05 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9912\n",
      "Epoch 86/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 2.3819e-05 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9912\n",
      "Epoch 87/100\n",
      "27000/27000 [==============================] - 140s 5ms/step - loss: 2.3523e-05 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9912\n",
      "Epoch 88/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.3209e-05 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9912\n",
      "Epoch 89/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.2898e-05 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9912\n",
      "Epoch 90/100\n",
      "27000/27000 [==============================] - 139s 5ms/step - loss: 2.2606e-05 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 0.9912\n",
      "Epoch 91/100\n",
      "27000/27000 [==============================] - 138s 5ms/step - loss: 2.2250e-05 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9912\n",
      "Epoch 92/100\n",
      "27000/27000 [==============================] - 141s 5ms/step - loss: 2.1973e-05 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9912\n",
      "Epoch 93/100\n",
      "27000/27000 [==============================] - 150s 6ms/step - loss: 2.1710e-05 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9912\n",
      "Epoch 94/100\n",
      "27000/27000 [==============================] - 146s 5ms/step - loss: 2.1345e-05 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9912\n",
      "Epoch 95/100\n",
      "27000/27000 [==============================] - 144s 5ms/step - loss: 2.1092e-05 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9912\n",
      "Epoch 96/100\n",
      "27000/27000 [==============================] - 145s 5ms/step - loss: 2.0866e-05 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9912\n",
      "Epoch 97/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.0629e-05 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9912\n",
      "Epoch 98/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.0415e-05 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9912\n",
      "Epoch 99/100\n",
      "27000/27000 [==============================] - 142s 5ms/step - loss: 2.0063e-05 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9912\n",
      "Epoch 100/100\n",
      "27000/27000 [==============================] - 143s 5ms/step - loss: 1.9870e-05 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 0.9912\n",
      "313/313 - 1s - loss: 0.0553 - accuracy: 0.9909\n",
      "testSetLoss: 0.055292725563049316 - testSetAccuracyz: 0.9908999800682068%\n"
     ]
    }
   ],
   "source": [
    "test5_2 = trainModel4(100, 2)\n",
    "hist_df = pd.DataFrame(test5_2.history)\n",
    "hist_json_file = 'test5_2.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_38 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.2963 - accuracy: 0.9094 - val_loss: 0.1106 - val_accuracy: 0.9695\n",
      "Epoch 2/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 0.0953 - accuracy: 0.9706 - val_loss: 0.0676 - val_accuracy: 0.9810\n",
      "Epoch 3/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0710 - accuracy: 0.9778 - val_loss: 0.0574 - val_accuracy: 0.9838\n",
      "Epoch 4/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 0.0587 - accuracy: 0.9819 - val_loss: 0.0477 - val_accuracy: 0.9860\n",
      "Epoch 5/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0510 - accuracy: 0.9845 - val_loss: 0.0519 - val_accuracy: 0.9852\n",
      "Epoch 6/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 0.0465 - val_accuracy: 0.9865\n",
      "Epoch 7/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0403 - accuracy: 0.9874 - val_loss: 0.0493 - val_accuracy: 0.9873\n",
      "Epoch 8/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 0.0365 - accuracy: 0.9886 - val_loss: 0.0482 - val_accuracy: 0.9867\n",
      "Epoch 9/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 0.0440 - val_accuracy: 0.9865\n",
      "Epoch 10/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 0.0481 - val_accuracy: 0.9877\n",
      "Epoch 11/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.0425 - val_accuracy: 0.9870\n",
      "Epoch 12/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.0488 - val_accuracy: 0.9883\n",
      "Epoch 13/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0245 - accuracy: 0.9924 - val_loss: 0.0465 - val_accuracy: 0.9877\n",
      "Epoch 14/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.0420 - val_accuracy: 0.9885\n",
      "Epoch 15/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.0468 - val_accuracy: 0.9868\n",
      "Epoch 16/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0430 - val_accuracy: 0.9885\n",
      "Epoch 17/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 0.0441 - val_accuracy: 0.9888\n",
      "Epoch 18/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0172 - accuracy: 0.9946 - val_loss: 0.0441 - val_accuracy: 0.9878\n",
      "Epoch 19/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0469 - val_accuracy: 0.9878\n",
      "Epoch 20/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0461 - val_accuracy: 0.9887\n",
      "Epoch 21/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.0475 - val_accuracy: 0.9860\n",
      "Epoch 22/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0431 - val_accuracy: 0.9898\n",
      "Epoch 23/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.0452 - val_accuracy: 0.9885\n",
      "Epoch 24/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0442 - val_accuracy: 0.9895\n",
      "Epoch 25/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0466 - val_accuracy: 0.9882\n",
      "Epoch 26/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.0529 - val_accuracy: 0.9878\n",
      "Epoch 27/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.0540 - val_accuracy: 0.9883\n",
      "Epoch 28/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0482 - val_accuracy: 0.9882\n",
      "Epoch 29/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0510 - val_accuracy: 0.9878\n",
      "Epoch 30/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.0487 - val_accuracy: 0.9898\n",
      "Epoch 31/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
      "Epoch 32/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0460 - val_accuracy: 0.9897\n",
      "Epoch 33/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0475 - val_accuracy: 0.9888\n",
      "Epoch 34/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0499 - val_accuracy: 0.9893\n",
      "Epoch 35/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0562 - val_accuracy: 0.9887\n",
      "Epoch 36/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0497 - val_accuracy: 0.9898\n",
      "Epoch 37/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0500 - val_accuracy: 0.9888\n",
      "Epoch 38/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0526 - val_accuracy: 0.9883\n",
      "Epoch 39/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0536 - val_accuracy: 0.9893\n",
      "Epoch 40/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0514 - val_accuracy: 0.9890\n",
      "Epoch 41/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0517 - val_accuracy: 0.9897\n",
      "Epoch 42/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0552 - val_accuracy: 0.9892\n",
      "Epoch 43/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0525 - val_accuracy: 0.9897\n",
      "Epoch 44/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0593 - val_accuracy: 0.9887\n",
      "Epoch 45/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0563 - val_accuracy: 0.9895\n",
      "Epoch 46/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0560 - val_accuracy: 0.9890\n",
      "Epoch 47/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0560 - val_accuracy: 0.9897\n",
      "Epoch 48/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0563 - val_accuracy: 0.9898\n",
      "Epoch 49/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 9.8467e-04 - accuracy: 0.9999 - val_loss: 0.0557 - val_accuracy: 0.9892\n",
      "Epoch 50/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 8.4388e-04 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9895\n",
      "Epoch 51/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 8.1825e-04 - accuracy: 0.9999 - val_loss: 0.0586 - val_accuracy: 0.9897\n",
      "Epoch 52/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 7.9451e-04 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9897\n",
      "Epoch 53/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 6.6961e-04 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9895\n",
      "Epoch 54/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 6.2823e-04 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9900\n",
      "Epoch 55/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 6.0517e-04 - accuracy: 0.9999 - val_loss: 0.0606 - val_accuracy: 0.9898\n",
      "Epoch 56/100\n",
      "6750/6750 [==============================] - 31s 5ms/step - loss: 5.5943e-04 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9898\n",
      "Epoch 57/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 6.1487e-04 - accuracy: 0.9999 - val_loss: 0.0627 - val_accuracy: 0.9893\n",
      "Epoch 58/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 5.4027e-04 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 0.9902\n",
      "Epoch 59/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 4.6817e-04 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.9897\n",
      "Epoch 60/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 4.6190e-04 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9895\n",
      "Epoch 61/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 4.4641e-04 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9900\n",
      "Epoch 62/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 4.2829e-04 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9897\n",
      "Epoch 63/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 4.0035e-04 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9898\n",
      "Epoch 64/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 3.8565e-04 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9895\n",
      "Epoch 65/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 3.6401e-04 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 0.9902\n",
      "Epoch 66/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 3.6935e-04 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9902\n",
      "Epoch 67/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 3.4058e-04 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 0.9893\n",
      "Epoch 68/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 3.3878e-04 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9893\n",
      "Epoch 69/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 3.2809e-04 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9893\n",
      "Epoch 70/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 3.1767e-04 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 0.9895\n",
      "Epoch 71/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 2.9678e-04 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9898\n",
      "Epoch 72/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 2.9442e-04 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9897\n",
      "Epoch 73/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 2.7987e-04 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9897\n",
      "Epoch 74/100\n",
      "6750/6750 [==============================] - 37s 6ms/step - loss: 2.8719e-04 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9898\n",
      "Epoch 75/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 2.6413e-04 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9895\n",
      "Epoch 76/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 2.7016e-04 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9898\n",
      "Epoch 77/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 2.6267e-04 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 0.9900\n",
      "Epoch 78/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 2.4765e-04 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9900\n",
      "Epoch 79/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 2.5047e-04 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9895\n",
      "Epoch 80/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 2.4193e-04 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 0.9897\n",
      "Epoch 81/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 2.3662e-04 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9902\n",
      "Epoch 82/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 2.2639e-04 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9897\n",
      "Epoch 83/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 2.2274e-04 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9898\n",
      "Epoch 84/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 2.1368e-04 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9897\n",
      "Epoch 85/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 2.0977e-04 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9895\n",
      "Epoch 86/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 2.0456e-04 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9897\n",
      "Epoch 87/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 2.0566e-04 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9895\n",
      "Epoch 88/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 1.9794e-04 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9895\n",
      "Epoch 89/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 1.9930e-04 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9897\n",
      "Epoch 90/100\n",
      "6750/6750 [==============================] - 38s 6ms/step - loss: 1.9186e-04 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9893\n",
      "Epoch 91/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 1.9124e-04 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9898\n",
      "Epoch 92/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 1.8414e-04 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9898\n",
      "Epoch 93/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 1.7999e-04 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9898\n",
      "Epoch 94/100\n",
      "6750/6750 [==============================] - 35s 5ms/step - loss: 1.7816e-04 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9903\n",
      "Epoch 95/100\n",
      "6750/6750 [==============================] - 34s 5ms/step - loss: 1.7487e-04 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9898\n",
      "Epoch 96/100\n",
      "6750/6750 [==============================] - 33s 5ms/step - loss: 1.7320e-04 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9897\n",
      "Epoch 97/100\n",
      "6750/6750 [==============================] - 37s 5ms/step - loss: 1.6857e-04 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9902\n",
      "Epoch 98/100\n",
      "6750/6750 [==============================] - 39s 6ms/step - loss: 1.6463e-04 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9898\n",
      "Epoch 99/100\n",
      "6750/6750 [==============================] - 36s 5ms/step - loss: 1.6162e-04 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9900\n",
      "Epoch 100/100\n",
      "6750/6750 [==============================] - 40s 6ms/step - loss: 1.5854e-04 - accuracy: 1.0000 - val_loss: 0.0707 - val_accuracy: 0.9900\n",
      "313/313 - 1s - loss: 0.0586 - accuracy: 0.9903\n",
      "testSetLoss: 0.058643780648708344 - testSetAccuracyz: 0.9902999997138977%\n"
     ]
    }
   ],
   "source": [
    "test5_8 = trainModel4(100, 8)\n",
    "hist_df = pd.DataFrame(test5_8.history)\n",
    "hist_json_file = 'test5_8.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "3375/3375 [==============================] - 24s 7ms/step - loss: 0.4084 - accuracy: 0.8831 - val_loss: 0.1130 - val_accuracy: 0.9690\n",
      "Epoch 2/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.1191 - accuracy: 0.9640 - val_loss: 0.0825 - val_accuracy: 0.9762\n",
      "Epoch 3/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0903 - accuracy: 0.9727 - val_loss: 0.0723 - val_accuracy: 0.9785\n",
      "Epoch 4/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0769 - accuracy: 0.9761 - val_loss: 0.0705 - val_accuracy: 0.9793\n",
      "Epoch 5/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 0.0671 - accuracy: 0.9798 - val_loss: 0.0681 - val_accuracy: 0.9807\n",
      "Epoch 6/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0606 - accuracy: 0.9815 - val_loss: 0.0558 - val_accuracy: 0.9845\n",
      "Epoch 7/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0562 - accuracy: 0.9828 - val_loss: 0.0542 - val_accuracy: 0.9843\n",
      "Epoch 8/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0519 - accuracy: 0.9843 - val_loss: 0.0582 - val_accuracy: 0.9832\n",
      "Epoch 9/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0487 - accuracy: 0.9851 - val_loss: 0.0533 - val_accuracy: 0.9853\n",
      "Epoch 10/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0459 - accuracy: 0.9856 - val_loss: 0.0575 - val_accuracy: 0.9832\n",
      "Epoch 11/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.0518 - val_accuracy: 0.9870\n",
      "Epoch 12/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0411 - accuracy: 0.9874 - val_loss: 0.0476 - val_accuracy: 0.9858\n",
      "Epoch 13/100\n",
      "3375/3375 [==============================] - 19s 5ms/step - loss: 0.0389 - accuracy: 0.9879 - val_loss: 0.0543 - val_accuracy: 0.9858\n",
      "Epoch 14/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0374 - accuracy: 0.9883 - val_loss: 0.0454 - val_accuracy: 0.9887\n",
      "Epoch 15/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.0498 - val_accuracy: 0.9860\n",
      "Epoch 16/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0339 - accuracy: 0.9891 - val_loss: 0.0486 - val_accuracy: 0.9875\n",
      "Epoch 17/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0321 - accuracy: 0.9903 - val_loss: 0.0473 - val_accuracy: 0.9880\n",
      "Epoch 18/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.0481 - val_accuracy: 0.9868\n",
      "Epoch 19/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 0.0479 - val_accuracy: 0.9867\n",
      "Epoch 20/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0284 - accuracy: 0.9910 - val_loss: 0.0429 - val_accuracy: 0.9882\n",
      "Epoch 21/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0269 - accuracy: 0.9916 - val_loss: 0.0525 - val_accuracy: 0.9872\n",
      "Epoch 22/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.0503 - val_accuracy: 0.9870\n",
      "Epoch 23/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0248 - accuracy: 0.9927 - val_loss: 0.0436 - val_accuracy: 0.9872\n",
      "Epoch 24/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0452 - val_accuracy: 0.9863\n",
      "Epoch 25/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0490 - val_accuracy: 0.9868\n",
      "Epoch 26/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0226 - accuracy: 0.9928 - val_loss: 0.0425 - val_accuracy: 0.9880\n",
      "Epoch 27/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0443 - val_accuracy: 0.9882\n",
      "Epoch 28/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0454 - val_accuracy: 0.9885\n",
      "Epoch 29/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.0447 - val_accuracy: 0.9873\n",
      "Epoch 30/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.0475 - val_accuracy: 0.9872\n",
      "Epoch 31/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0494 - val_accuracy: 0.9872\n",
      "Epoch 32/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 0.0436 - val_accuracy: 0.9880\n",
      "Epoch 33/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 34/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.0484 - val_accuracy: 0.9875\n",
      "Epoch 35/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.0451 - val_accuracy: 0.9890\n",
      "Epoch 36/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.0506 - val_accuracy: 0.9880\n",
      "Epoch 37/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.0465 - val_accuracy: 0.9890\n",
      "Epoch 38/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0489 - val_accuracy: 0.9888\n",
      "Epoch 39/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0489 - val_accuracy: 0.9885\n",
      "Epoch 40/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0532 - val_accuracy: 0.9873\n",
      "Epoch 41/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0455 - val_accuracy: 0.9897\n",
      "Epoch 42/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0487 - val_accuracy: 0.9870\n",
      "Epoch 43/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0473 - val_accuracy: 0.9885\n",
      "Epoch 44/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.0465 - val_accuracy: 0.9895\n",
      "Epoch 45/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.0489 - val_accuracy: 0.9887\n",
      "Epoch 46/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0470 - val_accuracy: 0.9880\n",
      "Epoch 47/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.0461 - val_accuracy: 0.9885\n",
      "Epoch 48/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0462 - val_accuracy: 0.9890\n",
      "Epoch 49/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.0484 - val_accuracy: 0.9883\n",
      "Epoch 50/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0494 - val_accuracy: 0.9880\n",
      "Epoch 51/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0487 - val_accuracy: 0.9897\n",
      "Epoch 52/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0490 - val_accuracy: 0.9890\n",
      "Epoch 53/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0508 - val_accuracy: 0.9888\n",
      "Epoch 54/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0499 - val_accuracy: 0.9887\n",
      "Epoch 55/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0499 - val_accuracy: 0.9888\n",
      "Epoch 56/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0503 - val_accuracy: 0.9897\n",
      "Epoch 57/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0510 - val_accuracy: 0.9890\n",
      "Epoch 58/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0517 - val_accuracy: 0.9885\n",
      "Epoch 59/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0551 - val_accuracy: 0.9892\n",
      "Epoch 60/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0508 - val_accuracy: 0.9880\n",
      "Epoch 61/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0532 - val_accuracy: 0.9893\n",
      "Epoch 62/100\n",
      "3375/3375 [==============================] - 22s 6ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.0542 - val_accuracy: 0.9888\n",
      "Epoch 63/100\n",
      "3375/3375 [==============================] - 20s 6ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0559 - val_accuracy: 0.9880\n",
      "Epoch 64/100\n",
      "3375/3375 [==============================] - 19s 6ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0541 - val_accuracy: 0.9888\n",
      "Epoch 65/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0502 - val_accuracy: 0.9895\n",
      "Epoch 66/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0543 - val_accuracy: 0.9890\n",
      "Epoch 67/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0574 - val_accuracy: 0.9875\n",
      "Epoch 68/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0518 - val_accuracy: 0.9895\n",
      "Epoch 69/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0590 - val_accuracy: 0.9880\n",
      "Epoch 70/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0546 - val_accuracy: 0.9892\n",
      "Epoch 71/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0544 - val_accuracy: 0.9893\n",
      "Epoch 72/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0564 - val_accuracy: 0.9885\n",
      "Epoch 73/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0566 - val_accuracy: 0.9883\n",
      "Epoch 74/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0547 - val_accuracy: 0.9890\n",
      "Epoch 75/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0559 - val_accuracy: 0.9883\n",
      "Epoch 76/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0588 - val_accuracy: 0.9882\n",
      "Epoch 77/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0563 - val_accuracy: 0.9883\n",
      "Epoch 78/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0567 - val_accuracy: 0.9888\n",
      "Epoch 79/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0582 - val_accuracy: 0.9882\n",
      "Epoch 80/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0593 - val_accuracy: 0.9878\n",
      "Epoch 81/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0562 - val_accuracy: 0.9885\n",
      "Epoch 82/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0578 - val_accuracy: 0.9893\n",
      "Epoch 83/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9878\n",
      "Epoch 84/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0584 - val_accuracy: 0.9887\n",
      "Epoch 85/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0596 - val_accuracy: 0.9882\n",
      "Epoch 86/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 9.7785e-04 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9888\n",
      "Epoch 87/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 9.2364e-04 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 0.9885\n",
      "Epoch 88/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 9.5239e-04 - accuracy: 0.9999 - val_loss: 0.0600 - val_accuracy: 0.9888\n",
      "Epoch 89/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 9.6320e-04 - accuracy: 0.9999 - val_loss: 0.0603 - val_accuracy: 0.9880\n",
      "Epoch 90/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 9.9061e-04 - accuracy: 0.9999 - val_loss: 0.0613 - val_accuracy: 0.9888\n",
      "Epoch 91/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 8.0307e-04 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 0.9892\n",
      "Epoch 92/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 8.9333e-04 - accuracy: 0.9999 - val_loss: 0.0614 - val_accuracy: 0.9883\n",
      "Epoch 93/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 8.0205e-04 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 0.9893\n",
      "Epoch 94/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 7.6015e-04 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9888\n",
      "Epoch 95/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 7.1953e-04 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9887\n",
      "Epoch 96/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 6.7071e-04 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 0.9888\n",
      "Epoch 97/100\n",
      "3375/3375 [==============================] - 18s 5ms/step - loss: 6.3490e-04 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9885\n",
      "Epoch 98/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 6.5776e-04 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9890\n",
      "Epoch 99/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 7.0337e-04 - accuracy: 0.9999 - val_loss: 0.0612 - val_accuracy: 0.9890\n",
      "Epoch 100/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 6.2765e-04 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 0.9888\n",
      "313/313 - 1s - loss: 0.0640 - accuracy: 0.9892\n",
      "testSetLoss: 0.06401630491018295 - testSetAccuracyz: 0.9891999959945679%\n"
     ]
    }
   ],
   "source": [
    "test5_16 = trainModel4(100, 16)\n",
    "hist_df = pd.DataFrame(test5_16.history)\n",
    "hist_json_file = 'test5_16.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_44 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.5812 - accuracy: 0.8377 - val_loss: 0.1866 - val_accuracy: 0.9448\n",
      "Epoch 2/100\n",
      "1688/1688 [==============================] - 9s 5ms/step - loss: 0.1730 - accuracy: 0.9490 - val_loss: 0.1314 - val_accuracy: 0.9652\n",
      "Epoch 3/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.1266 - accuracy: 0.9619 - val_loss: 0.0930 - val_accuracy: 0.9720\n",
      "Epoch 4/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.1048 - accuracy: 0.9680 - val_loss: 0.0920 - val_accuracy: 0.9722\n",
      "Epoch 5/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0910 - accuracy: 0.9722 - val_loss: 0.0721 - val_accuracy: 0.9790\n",
      "Epoch 6/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0810 - accuracy: 0.9753 - val_loss: 0.0713 - val_accuracy: 0.9787\n",
      "Epoch 7/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0743 - accuracy: 0.9769 - val_loss: 0.0827 - val_accuracy: 0.9758\n",
      "Epoch 8/100\n",
      "1688/1688 [==============================] - 9s 6ms/step - loss: 0.0688 - accuracy: 0.9789 - val_loss: 0.0669 - val_accuracy: 0.9817\n",
      "Epoch 9/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0643 - accuracy: 0.9801 - val_loss: 0.0616 - val_accuracy: 0.9830\n",
      "Epoch 10/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0605 - accuracy: 0.9817 - val_loss: 0.0584 - val_accuracy: 0.9830\n",
      "Epoch 11/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0571 - accuracy: 0.9825 - val_loss: 0.0551 - val_accuracy: 0.9845\n",
      "Epoch 12/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0546 - accuracy: 0.9836 - val_loss: 0.0540 - val_accuracy: 0.9852\n",
      "Epoch 13/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0524 - accuracy: 0.9841 - val_loss: 0.0603 - val_accuracy: 0.9833\n",
      "Epoch 14/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0501 - accuracy: 0.9845 - val_loss: 0.0509 - val_accuracy: 0.9857\n",
      "Epoch 15/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0483 - accuracy: 0.9851 - val_loss: 0.0528 - val_accuracy: 0.9863\n",
      "Epoch 16/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0461 - accuracy: 0.9856 - val_loss: 0.0548 - val_accuracy: 0.9847\n",
      "Epoch 17/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0447 - accuracy: 0.9864 - val_loss: 0.0485 - val_accuracy: 0.9855\n",
      "Epoch 18/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0424 - accuracy: 0.9873 - val_loss: 0.0513 - val_accuracy: 0.9860\n",
      "Epoch 19/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0412 - accuracy: 0.9874 - val_loss: 0.0502 - val_accuracy: 0.9862\n",
      "Epoch 20/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.0569 - val_accuracy: 0.9850\n",
      "Epoch 21/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 0.0472 - val_accuracy: 0.9867\n",
      "Epoch 22/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0379 - accuracy: 0.9884 - val_loss: 0.0449 - val_accuracy: 0.9868\n",
      "Epoch 23/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0364 - accuracy: 0.9889 - val_loss: 0.0455 - val_accuracy: 0.9870\n",
      "Epoch 24/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0359 - accuracy: 0.9886 - val_loss: 0.0486 - val_accuracy: 0.9857\n",
      "Epoch 25/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 0.0453 - val_accuracy: 0.9872\n",
      "Epoch 26/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0334 - accuracy: 0.9895 - val_loss: 0.0514 - val_accuracy: 0.9857\n",
      "Epoch 27/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 0.0471 - val_accuracy: 0.9865\n",
      "Epoch 28/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.0511 - val_accuracy: 0.9875\n",
      "Epoch 29/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0306 - accuracy: 0.9906 - val_loss: 0.0447 - val_accuracy: 0.9867\n",
      "Epoch 30/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0296 - accuracy: 0.9907 - val_loss: 0.0428 - val_accuracy: 0.9880\n",
      "Epoch 31/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 0.0445 - val_accuracy: 0.9875\n",
      "Epoch 32/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.0461 - val_accuracy: 0.9858\n",
      "Epoch 33/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.0427 - val_accuracy: 0.9882\n",
      "Epoch 34/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0263 - accuracy: 0.9922 - val_loss: 0.0477 - val_accuracy: 0.9862\n",
      "Epoch 35/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0264 - accuracy: 0.9919 - val_loss: 0.0414 - val_accuracy: 0.9888\n",
      "Epoch 36/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.0400 - val_accuracy: 0.9887\n",
      "Epoch 37/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0247 - accuracy: 0.9927 - val_loss: 0.0421 - val_accuracy: 0.9893\n",
      "Epoch 38/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0241 - accuracy: 0.9926 - val_loss: 0.0465 - val_accuracy: 0.9867\n",
      "Epoch 39/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0432 - val_accuracy: 0.9877\n",
      "Epoch 40/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 0.0433 - val_accuracy: 0.9875\n",
      "Epoch 41/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.0420 - val_accuracy: 0.9885\n",
      "Epoch 42/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0409 - val_accuracy: 0.9893\n",
      "Epoch 43/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 0.0397 - val_accuracy: 0.9888\n",
      "Epoch 44/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0441 - val_accuracy: 0.9875\n",
      "Epoch 45/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.0429 - val_accuracy: 0.9880\n",
      "Epoch 46/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.0441 - val_accuracy: 0.9890\n",
      "Epoch 47/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.0442 - val_accuracy: 0.9878\n",
      "Epoch 48/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0431 - val_accuracy: 0.9878\n",
      "Epoch 49/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.0459 - val_accuracy: 0.9872\n",
      "Epoch 50/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0481 - val_accuracy: 0.9865\n",
      "Epoch 51/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.0422 - val_accuracy: 0.9880\n",
      "Epoch 52/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.0430 - val_accuracy: 0.9878\n",
      "Epoch 53/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0439 - val_accuracy: 0.9868\n",
      "Epoch 54/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0429 - val_accuracy: 0.9878\n",
      "Epoch 55/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.0456 - val_accuracy: 0.9880\n",
      "Epoch 56/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0431 - val_accuracy: 0.9897\n",
      "Epoch 57/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0501 - val_accuracy: 0.9865\n",
      "Epoch 58/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0409 - val_accuracy: 0.9898\n",
      "Epoch 59/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.0422 - val_accuracy: 0.9885\n",
      "Epoch 60/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.0458 - val_accuracy: 0.9870\n",
      "Epoch 61/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0458 - val_accuracy: 0.9898\n",
      "Epoch 62/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.0427 - val_accuracy: 0.9890\n",
      "Epoch 63/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.0433 - val_accuracy: 0.9892\n",
      "Epoch 64/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.0461 - val_accuracy: 0.9875\n",
      "Epoch 65/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.0460 - val_accuracy: 0.9882\n",
      "Epoch 66/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.0477 - val_accuracy: 0.9888\n",
      "Epoch 67/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.0505 - val_accuracy: 0.9855\n",
      "Epoch 68/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.0415 - val_accuracy: 0.9893\n",
      "Epoch 69/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.0465 - val_accuracy: 0.9887\n",
      "Epoch 70/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.0491 - val_accuracy: 0.9885\n",
      "Epoch 71/100\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0515 - val_accuracy: 0.9875\n",
      "Epoch 72/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.0430 - val_accuracy: 0.9895\n",
      "Epoch 73/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0455 - val_accuracy: 0.9893\n",
      "Epoch 74/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0092 - accuracy: 0.9976 - val_loss: 0.0447 - val_accuracy: 0.9890\n",
      "Epoch 75/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0090 - accuracy: 0.9978 - val_loss: 0.0477 - val_accuracy: 0.9873\n",
      "Epoch 76/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0468 - val_accuracy: 0.9888\n",
      "Epoch 77/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0084 - accuracy: 0.9979 - val_loss: 0.0455 - val_accuracy: 0.9892\n",
      "Epoch 78/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.0506 - val_accuracy: 0.9883\n",
      "Epoch 79/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.0471 - val_accuracy: 0.9887\n",
      "Epoch 80/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.0469 - val_accuracy: 0.9883\n",
      "Epoch 81/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0465 - val_accuracy: 0.9887\n",
      "Epoch 82/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0508 - val_accuracy: 0.9870\n",
      "Epoch 83/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0478 - val_accuracy: 0.9880\n",
      "Epoch 84/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0464 - val_accuracy: 0.9885\n",
      "Epoch 85/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.0492 - val_accuracy: 0.9875\n",
      "Epoch 86/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.0454 - val_accuracy: 0.9895\n",
      "Epoch 87/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0496 - val_accuracy: 0.9880\n",
      "Epoch 88/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0496 - val_accuracy: 0.9880\n",
      "Epoch 89/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0499 - val_accuracy: 0.9885\n",
      "Epoch 90/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0500 - val_accuracy: 0.9885\n",
      "Epoch 91/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0482 - val_accuracy: 0.9888\n",
      "Epoch 92/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0475 - val_accuracy: 0.9900\n",
      "Epoch 93/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0487 - val_accuracy: 0.9893\n",
      "Epoch 94/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0499 - val_accuracy: 0.9888\n",
      "Epoch 95/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0507 - val_accuracy: 0.9885\n",
      "Epoch 96/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.0538 - val_accuracy: 0.9885\n",
      "Epoch 97/100\n",
      "1688/1688 [==============================] - 11s 6ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0495 - val_accuracy: 0.9887\n",
      "Epoch 98/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0504 - val_accuracy: 0.9887\n",
      "Epoch 99/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0511 - val_accuracy: 0.9885\n",
      "Epoch 100/100\n",
      "1688/1688 [==============================] - 10s 6ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0508 - val_accuracy: 0.9890\n",
      "313/313 - 1s - loss: 0.0464 - accuracy: 0.9889\n",
      "testSetLoss: 0.0463867262005806 - testSetAccuracyz: 0.9889000058174133%\n"
     ]
    }
   ],
   "source": [
    "test5_32 = trainModel4(100, 32)\n",
    "hist_df = pd.DataFrame(test5_32.history)\n",
    "hist_json_file = 'test5_32.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "844/844 [==============================] - 7s 7ms/step - loss: 0.9876 - accuracy: 0.7276 - val_loss: 0.2683 - val_accuracy: 0.9223\n",
      "Epoch 2/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.2717 - accuracy: 0.9201 - val_loss: 0.1737 - val_accuracy: 0.9500\n",
      "Epoch 3/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.1909 - accuracy: 0.9440 - val_loss: 0.1337 - val_accuracy: 0.9635\n",
      "Epoch 4/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.1501 - accuracy: 0.9561 - val_loss: 0.1118 - val_accuracy: 0.9682\n",
      "Epoch 5/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.1259 - accuracy: 0.9628 - val_loss: 0.1019 - val_accuracy: 0.9715\n",
      "Epoch 6/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.1101 - accuracy: 0.9675 - val_loss: 0.0940 - val_accuracy: 0.9738\n",
      "Epoch 7/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0989 - accuracy: 0.9704 - val_loss: 0.0806 - val_accuracy: 0.9782\n",
      "Epoch 8/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0915 - accuracy: 0.9729 - val_loss: 0.0787 - val_accuracy: 0.9772\n",
      "Epoch 9/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0846 - accuracy: 0.9742 - val_loss: 0.0736 - val_accuracy: 0.9802\n",
      "Epoch 10/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0793 - accuracy: 0.9762 - val_loss: 0.0720 - val_accuracy: 0.9807\n",
      "Epoch 11/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0752 - accuracy: 0.9772 - val_loss: 0.0678 - val_accuracy: 0.9808\n",
      "Epoch 12/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0715 - accuracy: 0.9780 - val_loss: 0.0655 - val_accuracy: 0.9810\n",
      "Epoch 13/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0680 - accuracy: 0.9792 - val_loss: 0.0625 - val_accuracy: 0.9828\n",
      "Epoch 14/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0651 - accuracy: 0.9803 - val_loss: 0.0628 - val_accuracy: 0.9825\n",
      "Epoch 15/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0629 - accuracy: 0.9811 - val_loss: 0.0612 - val_accuracy: 0.9825\n",
      "Epoch 16/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0611 - accuracy: 0.9820 - val_loss: 0.0602 - val_accuracy: 0.9843\n",
      "Epoch 17/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0588 - accuracy: 0.9819 - val_loss: 0.0596 - val_accuracy: 0.9838\n",
      "Epoch 18/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0568 - accuracy: 0.9828 - val_loss: 0.0625 - val_accuracy: 0.9845\n",
      "Epoch 19/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0554 - accuracy: 0.9835 - val_loss: 0.0577 - val_accuracy: 0.9842\n",
      "Epoch 20/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0531 - accuracy: 0.9842 - val_loss: 0.0632 - val_accuracy: 0.9813\n",
      "Epoch 21/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0520 - accuracy: 0.9844 - val_loss: 0.0566 - val_accuracy: 0.9852\n",
      "Epoch 22/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0503 - accuracy: 0.9854 - val_loss: 0.0587 - val_accuracy: 0.9850\n",
      "Epoch 23/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0497 - accuracy: 0.9852 - val_loss: 0.0560 - val_accuracy: 0.9843\n",
      "Epoch 24/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0481 - accuracy: 0.9855 - val_loss: 0.0555 - val_accuracy: 0.9860\n",
      "Epoch 25/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0469 - accuracy: 0.9861 - val_loss: 0.0526 - val_accuracy: 0.9860\n",
      "Epoch 26/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0462 - accuracy: 0.9860 - val_loss: 0.0529 - val_accuracy: 0.9860\n",
      "Epoch 27/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.0537 - val_accuracy: 0.9855\n",
      "Epoch 28/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0436 - accuracy: 0.9866 - val_loss: 0.0564 - val_accuracy: 0.9852\n",
      "Epoch 29/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0427 - accuracy: 0.9875 - val_loss: 0.0547 - val_accuracy: 0.9850\n",
      "Epoch 30/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0421 - accuracy: 0.9874 - val_loss: 0.0521 - val_accuracy: 0.9857\n",
      "Epoch 31/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0414 - accuracy: 0.9878 - val_loss: 0.0589 - val_accuracy: 0.9847\n",
      "Epoch 32/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0406 - accuracy: 0.9880 - val_loss: 0.0525 - val_accuracy: 0.9870\n",
      "Epoch 33/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0393 - accuracy: 0.9884 - val_loss: 0.0497 - val_accuracy: 0.9868\n",
      "Epoch 34/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0396 - accuracy: 0.9879 - val_loss: 0.0498 - val_accuracy: 0.9868\n",
      "Epoch 35/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0385 - accuracy: 0.9886 - val_loss: 0.0494 - val_accuracy: 0.9865\n",
      "Epoch 36/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0382 - accuracy: 0.9880 - val_loss: 0.0487 - val_accuracy: 0.9883\n",
      "Epoch 37/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0369 - accuracy: 0.9891 - val_loss: 0.0513 - val_accuracy: 0.9863\n",
      "Epoch 38/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0364 - accuracy: 0.9890 - val_loss: 0.0516 - val_accuracy: 0.9872\n",
      "Epoch 39/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0356 - accuracy: 0.9894 - val_loss: 0.0525 - val_accuracy: 0.9860\n",
      "Epoch 40/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 0.0354 - accuracy: 0.9895 - val_loss: 0.0499 - val_accuracy: 0.9877\n",
      "Epoch 41/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 0.0346 - accuracy: 0.9895 - val_loss: 0.0514 - val_accuracy: 0.9852\n",
      "Epoch 42/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 0.0342 - accuracy: 0.9899 - val_loss: 0.0537 - val_accuracy: 0.9862\n",
      "Epoch 43/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0335 - accuracy: 0.9897 - val_loss: 0.0483 - val_accuracy: 0.9877\n",
      "Epoch 44/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0326 - accuracy: 0.9901 - val_loss: 0.0493 - val_accuracy: 0.9873\n",
      "Epoch 45/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0322 - accuracy: 0.9903 - val_loss: 0.0473 - val_accuracy: 0.9865\n",
      "Epoch 46/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 0.0487 - val_accuracy: 0.9870\n",
      "Epoch 47/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0313 - accuracy: 0.9906 - val_loss: 0.0515 - val_accuracy: 0.9867\n",
      "Epoch 48/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0309 - accuracy: 0.9907 - val_loss: 0.0483 - val_accuracy: 0.9868\n",
      "Epoch 49/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0301 - accuracy: 0.9909 - val_loss: 0.0460 - val_accuracy: 0.9880\n",
      "Epoch 50/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0297 - accuracy: 0.9911 - val_loss: 0.0473 - val_accuracy: 0.9878\n",
      "Epoch 51/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0294 - accuracy: 0.9905 - val_loss: 0.0485 - val_accuracy: 0.9872\n",
      "Epoch 52/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.0466 - val_accuracy: 0.9887\n",
      "Epoch 53/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.0487 - val_accuracy: 0.9877\n",
      "Epoch 54/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.0490 - val_accuracy: 0.9875\n",
      "Epoch 55/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0278 - accuracy: 0.9916 - val_loss: 0.0491 - val_accuracy: 0.9867\n",
      "Epoch 56/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.0478 - val_accuracy: 0.9867\n",
      "Epoch 57/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0273 - accuracy: 0.9918 - val_loss: 0.0460 - val_accuracy: 0.9880\n",
      "Epoch 58/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 0.0470 - val_accuracy: 0.9887\n",
      "Epoch 59/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 0.0510 - val_accuracy: 0.9870\n",
      "Epoch 60/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.0477 - val_accuracy: 0.9882\n",
      "Epoch 61/100\n",
      "844/844 [==============================] - 6s 8ms/step - loss: 0.0253 - accuracy: 0.9919 - val_loss: 0.0485 - val_accuracy: 0.9870\n",
      "Epoch 62/100\n",
      "844/844 [==============================] - 7s 8ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 0.0463 - val_accuracy: 0.9885\n",
      "Epoch 63/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 0.0487 - val_accuracy: 0.9868\n",
      "Epoch 64/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.0467 - val_accuracy: 0.9872\n",
      "Epoch 65/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0237 - accuracy: 0.9926 - val_loss: 0.0484 - val_accuracy: 0.9878\n",
      "Epoch 66/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0475 - val_accuracy: 0.9875\n",
      "Epoch 67/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.0476 - val_accuracy: 0.9878\n",
      "Epoch 68/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.0485 - val_accuracy: 0.9885\n",
      "Epoch 69/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0533 - val_accuracy: 0.9860\n",
      "Epoch 70/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0478 - val_accuracy: 0.9885\n",
      "Epoch 71/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0485 - val_accuracy: 0.9877\n",
      "Epoch 72/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0215 - accuracy: 0.9935 - val_loss: 0.0511 - val_accuracy: 0.9867\n",
      "Epoch 73/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0480 - val_accuracy: 0.9870\n",
      "Epoch 74/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0479 - val_accuracy: 0.9877\n",
      "Epoch 75/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0501 - val_accuracy: 0.9868\n",
      "Epoch 76/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.0476 - val_accuracy: 0.9878\n",
      "Epoch 77/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.0465 - val_accuracy: 0.9868\n",
      "Epoch 78/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0482 - val_accuracy: 0.9877\n",
      "Epoch 79/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.0514 - val_accuracy: 0.9868\n",
      "Epoch 80/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 0.0490 - val_accuracy: 0.9868\n",
      "Epoch 81/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.0493 - val_accuracy: 0.9875\n",
      "Epoch 82/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.0519 - val_accuracy: 0.9870\n",
      "Epoch 83/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.0500 - val_accuracy: 0.9872\n",
      "Epoch 84/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0503 - val_accuracy: 0.9882\n",
      "Epoch 85/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.0521 - val_accuracy: 0.9878\n",
      "Epoch 86/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0534 - val_accuracy: 0.9858\n",
      "Epoch 87/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0476 - val_accuracy: 0.9887\n",
      "Epoch 88/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.0485 - val_accuracy: 0.9880\n",
      "Epoch 89/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0163 - accuracy: 0.9954 - val_loss: 0.0480 - val_accuracy: 0.9880\n",
      "Epoch 90/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.0501 - val_accuracy: 0.9878\n",
      "Epoch 91/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0160 - accuracy: 0.9955 - val_loss: 0.0520 - val_accuracy: 0.9870\n",
      "Epoch 92/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0491 - val_accuracy: 0.9877\n",
      "Epoch 93/100\n",
      "844/844 [==============================] - 5s 6ms/step - loss: 0.0156 - accuracy: 0.9957 - val_loss: 0.0485 - val_accuracy: 0.9888\n",
      "Epoch 94/100\n",
      "844/844 [==============================] - 5s 7ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.0465 - val_accuracy: 0.9880\n",
      "Epoch 95/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.0478 - val_accuracy: 0.9883\n",
      "Epoch 96/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.0485 - val_accuracy: 0.9878\n",
      "Epoch 97/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.0473 - val_accuracy: 0.9883\n",
      "Epoch 98/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.0533 - val_accuracy: 0.9873\n",
      "Epoch 99/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0140 - accuracy: 0.9960 - val_loss: 0.0504 - val_accuracy: 0.9870\n",
      "Epoch 100/100\n",
      "844/844 [==============================] - 6s 7ms/step - loss: 0.0139 - accuracy: 0.9964 - val_loss: 0.0480 - val_accuracy: 0.9887\n",
      "313/313 - 1s - loss: 0.0434 - accuracy: 0.9879\n",
      "testSetLoss: 0.043380290269851685 - testSetAccuracyz: 0.9879000186920166%\n"
     ]
    }
   ],
   "source": [
    "test5_64 = trainModel4(100, 64)\n",
    "hist_df = pd.DataFrame(test5_64.history)\n",
    "hist_json_file = 'test5_64.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_48 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "422/422 [==============================] - 5s 10ms/step - loss: 1.2086 - accuracy: 0.6900 - val_loss: 0.3679 - val_accuracy: 0.9005\n",
      "Epoch 2/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.3650 - accuracy: 0.8929 - val_loss: 0.2498 - val_accuracy: 0.9290\n",
      "Epoch 3/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.2789 - accuracy: 0.9180 - val_loss: 0.2005 - val_accuracy: 0.9448\n",
      "Epoch 4/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.2298 - accuracy: 0.9330 - val_loss: 0.1691 - val_accuracy: 0.9537\n",
      "Epoch 5/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.1953 - accuracy: 0.9431 - val_loss: 0.1490 - val_accuracy: 0.9588\n",
      "Epoch 6/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.1700 - accuracy: 0.9505 - val_loss: 0.1258 - val_accuracy: 0.9657\n",
      "Epoch 7/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.1520 - accuracy: 0.9559 - val_loss: 0.1224 - val_accuracy: 0.9657\n",
      "Epoch 8/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.1380 - accuracy: 0.9597 - val_loss: 0.1115 - val_accuracy: 0.9688\n",
      "Epoch 9/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.1272 - accuracy: 0.9627 - val_loss: 0.1037 - val_accuracy: 0.9715\n",
      "Epoch 10/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.1178 - accuracy: 0.9654 - val_loss: 0.0974 - val_accuracy: 0.9720\n",
      "Epoch 11/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.1111 - accuracy: 0.9675 - val_loss: 0.0936 - val_accuracy: 0.9733\n",
      "Epoch 12/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.1044 - accuracy: 0.9689 - val_loss: 0.0888 - val_accuracy: 0.9758\n",
      "Epoch 13/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0995 - accuracy: 0.9701 - val_loss: 0.0873 - val_accuracy: 0.9743\n",
      "Epoch 14/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0950 - accuracy: 0.9716 - val_loss: 0.0808 - val_accuracy: 0.9772\n",
      "Epoch 15/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0908 - accuracy: 0.9728 - val_loss: 0.0877 - val_accuracy: 0.9760\n",
      "Epoch 16/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0875 - accuracy: 0.9737 - val_loss: 0.0832 - val_accuracy: 0.9772\n",
      "Epoch 17/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0842 - accuracy: 0.9749 - val_loss: 0.0796 - val_accuracy: 0.9765\n",
      "Epoch 18/100\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0811 - accuracy: 0.9757 - val_loss: 0.0780 - val_accuracy: 0.9788\n",
      "Epoch 19/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0790 - accuracy: 0.9762 - val_loss: 0.0751 - val_accuracy: 0.9785\n",
      "Epoch 20/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0765 - accuracy: 0.9771 - val_loss: 0.0713 - val_accuracy: 0.9785\n",
      "Epoch 21/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0742 - accuracy: 0.9776 - val_loss: 0.0696 - val_accuracy: 0.9798\n",
      "Epoch 22/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0723 - accuracy: 0.9784 - val_loss: 0.0703 - val_accuracy: 0.9808\n",
      "Epoch 23/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0708 - accuracy: 0.9785 - val_loss: 0.0697 - val_accuracy: 0.9797\n",
      "Epoch 24/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0688 - accuracy: 0.9786 - val_loss: 0.0657 - val_accuracy: 0.9818\n",
      "Epoch 25/100\n",
      "422/422 [==============================] - 4s 11ms/step - loss: 0.0667 - accuracy: 0.9792 - val_loss: 0.0651 - val_accuracy: 0.9825\n",
      "Epoch 26/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0655 - accuracy: 0.9799 - val_loss: 0.0661 - val_accuracy: 0.9817\n",
      "Epoch 27/100\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0641 - accuracy: 0.9804 - val_loss: 0.0641 - val_accuracy: 0.9820\n",
      "Epoch 28/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0630 - accuracy: 0.9808 - val_loss: 0.0633 - val_accuracy: 0.9823\n",
      "Epoch 29/100\n",
      "422/422 [==============================] - 5s 12ms/step - loss: 0.0612 - accuracy: 0.9815 - val_loss: 0.0600 - val_accuracy: 0.9833\n",
      "Epoch 30/100\n",
      "422/422 [==============================] - 5s 12ms/step - loss: 0.0605 - accuracy: 0.9814 - val_loss: 0.0611 - val_accuracy: 0.9832\n",
      "Epoch 31/100\n",
      "422/422 [==============================] - 5s 13ms/step - loss: 0.0590 - accuracy: 0.9819 - val_loss: 0.0618 - val_accuracy: 0.9827\n",
      "Epoch 32/100\n",
      "422/422 [==============================] - 5s 12ms/step - loss: 0.0577 - accuracy: 0.9826 - val_loss: 0.0642 - val_accuracy: 0.9828\n",
      "Epoch 33/100\n",
      "422/422 [==============================] - 5s 12ms/step - loss: 0.0570 - accuracy: 0.9832 - val_loss: 0.0650 - val_accuracy: 0.9820\n",
      "Epoch 34/100\n",
      "422/422 [==============================] - 5s 12ms/step - loss: 0.0563 - accuracy: 0.9828 - val_loss: 0.0598 - val_accuracy: 0.9830\n",
      "Epoch 35/100\n",
      "422/422 [==============================] - 5s 11ms/step - loss: 0.0549 - accuracy: 0.9836 - val_loss: 0.0631 - val_accuracy: 0.9818\n",
      "Epoch 36/100\n",
      "422/422 [==============================] - 5s 11ms/step - loss: 0.0541 - accuracy: 0.9833 - val_loss: 0.0582 - val_accuracy: 0.9830\n",
      "Epoch 37/100\n",
      "422/422 [==============================] - 5s 12ms/step - loss: 0.0533 - accuracy: 0.9840 - val_loss: 0.0564 - val_accuracy: 0.9843\n",
      "Epoch 38/100\n",
      "422/422 [==============================] - 5s 12ms/step - loss: 0.0525 - accuracy: 0.9838 - val_loss: 0.0589 - val_accuracy: 0.9837\n",
      "Epoch 39/100\n",
      "422/422 [==============================] - 5s 12ms/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 0.0602 - val_accuracy: 0.9837\n",
      "Epoch 40/100\n",
      "422/422 [==============================] - 5s 12ms/step - loss: 0.0509 - accuracy: 0.9845 - val_loss: 0.0572 - val_accuracy: 0.9835\n",
      "Epoch 41/100\n",
      "422/422 [==============================] - 5s 11ms/step - loss: 0.0502 - accuracy: 0.9851 - val_loss: 0.0575 - val_accuracy: 0.9825\n",
      "Epoch 42/100\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0494 - accuracy: 0.9849 - val_loss: 0.0580 - val_accuracy: 0.9832\n",
      "Epoch 43/100\n",
      "422/422 [==============================] - 5s 11ms/step - loss: 0.0490 - accuracy: 0.9851 - val_loss: 0.0550 - val_accuracy: 0.9842\n",
      "Epoch 44/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0483 - accuracy: 0.9853 - val_loss: 0.0568 - val_accuracy: 0.9840\n",
      "Epoch 45/100\n",
      "422/422 [==============================] - 7s 18ms/step - loss: 0.0472 - accuracy: 0.9858 - val_loss: 0.0560 - val_accuracy: 0.9843\n",
      "Epoch 46/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0470 - accuracy: 0.9857 - val_loss: 0.0560 - val_accuracy: 0.9837\n",
      "Epoch 47/100\n",
      "422/422 [==============================] - 8s 18ms/step - loss: 0.0465 - accuracy: 0.9862 - val_loss: 0.0541 - val_accuracy: 0.9860\n",
      "Epoch 48/100\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 0.0530 - val_accuracy: 0.9853\n",
      "Epoch 49/100\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0449 - accuracy: 0.9865 - val_loss: 0.0528 - val_accuracy: 0.9848\n",
      "Epoch 50/100\n",
      "422/422 [==============================] - 9s 20ms/step - loss: 0.0445 - accuracy: 0.9865 - val_loss: 0.0551 - val_accuracy: 0.9852\n",
      "Epoch 51/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0437 - accuracy: 0.9867 - val_loss: 0.0580 - val_accuracy: 0.9840\n",
      "Epoch 52/100\n",
      "422/422 [==============================] - 7s 17ms/step - loss: 0.0432 - accuracy: 0.9865 - val_loss: 0.0553 - val_accuracy: 0.9848\n",
      "Epoch 53/100\n",
      "422/422 [==============================] - 5s 12ms/step - loss: 0.0429 - accuracy: 0.9872 - val_loss: 0.0536 - val_accuracy: 0.9845\n",
      "Epoch 54/100\n",
      "422/422 [==============================] - 5s 11ms/step - loss: 0.0423 - accuracy: 0.9873 - val_loss: 0.0519 - val_accuracy: 0.9865\n",
      "Epoch 55/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0418 - accuracy: 0.9875 - val_loss: 0.0514 - val_accuracy: 0.9850\n",
      "Epoch 56/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.0508 - val_accuracy: 0.9862\n",
      "Epoch 57/100\n",
      "422/422 [==============================] - 4s 10ms/step - loss: 0.0409 - accuracy: 0.9874 - val_loss: 0.0526 - val_accuracy: 0.9853\n",
      "Epoch 58/100\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0401 - accuracy: 0.9879 - val_loss: 0.0506 - val_accuracy: 0.9863\n",
      "Epoch 59/100\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0398 - accuracy: 0.9877 - val_loss: 0.0496 - val_accuracy: 0.9867\n",
      "Epoch 60/100\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.0396 - accuracy: 0.9880 - val_loss: 0.0506 - val_accuracy: 0.9858\n",
      "Epoch 61/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0391 - accuracy: 0.9883 - val_loss: 0.0540 - val_accuracy: 0.9853\n",
      "Epoch 62/100\n",
      "422/422 [==============================] - 10s 23ms/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 0.0525 - val_accuracy: 0.9852\n",
      "Epoch 63/100\n",
      "422/422 [==============================] - 10s 23ms/step - loss: 0.0381 - accuracy: 0.9887 - val_loss: 0.0512 - val_accuracy: 0.9850\n",
      "Epoch 64/100\n",
      "422/422 [==============================] - 10s 23ms/step - loss: 0.0380 - accuracy: 0.9886 - val_loss: 0.0522 - val_accuracy: 0.9858\n",
      "Epoch 65/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.0530 - val_accuracy: 0.9858\n",
      "Epoch 66/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.0506 - val_accuracy: 0.9858\n",
      "Epoch 67/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0368 - accuracy: 0.9887 - val_loss: 0.0508 - val_accuracy: 0.9860\n",
      "Epoch 68/100\n",
      "422/422 [==============================] - 10s 23ms/step - loss: 0.0364 - accuracy: 0.9888 - val_loss: 0.0524 - val_accuracy: 0.9857\n",
      "Epoch 69/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0357 - accuracy: 0.9895 - val_loss: 0.0489 - val_accuracy: 0.9867\n",
      "Epoch 70/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0359 - accuracy: 0.9892 - val_loss: 0.0495 - val_accuracy: 0.9870\n",
      "Epoch 71/100\n",
      "422/422 [==============================] - 10s 23ms/step - loss: 0.0354 - accuracy: 0.9891 - val_loss: 0.0491 - val_accuracy: 0.9858\n",
      "Epoch 72/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 0.0593 - val_accuracy: 0.9833\n",
      "Epoch 73/100\n",
      "422/422 [==============================] - 10s 24ms/step - loss: 0.0343 - accuracy: 0.9894 - val_loss: 0.0531 - val_accuracy: 0.9855\n",
      "Epoch 74/100\n",
      "422/422 [==============================] - 10s 23ms/step - loss: 0.0343 - accuracy: 0.9897 - val_loss: 0.0507 - val_accuracy: 0.9850\n",
      "Epoch 75/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.0495 - val_accuracy: 0.9867\n",
      "Epoch 76/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 0.0499 - val_accuracy: 0.9857\n",
      "Epoch 77/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0336 - accuracy: 0.9899 - val_loss: 0.0493 - val_accuracy: 0.9870\n",
      "Epoch 78/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0331 - accuracy: 0.9899 - val_loss: 0.0496 - val_accuracy: 0.9867s - l\n",
      "Epoch 79/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 0.0487 - val_accuracy: 0.9870\n",
      "Epoch 80/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0325 - accuracy: 0.9899 - val_loss: 0.0537 - val_accuracy: 0.9847\n",
      "Epoch 81/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.0539 - val_accuracy: 0.9847\n",
      "Epoch 82/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0321 - accuracy: 0.9902 - val_loss: 0.0509 - val_accuracy: 0.9862\n",
      "Epoch 83/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0314 - accuracy: 0.9907 - val_loss: 0.0485 - val_accuracy: 0.9862\n",
      "Epoch 84/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 0.0482 - val_accuracy: 0.9872\n",
      "Epoch 85/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.0530 - val_accuracy: 0.9860\n",
      "Epoch 86/100\n",
      "422/422 [==============================] - 8s 20ms/step - loss: 0.0305 - accuracy: 0.9910 - val_loss: 0.0532 - val_accuracy: 0.9852\n",
      "Epoch 87/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0306 - accuracy: 0.9908 - val_loss: 0.0491 - val_accuracy: 0.9858\n",
      "Epoch 88/100\n",
      "422/422 [==============================] - 10s 23ms/step - loss: 0.0300 - accuracy: 0.9910 - val_loss: 0.0480 - val_accuracy: 0.9870\n",
      "Epoch 89/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.0486 - val_accuracy: 0.9867\n",
      "Epoch 90/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0294 - accuracy: 0.9913 - val_loss: 0.0515 - val_accuracy: 0.9857\n",
      "Epoch 91/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0295 - accuracy: 0.9907 - val_loss: 0.0487 - val_accuracy: 0.9855\n",
      "Epoch 92/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0292 - accuracy: 0.9910 - val_loss: 0.0507 - val_accuracy: 0.9857\n",
      "Epoch 93/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.0478 - val_accuracy: 0.9870\n",
      "Epoch 94/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.0485 - val_accuracy: 0.9863\n",
      "Epoch 95/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.0481 - val_accuracy: 0.9870\n",
      "Epoch 96/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.0503 - val_accuracy: 0.9853\n",
      "Epoch 97/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0279 - accuracy: 0.9913 - val_loss: 0.0494 - val_accuracy: 0.9867\n",
      "Epoch 98/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0278 - accuracy: 0.9916 - val_loss: 0.0487 - val_accuracy: 0.9880\n",
      "Epoch 99/100\n",
      "422/422 [==============================] - 9s 22ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.0496 - val_accuracy: 0.9860\n",
      "Epoch 100/100\n",
      "422/422 [==============================] - 9s 21ms/step - loss: 0.0271 - accuracy: 0.9919 - val_loss: 0.0471 - val_accuracy: 0.9867\n",
      "313/313 - 3s - loss: 0.0392 - accuracy: 0.9894\n",
      "testSetLoss: 0.03921043500304222 - testSetAccuracyz: 0.9894000291824341%\n"
     ]
    }
   ],
   "source": [
    "test5_128 = trainModel4(100, 128)\n",
    "hist_df = pd.DataFrame(test5_128.history)\n",
    "hist_json_file = 'test5_128.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_50 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "211/211 [==============================] - 8s 36ms/step - loss: 1.9610 - accuracy: 0.4866 - val_loss: 1.0835 - val_accuracy: 0.8030\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.6641 - accuracy: 0.8294 - val_loss: 0.3854 - val_accuracy: 0.8977\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.4081 - accuracy: 0.8814 - val_loss: 0.2866 - val_accuracy: 0.9182\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 9s 41ms/step - loss: 0.3391 - accuracy: 0.8995 - val_loss: 0.2453 - val_accuracy: 0.9323\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.2967 - accuracy: 0.9124 - val_loss: 0.2157 - val_accuracy: 0.9402\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.2648 - accuracy: 0.9226 - val_loss: 0.1929 - val_accuracy: 0.9473\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.2396 - accuracy: 0.9299 - val_loss: 0.1763 - val_accuracy: 0.9510\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.2189 - accuracy: 0.9364 - val_loss: 0.1649 - val_accuracy: 0.9538\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.2004 - accuracy: 0.9410 - val_loss: 0.1515 - val_accuracy: 0.9578\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 9s 40ms/step - loss: 0.1862 - accuracy: 0.9456 - val_loss: 0.1398 - val_accuracy: 0.9620\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1741 - accuracy: 0.9492 - val_loss: 0.1333 - val_accuracy: 0.9632\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.1632 - accuracy: 0.9527 - val_loss: 0.1240 - val_accuracy: 0.9660\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 9s 43ms/step - loss: 0.1539 - accuracy: 0.9551 - val_loss: 0.1186 - val_accuracy: 0.9690\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 9s 43ms/step - loss: 0.1462 - accuracy: 0.9578 - val_loss: 0.1133 - val_accuracy: 0.9698\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.1388 - accuracy: 0.9591 - val_loss: 0.1076 - val_accuracy: 0.9720\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1325 - accuracy: 0.9615 - val_loss: 0.1045 - val_accuracy: 0.9718\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1270 - accuracy: 0.9624 - val_loss: 0.1021 - val_accuracy: 0.9710\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.1224 - accuracy: 0.9636 - val_loss: 0.1014 - val_accuracy: 0.9727\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.1179 - accuracy: 0.9652 - val_loss: 0.0962 - val_accuracy: 0.9723\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.1135 - accuracy: 0.9662 - val_loss: 0.0934 - val_accuracy: 0.9745\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 8s 40ms/step - loss: 0.1098 - accuracy: 0.9676 - val_loss: 0.0910 - val_accuracy: 0.9740\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.1065 - accuracy: 0.9685 - val_loss: 0.0885 - val_accuracy: 0.9757\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 9s 42ms/step - loss: 0.1037 - accuracy: 0.9689 - val_loss: 0.0889 - val_accuracy: 0.9743\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 8s 39ms/step - loss: 0.1007 - accuracy: 0.9702 - val_loss: 0.0899 - val_accuracy: 0.9753\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.0985 - accuracy: 0.9704 - val_loss: 0.0818 - val_accuracy: 0.9770\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 8s 37ms/step - loss: 0.0959 - accuracy: 0.9713 - val_loss: 0.0799 - val_accuracy: 0.9780\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 4s 21ms/step - loss: 0.0935 - accuracy: 0.9715 - val_loss: 0.0787 - val_accuracy: 0.9783\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0917 - accuracy: 0.9726 - val_loss: 0.0779 - val_accuracy: 0.9782\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0894 - accuracy: 0.9730 - val_loss: 0.0788 - val_accuracy: 0.9773\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 0.0874 - accuracy: 0.9734 - val_loss: 0.0762 - val_accuracy: 0.9783\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 5s 22ms/step - loss: 0.0859 - accuracy: 0.9740 - val_loss: 0.0783 - val_accuracy: 0.9782\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 5s 21ms/step - loss: 0.0840 - accuracy: 0.9751 - val_loss: 0.0731 - val_accuracy: 0.9785\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0823 - accuracy: 0.9749 - val_loss: 0.0720 - val_accuracy: 0.9788\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0807 - accuracy: 0.9757 - val_loss: 0.0746 - val_accuracy: 0.9787\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0799 - accuracy: 0.9758 - val_loss: 0.0709 - val_accuracy: 0.9795\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0780 - accuracy: 0.9764 - val_loss: 0.0714 - val_accuracy: 0.9782\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0770 - accuracy: 0.9766 - val_loss: 0.0719 - val_accuracy: 0.9792\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0759 - accuracy: 0.9774 - val_loss: 0.0693 - val_accuracy: 0.9798\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0748 - accuracy: 0.9773 - val_loss: 0.0684 - val_accuracy: 0.9808\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 5s 23ms/step - loss: 0.0739 - accuracy: 0.9776 - val_loss: 0.0699 - val_accuracy: 0.9805\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0724 - accuracy: 0.9781 - val_loss: 0.0644 - val_accuracy: 0.9818\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0712 - accuracy: 0.9784 - val_loss: 0.0671 - val_accuracy: 0.9808\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0707 - accuracy: 0.9786 - val_loss: 0.0675 - val_accuracy: 0.9813\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0697 - accuracy: 0.9790 - val_loss: 0.0665 - val_accuracy: 0.9810\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0685 - accuracy: 0.9791 - val_loss: 0.0649 - val_accuracy: 0.9810\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0679 - accuracy: 0.9792 - val_loss: 0.0652 - val_accuracy: 0.9825\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0664 - accuracy: 0.9801 - val_loss: 0.0693 - val_accuracy: 0.9810\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0661 - accuracy: 0.9805 - val_loss: 0.0642 - val_accuracy: 0.9815\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0654 - accuracy: 0.9805 - val_loss: 0.0668 - val_accuracy: 0.9810\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0647 - accuracy: 0.9804 - val_loss: 0.0606 - val_accuracy: 0.9825\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0634 - accuracy: 0.9813 - val_loss: 0.0621 - val_accuracy: 0.9822\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0631 - accuracy: 0.9808 - val_loss: 0.0648 - val_accuracy: 0.9803\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0626 - accuracy: 0.9808 - val_loss: 0.0601 - val_accuracy: 0.9815\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0618 - accuracy: 0.9815 - val_loss: 0.0597 - val_accuracy: 0.9827\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0611 - accuracy: 0.9820 - val_loss: 0.0629 - val_accuracy: 0.9818\n",
      "Epoch 56/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0604 - accuracy: 0.9820 - val_loss: 0.0588 - val_accuracy: 0.9825\n",
      "Epoch 57/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0597 - accuracy: 0.9824 - val_loss: 0.0643 - val_accuracy: 0.9808\n",
      "Epoch 58/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0593 - accuracy: 0.9824 - val_loss: 0.0582 - val_accuracy: 0.9820\n",
      "Epoch 59/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0585 - accuracy: 0.9824 - val_loss: 0.0606 - val_accuracy: 0.9818\n",
      "Epoch 60/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0582 - accuracy: 0.9827 - val_loss: 0.0608 - val_accuracy: 0.9830\n",
      "Epoch 61/100\n",
      "211/211 [==============================] - 4s 17ms/step - loss: 0.0580 - accuracy: 0.9822 - val_loss: 0.0585 - val_accuracy: 0.9827\n",
      "Epoch 62/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0569 - accuracy: 0.9830 - val_loss: 0.0597 - val_accuracy: 0.9827\n",
      "Epoch 63/100\n",
      "211/211 [==============================] - 3s 16ms/step - loss: 0.0568 - accuracy: 0.9827 - val_loss: 0.0586 - val_accuracy: 0.9830\n",
      "Epoch 64/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0561 - accuracy: 0.9831 - val_loss: 0.0571 - val_accuracy: 0.9823\n",
      "Epoch 65/100\n",
      "211/211 [==============================] - 5s 25ms/step - loss: 0.0553 - accuracy: 0.9833 - val_loss: 0.0586 - val_accuracy: 0.9833\n",
      "Epoch 66/100\n",
      "211/211 [==============================] - 7s 31ms/step - loss: 0.0553 - accuracy: 0.9831 - val_loss: 0.0586 - val_accuracy: 0.9820\n",
      "Epoch 67/100\n",
      "211/211 [==============================] - 8s 38ms/step - loss: 0.0546 - accuracy: 0.9833 - val_loss: 0.0628 - val_accuracy: 0.9818\n",
      "Epoch 68/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.0541 - accuracy: 0.9836 - val_loss: 0.0561 - val_accuracy: 0.9833\n",
      "Epoch 69/100\n",
      "211/211 [==============================] - 7s 31ms/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 0.0555 - val_accuracy: 0.9830\n",
      "Epoch 70/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0531 - accuracy: 0.9840 - val_loss: 0.0604 - val_accuracy: 0.9823\n",
      "Epoch 71/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0530 - accuracy: 0.9837 - val_loss: 0.0561 - val_accuracy: 0.9832\n",
      "Epoch 72/100\n",
      "211/211 [==============================] - 6s 30ms/step - loss: 0.0524 - accuracy: 0.9840 - val_loss: 0.0546 - val_accuracy: 0.9840\n",
      "Epoch 73/100\n",
      "211/211 [==============================] - 6s 31ms/step - loss: 0.0516 - accuracy: 0.9844 - val_loss: 0.0571 - val_accuracy: 0.9832\n",
      "Epoch 74/100\n",
      "211/211 [==============================] - 4s 20ms/step - loss: 0.0516 - accuracy: 0.9845 - val_loss: 0.0558 - val_accuracy: 0.9833\n",
      "Epoch 75/100\n",
      "211/211 [==============================] - 4s 19ms/step - loss: 0.0511 - accuracy: 0.9846 - val_loss: 0.0560 - val_accuracy: 0.9842\n",
      "Epoch 76/100\n",
      "211/211 [==============================] - 4s 18ms/step - loss: 0.0508 - accuracy: 0.9848 - val_loss: 0.0537 - val_accuracy: 0.9847\n",
      "Epoch 77/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0503 - accuracy: 0.9847 - val_loss: 0.0549 - val_accuracy: 0.9838\n",
      "Epoch 78/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0496 - accuracy: 0.9849 - val_loss: 0.0586 - val_accuracy: 0.9832\n",
      "Epoch 79/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0493 - accuracy: 0.9854 - val_loss: 0.0553 - val_accuracy: 0.9840\n",
      "Epoch 80/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0490 - accuracy: 0.9853 - val_loss: 0.0529 - val_accuracy: 0.9837\n",
      "Epoch 81/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0488 - accuracy: 0.9855 - val_loss: 0.0587 - val_accuracy: 0.9825\n",
      "Epoch 82/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0481 - accuracy: 0.9853 - val_loss: 0.0532 - val_accuracy: 0.9845\n",
      "Epoch 83/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0484 - accuracy: 0.9855 - val_loss: 0.0546 - val_accuracy: 0.9835\n",
      "Epoch 84/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0473 - accuracy: 0.9861 - val_loss: 0.0559 - val_accuracy: 0.9835\n",
      "Epoch 85/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0474 - accuracy: 0.9854 - val_loss: 0.0540 - val_accuracy: 0.9837\n",
      "Epoch 86/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0470 - accuracy: 0.9856 - val_loss: 0.0533 - val_accuracy: 0.9848\n",
      "Epoch 87/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 0.0562 - val_accuracy: 0.9842\n",
      "Epoch 88/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0464 - accuracy: 0.9858 - val_loss: 0.0518 - val_accuracy: 0.9845\n",
      "Epoch 89/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0459 - accuracy: 0.9862 - val_loss: 0.0549 - val_accuracy: 0.9832\n",
      "Epoch 90/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0457 - accuracy: 0.9862 - val_loss: 0.0535 - val_accuracy: 0.9837\n",
      "Epoch 91/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0454 - accuracy: 0.9862 - val_loss: 0.0525 - val_accuracy: 0.9857\n",
      "Epoch 92/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0449 - accuracy: 0.9864 - val_loss: 0.0531 - val_accuracy: 0.9852\n",
      "Epoch 93/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0447 - accuracy: 0.9865 - val_loss: 0.0513 - val_accuracy: 0.9853\n",
      "Epoch 94/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0448 - accuracy: 0.9863 - val_loss: 0.0535 - val_accuracy: 0.9852\n",
      "Epoch 95/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0440 - accuracy: 0.9869 - val_loss: 0.0513 - val_accuracy: 0.9857\n",
      "Epoch 96/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0439 - accuracy: 0.9866 - val_loss: 0.0538 - val_accuracy: 0.9847\n",
      "Epoch 97/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0435 - accuracy: 0.9867 - val_loss: 0.0559 - val_accuracy: 0.9843\n",
      "Epoch 98/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0431 - accuracy: 0.9868 - val_loss: 0.0549 - val_accuracy: 0.9848\n",
      "Epoch 99/100\n",
      "211/211 [==============================] - 3s 14ms/step - loss: 0.0431 - accuracy: 0.9868 - val_loss: 0.0519 - val_accuracy: 0.9850\n",
      "Epoch 100/100\n",
      "211/211 [==============================] - 3s 15ms/step - loss: 0.0431 - accuracy: 0.9869 - val_loss: 0.0504 - val_accuracy: 0.9855\n",
      "313/313 - 1s - loss: 0.0454 - accuracy: 0.9852\n",
      "testSetLoss: 0.045441895723342896 - testSetAccuracyz: 0.9851999878883362%\n"
     ]
    }
   ],
   "source": [
    "test5_256 = trainModel4(100, 256)\n",
    "hist_df = pd.DataFrame(test5_256.history)\n",
    "hist_json_file = 'test5_256.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                16010     \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 3s 27ms/step - loss: 2.2300 - accuracy: 0.3191 - val_loss: 2.1178 - val_accuracy: 0.4888\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.8284 - accuracy: 0.6050 - val_loss: 1.3210 - val_accuracy: 0.7702\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.9347 - accuracy: 0.7852 - val_loss: 0.5945 - val_accuracy: 0.8588\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.5600 - accuracy: 0.8481 - val_loss: 0.4126 - val_accuracy: 0.8883\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.4470 - accuracy: 0.8739 - val_loss: 0.3368 - val_accuracy: 0.9100\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.3919 - accuracy: 0.8887 - val_loss: 0.3019 - val_accuracy: 0.9163\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.3568 - accuracy: 0.8968 - val_loss: 0.2772 - val_accuracy: 0.9210\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.3300 - accuracy: 0.9048 - val_loss: 0.2502 - val_accuracy: 0.9307\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.3089 - accuracy: 0.9100 - val_loss: 0.2356 - val_accuracy: 0.9360\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.2905 - accuracy: 0.9160 - val_loss: 0.2207 - val_accuracy: 0.9385\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.2755 - accuracy: 0.9200 - val_loss: 0.2191 - val_accuracy: 0.9375\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.2614 - accuracy: 0.9239 - val_loss: 0.2165 - val_accuracy: 0.9372\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.2484 - accuracy: 0.9279 - val_loss: 0.1952 - val_accuracy: 0.9465A: 0s - loss: 0.2483 - accuracy: \n",
      "Epoch 14/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.2373 - accuracy: 0.9306 - val_loss: 0.1812 - val_accuracy: 0.9513\n",
      "Epoch 15/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.2265 - accuracy: 0.9346 - val_loss: 0.1783 - val_accuracy: 0.9498\n",
      "Epoch 16/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.2179 - accuracy: 0.9372 - val_loss: 0.1688 - val_accuracy: 0.9537\n",
      "Epoch 17/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.2088 - accuracy: 0.9393 - val_loss: 0.1799 - val_accuracy: 0.9477\n",
      "Epoch 18/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.2006 - accuracy: 0.9414 - val_loss: 0.1566 - val_accuracy: 0.9567\n",
      "Epoch 19/100\n",
      "106/106 [==============================] - 2s 24ms/step - loss: 0.1937 - accuracy: 0.9443 - val_loss: 0.1534 - val_accuracy: 0.9573\n",
      "Epoch 20/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1867 - accuracy: 0.9464 - val_loss: 0.1455 - val_accuracy: 0.9603\n",
      "Epoch 21/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1799 - accuracy: 0.9482 - val_loss: 0.1470 - val_accuracy: 0.9602\n",
      "Epoch 22/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1740 - accuracy: 0.9496 - val_loss: 0.1405 - val_accuracy: 0.9617\n",
      "Epoch 23/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1683 - accuracy: 0.9519 - val_loss: 0.1379 - val_accuracy: 0.9625 0s - loss: 0.1685 - accuracy: 0.\n",
      "Epoch 24/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1634 - accuracy: 0.9532 - val_loss: 0.1318 - val_accuracy: 0.9652\n",
      "Epoch 25/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1583 - accuracy: 0.9545 - val_loss: 0.1284 - val_accuracy: 0.9658\n",
      "Epoch 26/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1540 - accuracy: 0.9554 - val_loss: 0.1244 - val_accuracy: 0.9653\n",
      "Epoch 27/100\n",
      "106/106 [==============================] - 2s 24ms/step - loss: 0.1496 - accuracy: 0.9571 - val_loss: 0.1213 - val_accuracy: 0.9672\n",
      "Epoch 28/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1455 - accuracy: 0.9582 - val_loss: 0.1178 - val_accuracy: 0.9678\n",
      "Epoch 29/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1418 - accuracy: 0.9592 - val_loss: 0.1151 - val_accuracy: 0.9690\n",
      "Epoch 30/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1386 - accuracy: 0.9608 - val_loss: 0.1159 - val_accuracy: 0.9678\n",
      "Epoch 31/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1353 - accuracy: 0.9612 - val_loss: 0.1150 - val_accuracy: 0.9697\n",
      "Epoch 32/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1321 - accuracy: 0.9619 - val_loss: 0.1093 - val_accuracy: 0.9703\n",
      "Epoch 33/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1291 - accuracy: 0.9629 - val_loss: 0.1093 - val_accuracy: 0.9693\n",
      "Epoch 34/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1264 - accuracy: 0.9642 - val_loss: 0.1040 - val_accuracy: 0.9727\n",
      "Epoch 35/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1237 - accuracy: 0.9643 - val_loss: 0.1056 - val_accuracy: 0.9708\n",
      "Epoch 36/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1213 - accuracy: 0.9649 - val_loss: 0.1008 - val_accuracy: 0.9732\n",
      "Epoch 37/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1192 - accuracy: 0.9655 - val_loss: 0.0987 - val_accuracy: 0.9733y\n",
      "Epoch 38/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1164 - accuracy: 0.9661 - val_loss: 0.0962 - val_accuracy: 0.9738\n",
      "Epoch 39/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1145 - accuracy: 0.9669 - val_loss: 0.1006 - val_accuracy: 0.9727\n",
      "Epoch 40/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1124 - accuracy: 0.9675 - val_loss: 0.0991 - val_accuracy: 0.9722\n",
      "Epoch 41/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1105 - accuracy: 0.9682 - val_loss: 0.0937 - val_accuracy: 0.9740\n",
      "Epoch 42/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1086 - accuracy: 0.9688 - val_loss: 0.0954 - val_accuracy: 0.9745\n",
      "Epoch 43/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1067 - accuracy: 0.9688 - val_loss: 0.0921 - val_accuracy: 0.9740\n",
      "Epoch 44/100\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 0.1054 - accuracy: 0.9694 - val_loss: 0.0913 - val_accuracy: 0.9748\n",
      "Epoch 45/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1034 - accuracy: 0.9696 - val_loss: 0.0932 - val_accuracy: 0.9738\n",
      "Epoch 46/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1019 - accuracy: 0.9700 - val_loss: 0.0880 - val_accuracy: 0.9763\n",
      "Epoch 47/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.1001 - accuracy: 0.9711 - val_loss: 0.0866 - val_accuracy: 0.9755\n",
      "Epoch 48/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0987 - accuracy: 0.9707 - val_loss: 0.0853 - val_accuracy: 0.9763\n",
      "Epoch 49/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0975 - accuracy: 0.9717 - val_loss: 0.0840 - val_accuracy: 0.9773\n",
      "Epoch 50/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0960 - accuracy: 0.9721 - val_loss: 0.0859 - val_accuracy: 0.9767\n",
      "Epoch 51/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0951 - accuracy: 0.9719 - val_loss: 0.0842 - val_accuracy: 0.9765\n",
      "Epoch 52/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0934 - accuracy: 0.9725 - val_loss: 0.0821 - val_accuracy: 0.9785\n",
      "Epoch 53/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0924 - accuracy: 0.9728 - val_loss: 0.0825 - val_accuracy: 0.9780\n",
      "Epoch 54/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0910 - accuracy: 0.9730 - val_loss: 0.0806 - val_accuracy: 0.9785\n",
      "Epoch 55/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0899 - accuracy: 0.9735 - val_loss: 0.0793 - val_accuracy: 0.9783\n",
      "Epoch 56/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0889 - accuracy: 0.9736 - val_loss: 0.0848 - val_accuracy: 0.9765\n",
      "Epoch 57/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0880 - accuracy: 0.9742 - val_loss: 0.0806 - val_accuracy: 0.9770\n",
      "Epoch 58/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0869 - accuracy: 0.9741 - val_loss: 0.0781 - val_accuracy: 0.9787\n",
      "Epoch 59/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0859 - accuracy: 0.9747 - val_loss: 0.0774 - val_accuracy: 0.9792\n",
      "Epoch 60/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0850 - accuracy: 0.9746 - val_loss: 0.0770 - val_accuracy: 0.9780\n",
      "Epoch 61/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0839 - accuracy: 0.9747 - val_loss: 0.0790 - val_accuracy: 0.9792\n",
      "Epoch 62/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0830 - accuracy: 0.9753 - val_loss: 0.0750 - val_accuracy: 0.9798\n",
      "Epoch 63/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0820 - accuracy: 0.9756 - val_loss: 0.0755 - val_accuracy: 0.9783\n",
      "Epoch 64/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0815 - accuracy: 0.9755 - val_loss: 0.0770 - val_accuracy: 0.9783\n",
      "Epoch 65/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0807 - accuracy: 0.9759 - val_loss: 0.0765 - val_accuracy: 0.9785\n",
      "Epoch 66/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0796 - accuracy: 0.9766 - val_loss: 0.0740 - val_accuracy: 0.9780\n",
      "Epoch 67/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0790 - accuracy: 0.9761 - val_loss: 0.0741 - val_accuracy: 0.9795\n",
      "Epoch 68/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0782 - accuracy: 0.9767 - val_loss: 0.0736 - val_accuracy: 0.9797\n",
      "Epoch 69/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0775 - accuracy: 0.9768 - val_loss: 0.0714 - val_accuracy: 0.9802\n",
      "Epoch 70/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0769 - accuracy: 0.9771 - val_loss: 0.0734 - val_accuracy: 0.9797\n",
      "Epoch 71/100\n",
      "106/106 [==============================] - 2s 24ms/step - loss: 0.0762 - accuracy: 0.9773 - val_loss: 0.0722 - val_accuracy: 0.9802\n",
      "Epoch 72/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0752 - accuracy: 0.9774 - val_loss: 0.0716 - val_accuracy: 0.9798\n",
      "Epoch 73/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0747 - accuracy: 0.9776 - val_loss: 0.0721 - val_accuracy: 0.9810\n",
      "Epoch 74/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0739 - accuracy: 0.9780 - val_loss: 0.0704 - val_accuracy: 0.9807\n",
      "Epoch 75/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0734 - accuracy: 0.9781 - val_loss: 0.0724 - val_accuracy: 0.9807\n",
      "Epoch 76/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0724 - accuracy: 0.9784 - val_loss: 0.0689 - val_accuracy: 0.9792\n",
      "Epoch 77/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0721 - accuracy: 0.9784 - val_loss: 0.0672 - val_accuracy: 0.9803\n",
      "Epoch 78/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0713 - accuracy: 0.9787 - val_loss: 0.0693 - val_accuracy: 0.9793\n",
      "Epoch 79/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0705 - accuracy: 0.9787 - val_loss: 0.0698 - val_accuracy: 0.9797\n",
      "Epoch 80/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0703 - accuracy: 0.9789 - val_loss: 0.0690 - val_accuracy: 0.9813\n",
      "Epoch 81/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0699 - accuracy: 0.9790 - val_loss: 0.0682 - val_accuracy: 0.9803\n",
      "Epoch 82/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0693 - accuracy: 0.9795 - val_loss: 0.0670 - val_accuracy: 0.9813\n",
      "Epoch 83/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0688 - accuracy: 0.9796 - val_loss: 0.0661 - val_accuracy: 0.9812\n",
      "Epoch 84/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0681 - accuracy: 0.9795 - val_loss: 0.0687 - val_accuracy: 0.9817\n",
      "Epoch 85/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0676 - accuracy: 0.9801 - val_loss: 0.0677 - val_accuracy: 0.9818\n",
      "Epoch 86/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0673 - accuracy: 0.9803 - val_loss: 0.0699 - val_accuracy: 0.9817\n",
      "Epoch 87/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0668 - accuracy: 0.9803 - val_loss: 0.0684 - val_accuracy: 0.9800\n",
      "Epoch 88/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0663 - accuracy: 0.9801 - val_loss: 0.0643 - val_accuracy: 0.9808\n",
      "Epoch 89/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0657 - accuracy: 0.9801 - val_loss: 0.0651 - val_accuracy: 0.9823\n",
      "Epoch 90/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0652 - accuracy: 0.9804 - val_loss: 0.0657 - val_accuracy: 0.9820\n",
      "Epoch 91/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0648 - accuracy: 0.9807 - val_loss: 0.0649 - val_accuracy: 0.9813\n",
      "Epoch 92/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0645 - accuracy: 0.9809 - val_loss: 0.0654 - val_accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0640 - accuracy: 0.9804 - val_loss: 0.0655 - val_accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0636 - accuracy: 0.9810 - val_loss: 0.0655 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0631 - accuracy: 0.9811 - val_loss: 0.0641 - val_accuracy: 0.9820\n",
      "Epoch 96/100\n",
      "106/106 [==============================] - 4s 34ms/step - loss: 0.0626 - accuracy: 0.9810 - val_loss: 0.0641 - val_accuracy: 0.9823\n",
      "Epoch 97/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0621 - accuracy: 0.9816 - val_loss: 0.0665 - val_accuracy: 0.9817\n",
      "Epoch 98/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0618 - accuracy: 0.9815 - val_loss: 0.0629 - val_accuracy: 0.9823\n",
      "Epoch 99/100\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 0.0615 - accuracy: 0.9817 - val_loss: 0.0633 - val_accuracy: 0.9813\n",
      "Epoch 100/100\n",
      "106/106 [==============================] - 2s 23ms/step - loss: 0.0611 - accuracy: 0.9821 - val_loss: 0.0649 - val_accuracy: 0.9815\n",
      "313/313 - 1s - loss: 0.0614 - accuracy: 0.9802\n",
      "testSetLoss: 0.06142297387123108 - testSetAccuracyz: 0.9801999926567078%\n"
     ]
    }
   ],
   "source": [
    "test5_512 = trainModel4(100, 512)\n",
    "hist_df = pd.DataFrame(test5_512.history)\n",
    "hist_json_file = 'test5_512.csv' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test1</th>\n",
       "      <th>test1Ttime</th>\n",
       "      <th>test2</th>\n",
       "      <th>test2Ttime</th>\n",
       "      <th>test3</th>\n",
       "      <th>test3Ttime</th>\n",
       "      <th>test4</th>\n",
       "      <th>test4Ttime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9860</td>\n",
       "      <td>14179.0</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>13664.3</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>13181.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9875</td>\n",
       "      <td>3833.2</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>3186.7</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>2953.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.9887</td>\n",
       "      <td>2265.8</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>1702.8</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>1676.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.9875</td>\n",
       "      <td>1350.1</td>\n",
       "      <td>0.9913</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>1082.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.9897</td>\n",
       "      <td>681.5</td>\n",
       "      <td>0.9923</td>\n",
       "      <td>636.5</td>\n",
       "      <td>0.9879</td>\n",
       "      <td>607.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.9894</td>\n",
       "      <td>479.6</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>403.0</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>402.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.9895</td>\n",
       "      <td>345.4</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>302.2</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>299.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.9889</td>\n",
       "      <td>277.5</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>259.3</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>258.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test1  test1Ttime   test2  test2Ttime   test3  test3Ttime  test4  \\\n",
       "2    0.9860     14179.0  0.9850     13664.3  0.9909     13181.8    NaN   \n",
       "8    0.9875      3833.2  0.9875      3186.7  0.9903      2953.7    NaN   \n",
       "16   0.9887      2265.8  0.9902      1702.8  0.9892      1676.2    NaN   \n",
       "32   0.9875      1350.1  0.9913      1113.0  0.9889      1082.8    NaN   \n",
       "64   0.9897       681.5  0.9923       636.5  0.9879       607.1    NaN   \n",
       "128  0.9894       479.6  0.9909       403.0  0.9894       402.8    NaN   \n",
       "256  0.9895       345.4  0.9903       302.2  0.9852       299.9    NaN   \n",
       "512  0.9889       277.5  0.9909       259.3  0.9802       258.6    NaN   \n",
       "\n",
       "     test4Ttime  \n",
       "2           NaN  \n",
       "8           NaN  \n",
       "16          NaN  \n",
       "32          NaN  \n",
       "64          NaN  \n",
       "128         NaN  \n",
       "256         NaN  \n",
       "512         NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('example5.xlsx', index_col=0)\n",
    "df['test1Ttime'] = df['test1Ttime'].apply(lambda x: x*86400)\n",
    "df['test2Ttime'] = df['test2Ttime'].apply(lambda x: x*86400)\n",
    "df['test3Ttime'] = df['test3Ttime'].apply(lambda x: x*86400)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['test1'] = df['test1'].apply(lambda x: x*100)\n",
    "df['test2'] = df['test2'].apply(lambda x: x*100)\n",
    "df['test3'] = df['test3'].apply(lambda x: x*100)\n",
    "# df['activation'] = df['activation'].apply(lambda x: x*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1c9959c7160>,\n",
       "  <matplotlib.axis.XTick at 0x1c9959c7130>,\n",
       "  <matplotlib.axis.XTick at 0x1c997a9f6a0>,\n",
       "  <matplotlib.axis.XTick at 0x1c997a946a0>,\n",
       "  <matplotlib.axis.XTick at 0x1c997aaa8b0>,\n",
       "  <matplotlib.axis.XTick at 0x1c997aaadc0>,\n",
       "  <matplotlib.axis.XTick at 0x1c995a36cd0>,\n",
       "  <matplotlib.axis.XTick at 0x1c997ee4dc0>],\n",
       " [Text(0, 0, '2'),\n",
       "  Text(1, 0, '8'),\n",
       "  Text(2, 0, '16'),\n",
       "  Text(3, 0, '32'),\n",
       "  Text(4, 0, '64'),\n",
       "  Text(5, 0, '128'),\n",
       "  Text(6, 0, '256'),\n",
       "  Text(7, 0, '512')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr1 = np.array(df['test1'])\n",
    "arr2 = np.array(df['test2'])\n",
    "arr5 = np.array(df['test3'])\n",
    "# arr7 = np.array(df['activation'])\n",
    "sized = np.arange(0, 8)\n",
    "bs = [2,8,16,32,64,128,256,512]\n",
    "fig, ((ax1, ax3, ax5)) = plt.subplots(3, 1, figsize=(20,10))\n",
    "fig.tight_layout(pad=5.0)\n",
    "\n",
    "ax1.plot(sized, arr1, label='activation function', marker = '*')\n",
    "ax1.set_xlabel('Batch size')\n",
    "ax1.set_ylabel('Test accuracy')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.set_title('test1')\n",
    "ax1.set_ylim([98, 100])\n",
    "# ax1.xticks(sized, bs)\n",
    "plt.sca(ax1)\n",
    "plt.xticks(sized, bs)\n",
    "\n",
    "ax3.plot(sized, arr2, label='loss function', marker = '*')\n",
    "ax3.set_xlabel('Batch size')\n",
    "ax3.set_ylabel('Test accuracy')\n",
    "ax3.legend(loc='lower right')\n",
    "ax3.set_title('test2')\n",
    "ax3.set_ylim([98, 100])\n",
    "# ax2.xticks(sized, bs)\n",
    "plt.sca(ax3)\n",
    "plt.xticks(sized, bs)\n",
    "\n",
    "\n",
    "ax5.plot(sized, arr5, label='optimizer', marker = '*')\n",
    "ax5.set_xlabel('Batch size')\n",
    "ax5.set_ylabel('Test accuracy')\n",
    "ax5.legend(loc='lower right')\n",
    "ax5.set_title('test3')\n",
    "ax5.set_ylim([98, 100])\n",
    "# ax3.xticks(sized, bs)\n",
    "plt.sca(ax3)\n",
    "plt.xticks(sized, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr1 = np.array(df['test1Ttime'])\n",
    "arr2 = np.array(df['test2Ttime'])\n",
    "arr3 = np.array(df['test3Ttime'])\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(sized, arr1, label='test1Time', marker = '*')\n",
    "plt.plot(sized, arr2, label='test2Time', marker = '*')\n",
    "plt.plot(sized, arr3, label='test3Time', marker = '*')\n",
    "plt.xlabel('Batch size')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Batch Size effect')\n",
    "plt.xticks(sized, bs)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
